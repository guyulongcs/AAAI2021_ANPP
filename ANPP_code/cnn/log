RuntimeError: module compiled against API version 0xc but this version of numpy is 0xb
RuntimeError: module compiled against API version 0xc but this version of numpy is 0xb
Loading data..
2018-06-13 22:07:36.475453: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-06-13 22:07:39.536101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: Tesla P40 major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:03:00.0
totalMemory: 22.38GiB freeMemory: 22.21GiB
2018-06-13 22:07:39.536158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-06-13 22:07:39.841262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-13 22:07:39.841325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-06-13 22:07:39.841334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-06-13 22:07:39.841840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21553 MB memory) -> physical GPU (device: 0, name: Tesla P40, pci bus id: 0000:03:00.0, compute capability: 6.1)
{
    "num_blocks": 1, 
    "help": false, 
    "train_batch_size": 32, 
    "max_epochs": 50, 
    "display_freq": 100, 
    "regulation_rate": 5e-05, 
    "eval_freq": 1000, 
    "test_batch_size": 512, 
    "num_heads": 8, 
    "model_dir": "save_path", 
    "dropout": 0.0, 
    "concat_time_emb": true, 
    "helpfull": false, 
    "from_scratch": true, 
    "optimizer": "sgd", 
    "cuda_visible_devices": "1", 
    "helpshort": false, 
    "learning_rate": 1.0, 
    "hidden_units": 128, 
    "max_gradient_norm": 5.0, 
    "per_process_gpu_memory_fraction": 0.0, 
    "h": false, 
    "itemid_embedding_size": 64, 
    "cateid_embedding_size": 64, 
    "user_count": 192403, 
    "item_count": 63001, 
    "cate_count": 801
}
All global variables:
('\t', <tf.Variable 'item_emb_w:0' shape=(63001, 64) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'item_b:0' shape=(63001,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'cate_emb_w:0' shape=(801, 64) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'dense/kernel:0' shape=(140, 128) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'dense/bias:0' shape=(128,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-1/W:0' shape=(1, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-1/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-2/W:0' shape=(2, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-2/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-3/W:0' shape=(3, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-3/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-4/W:0' shape=(4, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-4/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-5/W:0' shape=(5, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-5/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-6/W:0' shape=(6, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-6/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-7/W:0' shape=(7, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-7/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-8/W:0' shape=(8, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-8/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-9/W:0' shape=(9, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-9/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-10/W:0' shape=(10, 128, 1, 32) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'conv-maxpool-10/b:0' shape=(32,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'dense_1/kernel:0' shape=(320, 128) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'dense_1/bias:0' shape=(128,) dtype=float32_ref>, 'trainable')
('\t', <tf.Variable 'global_step:0' shape=() dtype=int32_ref>)
('\t', <tf.Variable 'global_epoch_step:0' shape=() dtype=int32_ref>)
Created new model parameters..
Init finish.	Cost time: 255.98s
Init AUC: 0.4820
Training..	max_epochs: 50	epoch_size: 81523
Epoch 0 Global_step 1000	Train_loss: 0.6808	Eval_AUC: 0.6365
Epoch 0 Global_step 2000	Train_loss: 0.6585	Eval_AUC: 0.6978
Epoch 0 Global_step 3000	Train_loss: 0.6253	Eval_AUC: 0.7382
Epoch 0 Global_step 4000	Train_loss: 0.6003	Eval_AUC: 0.7517
Epoch 0 Global_step 5000	Train_loss: 0.5886	Eval_AUC: 0.7721
Epoch 0 Global_step 6000	Train_loss: 0.5782	Eval_AUC: 0.7756
Epoch 0 Global_step 7000	Train_loss: 0.5720	Eval_AUC: 0.7794
Epoch 0 Global_step 8000	Train_loss: 0.5672	Eval_AUC: 0.7863
Epoch 0 Global_step 9000	Train_loss: 0.5620	Eval_AUC: 0.7890
Epoch 0 Global_step 10000	Train_loss: 0.5565	Eval_AUC: 0.7919
Epoch 0 Global_step 11000	Train_loss: 0.5487	Eval_AUC: 0.7936
Epoch 0 Global_step 12000	Train_loss: 0.5510	Eval_AUC: 0.7958
Epoch 0 Global_step 13000	Train_loss: 0.5491	Eval_AUC: 0.7953
Epoch 0 Global_step 14000	Train_loss: 0.5464	Eval_AUC: 0.7974
Epoch 0 Global_step 15000	Train_loss: 0.5410	Eval_AUC: 0.7989
Epoch 0 Global_step 16000	Train_loss: 0.5429	Eval_AUC: 0.8044
Epoch 0 Global_step 17000	Train_loss: 0.5392	Eval_AUC: 0.8064
Epoch 0 Global_step 18000	Train_loss: 0.5426	Eval_AUC: 0.7969
Epoch 0 Global_step 19000	Train_loss: 0.5390	Eval_AUC: 0.8091
Epoch 0 Global_step 20000	Train_loss: 0.5313	Eval_AUC: 0.8005
Epoch 0 Global_step 21000	Train_loss: 0.5380	Eval_AUC: 0.8004
Epoch 0 Global_step 22000	Train_loss: 0.5366	Eval_AUC: 0.7977
Epoch 0 Global_step 23000	Train_loss: 0.5330	Eval_AUC: 0.8102
Epoch 0 Global_step 24000	Train_loss: 0.5364	Eval_AUC: 0.8092
Epoch 0 Global_step 25000	Train_loss: 0.5321	Eval_AUC: 0.8024
Epoch 0 Global_step 26000	Train_loss: 0.5334	Eval_AUC: 0.8042
Epoch 0 Global_step 27000	Train_loss: 0.5289	Eval_AUC: 0.8092
Epoch 0 Global_step 28000	Train_loss: 0.5334	Eval_AUC: 0.8094
Epoch 0 Global_step 29000	Train_loss: 0.5299	Eval_AUC: 0.8105
Epoch 0 Global_step 30000	Train_loss: 0.5311	Eval_AUC: 0.8053
Epoch 0 Global_step 31000	Train_loss: 0.5323	Eval_AUC: 0.8093
Epoch 0 Global_step 32000	Train_loss: 0.5309	Eval_AUC: 0.8107
Epoch 0 Global_step 33000	Train_loss: 0.5298	Eval_AUC: 0.8133
Epoch 0 Global_step 34000	Train_loss: 0.5236	Eval_AUC: 0.8135
Epoch 0 Global_step 35000	Train_loss: 0.5250	Eval_AUC: 0.8131
Epoch 0 Global_step 36000	Train_loss: 0.5261	Eval_AUC: 0.8072
Epoch 0 Global_step 37000	Train_loss: 0.5277	Eval_AUC: 0.8114
Epoch 0 Global_step 38000	Train_loss: 0.5241	Eval_AUC: 0.8139
Epoch 0 Global_step 39000	Train_loss: 0.5268	Eval_AUC: 0.8127
Epoch 0 Global_step 40000	Train_loss: 0.5213	Eval_AUC: 0.8125
Epoch 0 Global_step 41000	Train_loss: 0.5168	Eval_AUC: 0.8116
Epoch 0 Global_step 42000	Train_loss: 0.5213	Eval_AUC: 0.8123
Epoch 0 Global_step 43000	Train_loss: 0.5203	Eval_AUC: 0.8122
Epoch 0 Global_step 44000	Train_loss: 0.5235	Eval_AUC: 0.8032
Epoch 0 Global_step 45000	Train_loss: 0.5200	Eval_AUC: 0.8113
Epoch 0 Global_step 46000	Train_loss: 0.5263	Eval_AUC: 0.8144
Epoch 0 Global_step 47000	Train_loss: 0.5178	Eval_AUC: 0.8168
Epoch 0 Global_step 48000	Train_loss: 0.5185	Eval_AUC: 0.8168
Epoch 0 Global_step 49000	Train_loss: 0.5169	Eval_AUC: 0.8179
Epoch 0 Global_step 50000	Train_loss: 0.5191	Eval_AUC: 0.8135
Epoch 0 Global_step 51000	Train_loss: 0.5187	Eval_AUC: 0.8171
Epoch 0 Global_step 52000	Train_loss: 0.5174	Eval_AUC: 0.8150
Epoch 0 Global_step 53000	Train_loss: 0.5158	Eval_AUC: 0.8129
Epoch 0 Global_step 54000	Train_loss: 0.5124	Eval_AUC: 0.8181
Epoch 0 Global_step 55000	Train_loss: 0.5179	Eval_AUC: 0.8161
Epoch 0 Global_step 56000	Train_loss: 0.5117	Eval_AUC: 0.8221
Epoch 0 Global_step 57000	Train_loss: 0.5172	Eval_AUC: 0.8174
Epoch 0 Global_step 58000	Train_loss: 0.5111	Eval_AUC: 0.8148
Epoch 0 Global_step 59000	Train_loss: 0.5149	Eval_AUC: 0.8183
Epoch 0 Global_step 60000	Train_loss: 0.5158	Eval_AUC: 0.8164
Epoch 0 Global_step 61000	Train_loss: 0.5124	Eval_AUC: 0.8155
Epoch 0 Global_step 62000	Train_loss: 0.5141	Eval_AUC: 0.8197
Epoch 0 Global_step 63000	Train_loss: 0.5145	Eval_AUC: 0.8180
Epoch 0 Global_step 64000	Train_loss: 0.5149	Eval_AUC: 0.8170
Epoch 0 Global_step 65000	Train_loss: 0.5119	Eval_AUC: 0.8250
Epoch 0 Global_step 66000	Train_loss: 0.5167	Eval_AUC: 0.8173
Epoch 0 Global_step 67000	Train_loss: 0.5119	Eval_AUC: 0.8213
Epoch 0 Global_step 68000	Train_loss: 0.5118	Eval_AUC: 0.8133
Epoch 0 Global_step 69000	Train_loss: 0.5109	Eval_AUC: 0.8163
Epoch 0 Global_step 70000	Train_loss: 0.5075	Eval_AUC: 0.8179
Epoch 0 Global_step 71000	Train_loss: 0.5126	Eval_AUC: 0.8209
Epoch 0 Global_step 72000	Train_loss: 0.5078	Eval_AUC: 0.8204
Epoch 0 Global_step 73000	Train_loss: 0.5088	Eval_AUC: 0.8210
Epoch 0 Global_step 74000	Train_loss: 0.5078	Eval_AUC: 0.8203
Epoch 0 Global_step 75000	Train_loss: 0.5099	Eval_AUC: 0.8208
Epoch 0 Global_step 76000	Train_loss: 0.5086	Eval_AUC: 0.8254
Epoch 0 Global_step 77000	Train_loss: 0.5044	Eval_AUC: 0.8181
Epoch 0 Global_step 78000	Train_loss: 0.5038	Eval_AUC: 0.8243
Epoch 0 Global_step 79000	Train_loss: 0.5044	Eval_AUC: 0.8194
Epoch 0 Global_step 80000	Train_loss: 0.5034	Eval_AUC: 0.8210
Epoch 0 Global_step 81000	Train_loss: 0.5060	Eval_AUC: 0.8193
Epoch 0 DONE	Cost time: 8206.59
Epoch 1 Global_step 82000	Train_loss: 0.4929	Eval_AUC: 0.8277
Epoch 1 Global_step 83000	Train_loss: 0.4774	Eval_AUC: 0.8214
Epoch 1 Global_step 84000	Train_loss: 0.4812	Eval_AUC: 0.8242
Epoch 1 Global_step 85000	Train_loss: 0.4830	Eval_AUC: 0.8269
Epoch 1 Global_step 86000	Train_loss: 0.4831	Eval_AUC: 0.8255
Epoch 1 Global_step 87000	Train_loss: 0.4796	Eval_AUC: 0.8248
Epoch 1 Global_step 88000	Train_loss: 0.4825	Eval_AUC: 0.8268
Epoch 1 Global_step 89000	Train_loss: 0.4806	Eval_AUC: 0.8300
Epoch 1 Global_step 90000	Train_loss: 0.4817	Eval_AUC: 0.8178
Epoch 1 Global_step 91000	Train_loss: 0.4861	Eval_AUC: 0.8309
Epoch 1 Global_step 92000	Train_loss: 0.4839	Eval_AUC: 0.8260
Epoch 1 Global_step 93000	Train_loss: 0.4799	Eval_AUC: 0.8239
Epoch 1 Global_step 94000	Train_loss: 0.4814	Eval_AUC: 0.8292
Epoch 1 Global_step 95000	Train_loss: 0.4872	Eval_AUC: 0.8235
Epoch 1 Global_step 96000	Train_loss: 0.4775	Eval_AUC: 0.8277
Epoch 1 Global_step 97000	Train_loss: 0.4858	Eval_AUC: 0.8244
Epoch 1 Global_step 98000	Train_loss: 0.4784	Eval_AUC: 0.8257
Epoch 1 Global_step 99000	Train_loss: 0.4840	Eval_AUC: 0.8095
Epoch 1 Global_step 100000	Train_loss: 0.4847	Eval_AUC: 0.8255
Epoch 1 Global_step 101000	Train_loss: 0.4875	Eval_AUC: 0.8309
Epoch 1 Global_step 102000	Train_loss: 0.4864	Eval_AUC: 0.8309
Epoch 1 Global_step 103000	Train_loss: 0.4820	Eval_AUC: 0.8290
Epoch 1 Global_step 104000	Train_loss: 0.4818	Eval_AUC: 0.8318
Epoch 1 Global_step 105000	Train_loss: 0.4790	Eval_AUC: 0.8186
Epoch 1 Global_step 106000	Train_loss: 0.4871	Eval_AUC: 0.8225
Epoch 1 Global_step 107000	Train_loss: 0.4852	Eval_AUC: 0.8349
Epoch 1 Global_step 108000	Train_loss: 0.4837	Eval_AUC: 0.8251
Epoch 1 Global_step 109000	Train_loss: 0.4837	Eval_AUC: 0.8290
Epoch 1 Global_step 110000	Train_loss: 0.4889	Eval_AUC: 0.8224
Epoch 1 Global_step 111000	Train_loss: 0.4877	Eval_AUC: 0.8333
Epoch 1 Global_step 112000	Train_loss: 0.4846	Eval_AUC: 0.8221
Epoch 1 Global_step 113000	Train_loss: 0.4880	Eval_AUC: 0.8251
Epoch 1 Global_step 114000	Train_loss: 0.4873	Eval_AUC: 0.8212
Epoch 1 Global_step 115000	Train_loss: 0.4847	Eval_AUC: 0.8417
Epoch 1 Global_step 116000	Train_loss: 0.4833	Eval_AUC: 0.8349
Epoch 1 Global_step 117000	Train_loss: 0.4802	Eval_AUC: 0.8298
Epoch 1 Global_step 118000	Train_loss: 0.4902	Eval_AUC: 0.8281
Epoch 1 Global_step 119000	Train_loss: 0.4881	Eval_AUC: 0.8156
Epoch 1 Global_step 120000	Train_loss: 0.4825	Eval_AUC: 0.8318
Epoch 1 Global_step 121000	Train_loss: 0.4843	Eval_AUC: 0.8348
Epoch 1 Global_step 122000	Train_loss: 0.4859	Eval_AUC: 0.8343
Epoch 1 Global_step 123000	Train_loss: 0.4841	Eval_AUC: 0.8394
Epoch 1 Global_step 124000	Train_loss: 0.4875	Eval_AUC: 0.8348
Epoch 1 Global_step 125000	Train_loss: 0.4831	Eval_AUC: 0.8298
Epoch 1 Global_step 126000	Train_loss: 0.4824	Eval_AUC: 0.8301
Epoch 1 Global_step 127000	Train_loss: 0.4870	Eval_AUC: 0.8374
Epoch 1 Global_step 128000	Train_loss: 0.4802	Eval_AUC: 0.8282
Epoch 1 Global_step 129000	Train_loss: 0.4824	Eval_AUC: 0.8327
Epoch 1 Global_step 130000	Train_loss: 0.4834	Eval_AUC: 0.8337
Epoch 1 Global_step 131000	Train_loss: 0.4836	Eval_AUC: 0.8305
Epoch 1 Global_step 132000	Train_loss: 0.4857	Eval_AUC: 0.8372
Epoch 1 Global_step 133000	Train_loss: 0.4825	Eval_AUC: 0.8278
Epoch 1 Global_step 134000	Train_loss: 0.4774	Eval_AUC: 0.8337
Epoch 1 Global_step 135000	Train_loss: 0.4808	Eval_AUC: 0.8334
Epoch 1 Global_step 136000	Train_loss: 0.4825	Eval_AUC: 0.8412
Epoch 1 Global_step 137000	Train_loss: 0.4850	Eval_AUC: 0.8268
Epoch 1 Global_step 138000	Train_loss: 0.4768	Eval_AUC: 0.8411
Epoch 1 Global_step 139000	Train_loss: 0.4772	Eval_AUC: 0.8445
Epoch 1 Global_step 140000	Train_loss: 0.4840	Eval_AUC: 0.8306
Epoch 1 Global_step 141000	Train_loss: 0.4806	Eval_AUC: 0.8353
Epoch 1 Global_step 142000	Train_loss: 0.4840	Eval_AUC: 0.8406
Epoch 1 Global_step 143000	Train_loss: 0.4796	Eval_AUC: 0.8206
Epoch 1 Global_step 144000	Train_loss: 0.4771	Eval_AUC: 0.8305
Epoch 1 Global_step 145000	Train_loss: 0.4783	Eval_AUC: 0.8398
Epoch 1 Global_step 146000	Train_loss: 0.4791	Eval_AUC: 0.8292
Epoch 1 Global_step 147000	Train_loss: 0.4750	Eval_AUC: 0.8302
Epoch 1 Global_step 148000	Train_loss: 0.4877	Eval_AUC: 0.8378
Epoch 1 Global_step 149000	Train_loss: 0.4778	Eval_AUC: 0.8340
Epoch 1 Global_step 150000	Train_loss: 0.4781	Eval_AUC: 0.8338
Epoch 1 Global_step 151000	Train_loss: 0.4771	Eval_AUC: 0.8268
Epoch 1 Global_step 152000	Train_loss: 0.4788	Eval_AUC: 0.8396
Epoch 1 Global_step 153000	Train_loss: 0.4788	Eval_AUC: 0.8420
Epoch 1 Global_step 154000	Train_loss: 0.4849	Eval_AUC: 0.8324
Epoch 1 Global_step 155000	Train_loss: 0.4780	Eval_AUC: 0.8364
Epoch 1 Global_step 156000	Train_loss: 0.4777	Eval_AUC: 0.8371
Epoch 1 Global_step 157000	Train_loss: 0.4782	Eval_AUC: 0.8309
Epoch 1 Global_step 158000	Train_loss: 0.4776	Eval_AUC: 0.8337
Epoch 1 Global_step 159000	Train_loss: 0.4726	Eval_AUC: 0.8319
Epoch 1 Global_step 160000	Train_loss: 0.4783	Eval_AUC: 0.8296
Epoch 1 Global_step 161000	Train_loss: 0.4796	Eval_AUC: 0.8246
Epoch 1 Global_step 162000	Train_loss: 0.4832	Eval_AUC: 0.8279
Epoch 1 Global_step 163000	Train_loss: 0.4783	Eval_AUC: 0.8358
Epoch 1 DONE	Cost time: 16464.48
Epoch 2 Global_step 164000	Train_loss: 0.4517	Eval_AUC: 0.8309
Epoch 2 Global_step 165000	Train_loss: 0.4486	Eval_AUC: 0.8333
Epoch 2 Global_step 166000	Train_loss: 0.4508	Eval_AUC: 0.8404
Epoch 2 Global_step 167000	Train_loss: 0.4553	Eval_AUC: 0.8373
Epoch 2 Global_step 168000	Train_loss: 0.4498	Eval_AUC: 0.8327
Epoch 2 Global_step 169000	Train_loss: 0.4518	Eval_AUC: 0.8447
Epoch 2 Global_step 170000	Train_loss: 0.4513	Eval_AUC: 0.8292
Epoch 2 Global_step 171000	Train_loss: 0.4502	Eval_AUC: 0.8335
Epoch 2 Global_step 172000	Train_loss: 0.4555	Eval_AUC: 0.8343
Epoch 2 Global_step 173000	Train_loss: 0.4501	Eval_AUC: 0.8349
Epoch 2 Global_step 174000	Train_loss: 0.4513	Eval_AUC: 0.8467
Epoch 2 Global_step 175000	Train_loss: 0.4563	Eval_AUC: 0.8378
Epoch 2 Global_step 176000	Train_loss: 0.4524	Eval_AUC: 0.8393
Epoch 2 Global_step 177000	Train_loss: 0.4544	Eval_AUC: 0.8393
Epoch 2 Global_step 178000	Train_loss: 0.4537	Eval_AUC: 0.8283
Epoch 2 Global_step 179000	Train_loss: 0.4514	Eval_AUC: 0.8307
Epoch 2 Global_step 180000	Train_loss: 0.4542	Eval_AUC: 0.8328
Epoch 2 Global_step 181000	Train_loss: 0.4610	Eval_AUC: 0.8434
Epoch 2 Global_step 182000	Train_loss: 0.4560	Eval_AUC: 0.8376
Epoch 2 Global_step 183000	Train_loss: 0.4587	Eval_AUC: 0.8390
Epoch 2 Global_step 184000	Train_loss: 0.4547	Eval_AUC: 0.8440
Epoch 2 Global_step 185000	Train_loss: 0.4616	Eval_AUC: 0.8458
Epoch 2 Global_step 186000	Train_loss: 0.4584	Eval_AUC: 0.8302
Epoch 2 Global_step 187000	Train_loss: 0.4565	Eval_AUC: 0.8362
Epoch 2 Global_step 188000	Train_loss: 0.4563	Eval_AUC: 0.8316
Epoch 2 Global_step 189000	Train_loss: 0.4591	Eval_AUC: 0.8367
Epoch 2 Global_step 190000	Train_loss: 0.4659	Eval_AUC: 0.8448
Epoch 2 Global_step 191000	Train_loss: 0.4613	Eval_AUC: 0.8318
Epoch 2 Global_step 192000	Train_loss: 0.4618	Eval_AUC: 0.8458
Epoch 2 Global_step 193000	Train_loss: 0.4578	Eval_AUC: 0.8417
Epoch 2 Global_step 194000	Train_loss: 0.4620	Eval_AUC: 0.8358
Epoch 2 Global_step 195000	Train_loss: 0.4552	Eval_AUC: 0.8479
Epoch 2 Global_step 196000	Train_loss: 0.4592	Eval_AUC: 0.8317
Epoch 2 Global_step 197000	Train_loss: 0.4583	Eval_AUC: 0.8410
Epoch 2 Global_step 198000	Train_loss: 0.4626	Eval_AUC: 0.8391
Epoch 2 Global_step 199000	Train_loss: 0.4569	Eval_AUC: 0.8387
Epoch 2 Global_step 200000	Train_loss: 0.4572	Eval_AUC: 0.8256
Epoch 2 Global_step 201000	Train_loss: 0.4587	Eval_AUC: 0.8453
Epoch 2 Global_step 202000	Train_loss: 0.4653	Eval_AUC: 0.8467
Epoch 2 Global_step 203000	Train_loss: 0.4605	Eval_AUC: 0.8336
Epoch 2 Global_step 204000	Train_loss: 0.4580	Eval_AUC: 0.8436
Epoch 2 Global_step 205000	Train_loss: 0.4621	Eval_AUC: 0.8541
Epoch 2 Global_step 206000	Train_loss: 0.4568	Eval_AUC: 0.8333
Epoch 2 Global_step 207000	Train_loss: 0.4609	Eval_AUC: 0.8531
Epoch 2 Global_step 208000	Train_loss: 0.4651	Eval_AUC: 0.8365
Epoch 2 Global_step 209000	Train_loss: 0.4561	Eval_AUC: 0.8431
Epoch 2 Global_step 210000	Train_loss: 0.4583	Eval_AUC: 0.8412
Epoch 2 Global_step 211000	Train_loss: 0.4601	Eval_AUC: 0.8343
Epoch 2 Global_step 212000	Train_loss: 0.4521	Eval_AUC: 0.8424
Epoch 2 Global_step 213000	Train_loss: 0.4535	Eval_AUC: 0.8361
Epoch 2 Global_step 214000	Train_loss: 0.4652	Eval_AUC: 0.8500
Epoch 2 Global_step 215000	Train_loss: 0.4555	Eval_AUC: 0.8467
Epoch 2 Global_step 216000	Train_loss: 0.4595	Eval_AUC: 0.8458
Epoch 2 Global_step 217000	Train_loss: 0.4584	Eval_AUC: 0.8401
Epoch 2 Global_step 218000	Train_loss: 0.4615	Eval_AUC: 0.8419
Epoch 2 Global_step 219000	Train_loss: 0.4642	Eval_AUC: 0.8339
Epoch 2 Global_step 220000	Train_loss: 0.4566	Eval_AUC: 0.8507
Epoch 2 Global_step 221000	Train_loss: 0.4602	Eval_AUC: 0.8319
Epoch 2 Global_step 222000	Train_loss: 0.4666	Eval_AUC: 0.8511
Epoch 2 Global_step 223000	Train_loss: 0.4608	Eval_AUC: 0.8441
Epoch 2 Global_step 224000	Train_loss: 0.4592	Eval_AUC: 0.8497
Epoch 2 Global_step 225000	Train_loss: 0.4638	Eval_AUC: 0.8356
Epoch 2 Global_step 226000	Train_loss: 0.4612	Eval_AUC: 0.8395
Epoch 2 Global_step 227000	Train_loss: 0.4608	Eval_AUC: 0.8357
Epoch 2 Global_step 228000	Train_loss: 0.4596	Eval_AUC: 0.8394
Epoch 2 Global_step 229000	Train_loss: 0.4666	Eval_AUC: 0.8535
Epoch 2 Global_step 230000	Train_loss: 0.4608	Eval_AUC: 0.8111
Epoch 2 Global_step 231000	Train_loss: 0.4567	Eval_AUC: 0.8375
Epoch 2 Global_step 232000	Train_loss: 0.4639	Eval_AUC: 0.8420
Epoch 2 Global_step 233000	Train_loss: 0.4589	Eval_AUC: 0.8458
Epoch 2 Global_step 234000	Train_loss: 0.4624	Eval_AUC: 0.8424
Epoch 2 Global_step 235000	Train_loss: 0.4576	Eval_AUC: 0.8348
Epoch 2 Global_step 236000	Train_loss: 0.4601	Eval_AUC: 0.8426
Epoch 2 Global_step 237000	Train_loss: 0.4604	Eval_AUC: 0.8500
Epoch 2 Global_step 238000	Train_loss: 0.4558	Eval_AUC: 0.8507
Epoch 2 Global_step 239000	Train_loss: 0.4613	Eval_AUC: 0.8450
Epoch 2 Global_step 240000	Train_loss: 0.4622	Eval_AUC: 0.8471
Epoch 2 Global_step 241000	Train_loss: 0.4602	Eval_AUC: 0.8394
Epoch 2 Global_step 242000	Train_loss: 0.4610	Eval_AUC: 0.8373
Epoch 2 Global_step 243000	Train_loss: 0.4529	Eval_AUC: 0.8329
Epoch 2 Global_step 244000	Train_loss: 0.4571	Eval_AUC: 0.8384
Epoch 2 DONE	Cost time: 24725.51
Epoch 3 Global_step 245000	Train_loss: 0.4503	Eval_AUC: 0.8456
Epoch 3 Global_step 246000	Train_loss: 0.4318	Eval_AUC: 0.8586
Epoch 3 Global_step 247000	Train_loss: 0.4264	Eval_AUC: 0.8500
Epoch 3 Global_step 248000	Train_loss: 0.4347	Eval_AUC: 0.8502
Epoch 3 Global_step 249000	Train_loss: 0.4306	Eval_AUC: 0.8423
Epoch 3 Global_step 250000	Train_loss: 0.4344	Eval_AUC: 0.8403
Epoch 3 Global_step 251000	Train_loss: 0.4335	Eval_AUC: 0.8469
Epoch 3 Global_step 252000	Train_loss: 0.4314	Eval_AUC: 0.8532
Epoch 3 Global_step 253000	Train_loss: 0.4313	Eval_AUC: 0.8315
Epoch 3 Global_step 254000	Train_loss: 0.4387	Eval_AUC: 0.8377
Epoch 3 Global_step 255000	Train_loss: 0.4320	Eval_AUC: 0.8461
Epoch 3 Global_step 256000	Train_loss: 0.4334	Eval_AUC: 0.8350
Epoch 3 Global_step 257000	Train_loss: 0.4400	Eval_AUC: 0.8469
Epoch 3 Global_step 258000	Train_loss: 0.4376	Eval_AUC: 0.8539
Epoch 3 Global_step 259000	Train_loss: 0.4390	Eval_AUC: 0.8482
Epoch 3 Global_step 260000	Train_loss: 0.4350	Eval_AUC: 0.8363
Epoch 3 Global_step 261000	Train_loss: 0.4360	Eval_AUC: 0.8545
Epoch 3 Global_step 262000	Train_loss: 0.4371	Eval_AUC: 0.8489
Epoch 3 Global_step 263000	Train_loss: 0.4369	Eval_AUC: 0.8291
Epoch 3 Global_step 264000	Train_loss: 0.4423	Eval_AUC: 0.8456
Epoch 3 Global_step 265000	Train_loss: 0.4414	Eval_AUC: 0.8493
Epoch 3 Global_step 266000	Train_loss: 0.4389	Eval_AUC: 0.8493
Epoch 3 Global_step 267000	Train_loss: 0.4429	Eval_AUC: 0.8512
Epoch 3 Global_step 268000	Train_loss: 0.4418	Eval_AUC: 0.8521
Epoch 3 Global_step 269000	Train_loss: 0.4474	Eval_AUC: 0.8534
Epoch 3 Global_step 270000	Train_loss: 0.4440	Eval_AUC: 0.8457
Epoch 3 Global_step 271000	Train_loss: 0.4410	Eval_AUC: 0.8303
Epoch 3 Global_step 272000	Train_loss: 0.4416	Eval_AUC: 0.8541
Epoch 3 Global_step 273000	Train_loss: 0.4382	Eval_AUC: 0.8524
Epoch 3 Global_step 274000	Train_loss: 0.4419	Eval_AUC: 0.8516
Epoch 3 Global_step 275000	Train_loss: 0.4463	Eval_AUC: 0.8529
Epoch 3 Global_step 276000	Train_loss: 0.4426	Eval_AUC: 0.8519
Epoch 3 Global_step 277000	Train_loss: 0.4462	Eval_AUC: 0.8483
Epoch 3 Global_step 278000	Train_loss: 0.4454	Eval_AUC: 0.8491
Epoch 3 Global_step 279000	Train_loss: 0.4431	Eval_AUC: 0.8468
Epoch 3 Global_step 280000	Train_loss: 0.4391	Eval_AUC: 0.8506
Epoch 3 Global_step 281000	Train_loss: 0.4364	Eval_AUC: 0.8550
Epoch 3 Global_step 282000	Train_loss: 0.4465	Eval_AUC: 0.8250
Epoch 3 Global_step 283000	Train_loss: 0.4483	Eval_AUC: 0.8515
Epoch 3 Global_step 284000	Train_loss: 0.4452	Eval_AUC: 0.8525
Epoch 3 Global_step 285000	Train_loss: 0.4445	Eval_AUC: 0.8585
Epoch 3 Global_step 286000	Train_loss: 0.4448	Eval_AUC: 0.8540
Epoch 3 Global_step 287000	Train_loss: 0.4436	Eval_AUC: 0.8269
Epoch 3 Global_step 288000	Train_loss: 0.4457	Eval_AUC: 0.8506
Epoch 3 Global_step 289000	Train_loss: 0.4462	Eval_AUC: 0.8534
Epoch 3 Global_step 290000	Train_loss: 0.4419	Eval_AUC: 0.8499
Epoch 3 Global_step 291000	Train_loss: 0.4425	Eval_AUC: 0.8463
Epoch 3 Global_step 292000	Train_loss: 0.4402	Eval_AUC: 0.8587
Epoch 3 Global_step 293000	Train_loss: 0.4452	Eval_AUC: 0.8488
Epoch 3 Global_step 294000	Train_loss: 0.4489	Eval_AUC: 0.8490
Epoch 3 Global_step 295000	Train_loss: 0.4503	Eval_AUC: 0.8373
Epoch 3 Global_step 296000	Train_loss: 0.4473	Eval_AUC: 0.8585
Epoch 3 Global_step 297000	Train_loss: 0.4429	Eval_AUC: 0.8247
Epoch 3 Global_step 298000	Train_loss: 0.4460	Eval_AUC: 0.8392
Epoch 3 Global_step 299000	Train_loss: 0.4430	Eval_AUC: 0.8518
Epoch 3 Global_step 300000	Train_loss: 0.4399	Eval_AUC: 0.8427
Epoch 3 Global_step 301000	Train_loss: 0.4426	Eval_AUC: 0.8381
Epoch 3 Global_step 302000	Train_loss: 0.4405	Eval_AUC: 0.8398
Epoch 3 Global_step 303000	Train_loss: 0.4483	Eval_AUC: 0.8544
Epoch 3 Global_step 304000	Train_loss: 0.4495	Eval_AUC: 0.8533
Epoch 3 Global_step 305000	Train_loss: 0.4474	Eval_AUC: 0.8264
Epoch 3 Global_step 306000	Train_loss: 0.4423	Eval_AUC: 0.8475
Epoch 3 Global_step 307000	Train_loss: 0.4527	Eval_AUC: 0.8523
Epoch 3 Global_step 308000	Train_loss: 0.4483	Eval_AUC: 0.8510
Epoch 3 Global_step 309000	Train_loss: 0.4468	Eval_AUC: 0.8558
Epoch 3 Global_step 310000	Train_loss: 0.4509	Eval_AUC: 0.8505
Epoch 3 Global_step 311000	Train_loss: 0.4482	Eval_AUC: 0.8509
Epoch 3 Global_step 312000	Train_loss: 0.4527	Eval_AUC: 0.8512
Epoch 3 Global_step 313000	Train_loss: 0.4467	Eval_AUC: 0.8536
Epoch 3 Global_step 314000	Train_loss: 0.4531	Eval_AUC: 0.8495
Epoch 3 Global_step 315000	Train_loss: 0.4476	Eval_AUC: 0.8421
Epoch 3 Global_step 316000	Train_loss: 0.4492	Eval_AUC: 0.8482
Epoch 3 Global_step 317000	Train_loss: 0.4448	Eval_AUC: 0.8539
Epoch 3 Global_step 318000	Train_loss: 0.4472	Eval_AUC: 0.8289
Epoch 3 Global_step 319000	Train_loss: 0.4513	Eval_AUC: 0.8557
Epoch 3 Global_step 320000	Train_loss: 0.4467	Eval_AUC: 0.8409
Epoch 3 Global_step 321000	Train_loss: 0.4528	Eval_AUC: 0.8451
Epoch 3 Global_step 322000	Train_loss: 0.4532	Eval_AUC: 0.8386
Epoch 3 Global_step 323000	Train_loss: 0.4512	Eval_AUC: 0.8540
Epoch 3 Global_step 324000	Train_loss: 0.4560	Eval_AUC: 0.8563
Epoch 3 Global_step 325000	Train_loss: 0.4516	Eval_AUC: 0.8527
Epoch 3 Global_step 326000	Train_loss: 0.4509	Eval_AUC: 0.8534
Epoch 3 DONE	Cost time: 33125.87
Epoch 4 Global_step 327000	Train_loss: 0.4195	Eval_AUC: 0.8568
Epoch 4 Global_step 328000	Train_loss: 0.4100	Eval_AUC: 0.8462
Epoch 4 Global_step 329000	Train_loss: 0.4137	Eval_AUC: 0.8526
Epoch 4 Global_step 330000	Train_loss: 0.4217	Eval_AUC: 0.8481
Epoch 4 Global_step 331000	Train_loss: 0.4156	Eval_AUC: 0.8388
Epoch 4 Global_step 332000	Train_loss: 0.4189	Eval_AUC: 0.8449
Epoch 4 Global_step 333000	Train_loss: 0.4186	Eval_AUC: 0.8500
Epoch 4 Global_step 334000	Train_loss: 0.4204	Eval_AUC: 0.8452
Epoch 4 Global_step 335000	Train_loss: 0.4183	Eval_AUC: 0.8575
Epoch 4 Global_step 336000	Train_loss: 0.4207	Eval_AUC: 0.8649
model saved at save_path/atrank-336000
Epoch 4 Global_step 337000	Train_loss: 0.4039	Eval_AUC: 0.8578
Epoch 4 Global_step 338000	Train_loss: 0.3995	Eval_AUC: 0.8605
Epoch 4 Global_step 339000	Train_loss: 0.3961	Eval_AUC: 0.8623
Epoch 4 Global_step 340000	Train_loss: 0.3913	Eval_AUC: 0.8662
model saved at save_path/atrank-340000
Epoch 4 Global_step 341000	Train_loss: 0.3861	Eval_AUC: 0.8644
Epoch 4 Global_step 342000	Train_loss: 0.3853	Eval_AUC: 0.8649
Epoch 4 Global_step 343000	Train_loss: 0.3861	Eval_AUC: 0.8685
model saved at save_path/atrank-343000
Epoch 4 Global_step 344000	Train_loss: 0.3859	Eval_AUC: 0.8667
Epoch 4 Global_step 345000	Train_loss: 0.3874	Eval_AUC: 0.8677
Epoch 4 Global_step 346000	Train_loss: 0.3901	Eval_AUC: 0.8658
Epoch 4 Global_step 347000	Train_loss: 0.3878	Eval_AUC: 0.8680
Epoch 4 Global_step 348000	Train_loss: 0.3863	Eval_AUC: 0.8671
Epoch 4 Global_step 349000	Train_loss: 0.3838	Eval_AUC: 0.8682
Epoch 4 Global_step 350000	Train_loss: 0.3792	Eval_AUC: 0.8707
model saved at save_path/atrank-350000
Epoch 4 Global_step 351000	Train_loss: 0.3844	Eval_AUC: 0.8701
Epoch 4 Global_step 352000	Train_loss: 0.3844	Eval_AUC: 0.8697
Epoch 4 Global_step 353000	Train_loss: 0.3834	Eval_AUC: 0.8682
Epoch 4 Global_step 354000	Train_loss: 0.3871	Eval_AUC: 0.8695
Epoch 4 Global_step 355000	Train_loss: 0.3845	Eval_AUC: 0.8653
Epoch 4 Global_step 356000	Train_loss: 0.3873	Eval_AUC: 0.8677
Epoch 4 Global_step 357000	Train_loss: 0.3854	Eval_AUC: 0.8695
Epoch 4 Global_step 358000	Train_loss: 0.3826	Eval_AUC: 0.8727
model saved at save_path/atrank-358000
Epoch 4 Global_step 359000	Train_loss: 0.3767	Eval_AUC: 0.8709
Epoch 4 Global_step 360000	Train_loss: 0.3808	Eval_AUC: 0.8701
Epoch 4 Global_step 361000	Train_loss: 0.3834	Eval_AUC: 0.8703
Epoch 4 Global_step 362000	Train_loss: 0.3814	Eval_AUC: 0.8724
Epoch 4 Global_step 363000	Train_loss: 0.3788	Eval_AUC: 0.8700
Epoch 4 Global_step 364000	Train_loss: 0.3813	Eval_AUC: 0.8681
Epoch 4 Global_step 365000	Train_loss: 0.3829	Eval_AUC: 0.8706
Epoch 4 Global_step 366000	Train_loss: 0.3825	Eval_AUC: 0.8724
Epoch 4 Global_step 367000	Train_loss: 0.3754	Eval_AUC: 0.8728
model saved at save_path/atrank-367000
Epoch 4 Global_step 368000	Train_loss: 0.3821	Eval_AUC: 0.8709
Epoch 4 Global_step 369000	Train_loss: 0.3820	Eval_AUC: 0.8693
Epoch 4 Global_step 370000	Train_loss: 0.3797	Eval_AUC: 0.8692
Epoch 4 Global_step 371000	Train_loss: 0.3784	Eval_AUC: 0.8703
Epoch 4 Global_step 372000	Train_loss: 0.3787	Eval_AUC: 0.8726
Epoch 4 Global_step 373000	Train_loss: 0.3773	Eval_AUC: 0.8679
Epoch 4 Global_step 374000	Train_loss: 0.3833	Eval_AUC: 0.8694
Epoch 4 Global_step 375000	Train_loss: 0.3796	Eval_AUC: 0.8728
model saved at save_path/atrank-375000
Epoch 4 Global_step 376000	Train_loss: 0.3794	Eval_AUC: 0.8701
Epoch 4 Global_step 377000	Train_loss: 0.3804	Eval_AUC: 0.8719
Epoch 4 Global_step 378000	Train_loss: 0.3790	Eval_AUC: 0.8700
Epoch 4 Global_step 379000	Train_loss: 0.3786	Eval_AUC: 0.8738
model saved at save_path/atrank-379000
Epoch 4 Global_step 380000	Train_loss: 0.3771	Eval_AUC: 0.8752
model saved at save_path/atrank-380000
Epoch 4 Global_step 381000	Train_loss: 0.3822	Eval_AUC: 0.8761
model saved at save_path/atrank-381000
Epoch 4 Global_step 382000	Train_loss: 0.3763	Eval_AUC: 0.8736
Epoch 4 Global_step 383000	Train_loss: 0.3840	Eval_AUC: 0.8744
Epoch 4 Global_step 384000	Train_loss: 0.3773	Eval_AUC: 0.8679
Epoch 4 Global_step 385000	Train_loss: 0.3839	Eval_AUC: 0.8717
Epoch 4 Global_step 386000	Train_loss: 0.3772	Eval_AUC: 0.8715
Epoch 4 Global_step 387000	Train_loss: 0.3832	Eval_AUC: 0.8737
Epoch 4 Global_step 388000	Train_loss: 0.3797	Eval_AUC: 0.8738
Epoch 4 Global_step 389000	Train_loss: 0.3670	Eval_AUC: 0.8721
Epoch 4 Global_step 390000	Train_loss: 0.3831	Eval_AUC: 0.8752
Epoch 4 Global_step 391000	Train_loss: 0.3777	Eval_AUC: 0.8748
Epoch 4 Global_step 392000	Train_loss: 0.3809	Eval_AUC: 0.8732
Epoch 4 Global_step 393000	Train_loss: 0.3807	Eval_AUC: 0.8758
Epoch 4 Global_step 394000	Train_loss: 0.3814	Eval_AUC: 0.8753
Epoch 4 Global_step 395000	Train_loss: 0.3780	Eval_AUC: 0.8726
Epoch 4 Global_step 396000	Train_loss: 0.3788	Eval_AUC: 0.8753
Epoch 4 Global_step 397000	Train_loss: 0.3857	Eval_AUC: 0.8728
Epoch 4 Global_step 398000	Train_loss: 0.3766	Eval_AUC: 0.8736
Epoch 4 Global_step 399000	Train_loss: 0.3752	Eval_AUC: 0.8728
Epoch 4 Global_step 400000	Train_loss: 0.3851	Eval_AUC: 0.8750
Epoch 4 Global_step 401000	Train_loss: 0.3816	Eval_AUC: 0.8704
Epoch 4 Global_step 402000	Train_loss: 0.3764	Eval_AUC: 0.8751
Epoch 4 Global_step 403000	Train_loss: 0.3827	Eval_AUC: 0.8747
Epoch 4 Global_step 404000	Train_loss: 0.3799	Eval_AUC: 0.8769
model saved at save_path/atrank-404000
Epoch 4 Global_step 405000	Train_loss: 0.3750	Eval_AUC: 0.8741
Epoch 4 Global_step 406000	Train_loss: 0.3757	Eval_AUC: 0.8714
Epoch 4 Global_step 407000	Train_loss: 0.3791	Eval_AUC: 0.8708
Epoch 4 DONE	Cost time: 41464.08
Epoch 5 Global_step 408000	Train_loss: 0.3753	Eval_AUC: 0.8778
model saved at save_path/atrank-408000
Epoch 5 Global_step 409000	Train_loss: 0.3653	Eval_AUC: 0.8708
Epoch 5 Global_step 410000	Train_loss: 0.3649	Eval_AUC: 0.8732
Epoch 5 Global_step 411000	Train_loss: 0.3642	Eval_AUC: 0.8722
Epoch 5 Global_step 412000	Train_loss: 0.3648	Eval_AUC: 0.8715
Epoch 5 Global_step 413000	Train_loss: 0.3641	Eval_AUC: 0.8749
Epoch 5 Global_step 414000	Train_loss: 0.3636	Eval_AUC: 0.8741
Epoch 5 Global_step 415000	Train_loss: 0.3636	Eval_AUC: 0.8730
Epoch 5 Global_step 416000	Train_loss: 0.3636	Eval_AUC: 0.8704
Epoch 5 Global_step 417000	Train_loss: 0.3663	Eval_AUC: 0.8715
Epoch 5 Global_step 418000	Train_loss: 0.3597	Eval_AUC: 0.8763
Epoch 5 Global_step 419000	Train_loss: 0.3603	Eval_AUC: 0.8746
Epoch 5 Global_step 420000	Train_loss: 0.3615	Eval_AUC: 0.8718
Epoch 5 Global_step 421000	Train_loss: 0.3644	Eval_AUC: 0.8753
Epoch 5 Global_step 422000	Train_loss: 0.3638	Eval_AUC: 0.8741
Epoch 5 Global_step 423000	Train_loss: 0.3635	Eval_AUC: 0.8740
Epoch 5 Global_step 424000	Train_loss: 0.3623	Eval_AUC: 0.8768
Epoch 5 Global_step 425000	Train_loss: 0.3654	Eval_AUC: 0.8721
Epoch 5 Global_step 426000	Train_loss: 0.3667	Eval_AUC: 0.8742
Epoch 5 Global_step 427000	Train_loss: 0.3619	Eval_AUC: 0.8745
Epoch 5 Global_step 428000	Train_loss: 0.3712	Eval_AUC: 0.8709
Epoch 5 Global_step 429000	Train_loss: 0.3648	Eval_AUC: 0.8734
Epoch 5 Global_step 430000	Train_loss: 0.3692	Eval_AUC: 0.8721
Epoch 5 Global_step 431000	Train_loss: 0.3635	Eval_AUC: 0.8766
Epoch 5 Global_step 432000	Train_loss: 0.3634	Eval_AUC: 0.8699
Epoch 5 Global_step 433000	Train_loss: 0.3701	Eval_AUC: 0.8765
Epoch 5 Global_step 434000	Train_loss: 0.3676	Eval_AUC: 0.8742
Epoch 5 Global_step 435000	Train_loss: 0.3630	Eval_AUC: 0.8732
Epoch 5 Global_step 436000	Train_loss: 0.3643	Eval_AUC: 0.8730
Epoch 5 Global_step 437000	Train_loss: 0.3630	Eval_AUC: 0.8764
Epoch 5 Global_step 438000	Train_loss: 0.3693	Eval_AUC: 0.8767
Epoch 5 Global_step 439000	Train_loss: 0.3662	Eval_AUC: 0.8722
Epoch 5 Global_step 440000	Train_loss: 0.3664	Eval_AUC: 0.8773
Epoch 5 Global_step 441000	Train_loss: 0.3650	Eval_AUC: 0.8723
Epoch 5 Global_step 442000	Train_loss: 0.3645	Eval_AUC: 0.8738
Epoch 5 Global_step 443000	Train_loss: 0.3655	Eval_AUC: 0.8688
Epoch 5 Global_step 444000	Train_loss: 0.3688	Eval_AUC: 0.8734
Epoch 5 Global_step 445000	Train_loss: 0.3681	Eval_AUC: 0.8719
Epoch 5 Global_step 446000	Train_loss: 0.3661	Eval_AUC: 0.8762
Epoch 5 Global_step 447000	Train_loss: 0.3649	Eval_AUC: 0.8737
Epoch 5 Global_step 448000	Train_loss: 0.3616	Eval_AUC: 0.8744
Epoch 5 Global_step 449000	Train_loss: 0.3678	Eval_AUC: 0.8758
Epoch 5 Global_step 450000	Train_loss: 0.3690	Eval_AUC: 0.8726
Epoch 5 Global_step 451000	Train_loss: 0.3600	Eval_AUC: 0.8718
Epoch 5 Global_step 452000	Train_loss: 0.3643	Eval_AUC: 0.8766
Epoch 5 Global_step 453000	Train_loss: 0.3691	Eval_AUC: 0.8747
Epoch 5 Global_step 454000	Train_loss: 0.3685	Eval_AUC: 0.8735
Epoch 5 Global_step 455000	Train_loss: 0.3660	Eval_AUC: 0.8753
Epoch 5 Global_step 456000	Train_loss: 0.3683	Eval_AUC: 0.8742
Epoch 5 Global_step 457000	Train_loss: 0.3690	Eval_AUC: 0.8713
Epoch 5 Global_step 458000	Train_loss: 0.3664	Eval_AUC: 0.8755
Epoch 5 Global_step 459000	Train_loss: 0.3647	Eval_AUC: 0.8735
Epoch 5 Global_step 460000	Train_loss: 0.3667	Eval_AUC: 0.8695
Epoch 5 Global_step 461000	Train_loss: 0.3620	Eval_AUC: 0.8768
Epoch 5 Global_step 462000	Train_loss: 0.3651	Eval_AUC: 0.8761
Epoch 5 Global_step 463000	Train_loss: 0.3701	Eval_AUC: 0.8764
Epoch 5 Global_step 464000	Train_loss: 0.3638	Eval_AUC: 0.8736
Epoch 5 Global_step 465000	Train_loss: 0.3647	Eval_AUC: 0.8752
Epoch 5 Global_step 466000	Train_loss: 0.3650	Eval_AUC: 0.8765
Epoch 5 Global_step 467000	Train_loss: 0.3665	Eval_AUC: 0.8743
Epoch 5 Global_step 468000	Train_loss: 0.3609	Eval_AUC: 0.8716
Epoch 5 Global_step 469000	Train_loss: 0.3655	Eval_AUC: 0.8735
Epoch 5 Global_step 470000	Train_loss: 0.3662	Eval_AUC: 0.8742
Epoch 5 Global_step 471000	Train_loss: 0.3657	Eval_AUC: 0.8745
Epoch 5 Global_step 472000	Train_loss: 0.3661	Eval_AUC: 0.8749
Epoch 5 Global_step 473000	Train_loss: 0.3670	Eval_AUC: 0.8725
Epoch 5 Global_step 474000	Train_loss: 0.3671	Eval_AUC: 0.8747
Epoch 5 Global_step 475000	Train_loss: 0.3642	Eval_AUC: 0.8790
model saved at save_path/atrank-475000
Epoch 5 Global_step 476000	Train_loss: 0.3674	Eval_AUC: 0.8728
Epoch 5 Global_step 477000	Train_loss: 0.3663	Eval_AUC: 0.8767
Epoch 5 Global_step 478000	Train_loss: 0.3624	Eval_AUC: 0.8783
Epoch 5 Global_step 479000	Train_loss: 0.3646	Eval_AUC: 0.8731
Epoch 5 Global_step 480000	Train_loss: 0.3611	Eval_AUC: 0.8747
Epoch 5 Global_step 481000	Train_loss: 0.3681	Eval_AUC: 0.8751
Epoch 5 Global_step 482000	Train_loss: 0.3700	Eval_AUC: 0.8753
Epoch 5 Global_step 483000	Train_loss: 0.3683	Eval_AUC: 0.8764
Epoch 5 Global_step 484000	Train_loss: 0.3683	Eval_AUC: 0.8741
Epoch 5 Global_step 485000	Train_loss: 0.3660	Eval_AUC: 0.8690
Epoch 5 Global_step 486000	Train_loss: 0.3611	Eval_AUC: 0.8745
Epoch 5 Global_step 487000	Train_loss: 0.3685	Eval_AUC: 0.8742
Epoch 5 Global_step 488000	Train_loss: 0.3705	Eval_AUC: 0.8745
Epoch 5 Global_step 489000	Train_loss: 0.3662	Eval_AUC: 0.8765
Epoch 5 DONE	Cost time: 49899.80
Epoch 6 Global_step 490000	Train_loss: 0.3578	Eval_AUC: 0.8781
Epoch 6 Global_step 491000	Train_loss: 0.3566	Eval_AUC: 0.8743
Epoch 6 Global_step 492000	Train_loss: 0.3529	Eval_AUC: 0.8747
Epoch 6 Global_step 493000	Train_loss: 0.3559	Eval_AUC: 0.8723
Epoch 6 Global_step 494000	Train_loss: 0.3575	Eval_AUC: 0.8745
Epoch 6 Global_step 495000	Train_loss: 0.3559	Eval_AUC: 0.8748
Epoch 6 Global_step 496000	Train_loss: 0.3567	Eval_AUC: 0.8805
model saved at save_path/atrank-496000
Epoch 6 Global_step 497000	Train_loss: 0.3557	Eval_AUC: 0.8728
Epoch 6 Global_step 498000	Train_loss: 0.3567	Eval_AUC: 0.8749
Epoch 6 Global_step 499000	Train_loss: 0.3572	Eval_AUC: 0.8712
Epoch 6 Global_step 500000	Train_loss: 0.3604	Eval_AUC: 0.8778
Epoch 6 Global_step 501000	Train_loss: 0.3555	Eval_AUC: 0.8745
Epoch 6 Global_step 502000	Train_loss: 0.3557	Eval_AUC: 0.8727
Epoch 6 Global_step 503000	Train_loss: 0.3581	Eval_AUC: 0.8687
Epoch 6 Global_step 504000	Train_loss: 0.3578	Eval_AUC: 0.8731
Epoch 6 Global_step 505000	Train_loss: 0.3556	Eval_AUC: 0.8748
Epoch 6 Global_step 506000	Train_loss: 0.3617	Eval_AUC: 0.8749
Epoch 6 Global_step 507000	Train_loss: 0.3593	Eval_AUC: 0.8747
Epoch 6 Global_step 508000	Train_loss: 0.3586	Eval_AUC: 0.8765
Epoch 6 Global_step 509000	Train_loss: 0.3578	Eval_AUC: 0.8750
Epoch 6 Global_step 510000	Train_loss: 0.3572	Eval_AUC: 0.8757
Epoch 6 Global_step 511000	Train_loss: 0.3580	Eval_AUC: 0.8738
Epoch 6 Global_step 512000	Train_loss: 0.3570	Eval_AUC: 0.8790
Epoch 6 Global_step 513000	Train_loss: 0.3629	Eval_AUC: 0.8736
Epoch 6 Global_step 514000	Train_loss: 0.3565	Eval_AUC: 0.8740
Epoch 6 Global_step 515000	Train_loss: 0.3553	Eval_AUC: 0.8727
Epoch 6 Global_step 516000	Train_loss: 0.3520	Eval_AUC: 0.8756
Epoch 6 Global_step 517000	Train_loss: 0.3563	Eval_AUC: 0.8725
Epoch 6 Global_step 518000	Train_loss: 0.3567	Eval_AUC: 0.8789
Epoch 6 Global_step 519000	Train_loss: 0.3553	Eval_AUC: 0.8735
Epoch 6 Global_step 520000	Train_loss: 0.3607	Eval_AUC: 0.8744
Epoch 6 Global_step 521000	Train_loss: 0.3549	Eval_AUC: 0.8758
Epoch 6 Global_step 522000	Train_loss: 0.3572	Eval_AUC: 0.8749
Epoch 6 Global_step 523000	Train_loss: 0.3511	Eval_AUC: 0.8739
Epoch 6 Global_step 524000	Train_loss: 0.3541	Eval_AUC: 0.8722
Epoch 6 Global_step 525000	Train_loss: 0.3562	Eval_AUC: 0.8727
Epoch 6 Global_step 526000	Train_loss: 0.3570	Eval_AUC: 0.8741
Epoch 6 Global_step 527000	Train_loss: 0.3561	Eval_AUC: 0.8757
Epoch 6 Global_step 528000	Train_loss: 0.3553	Eval_AUC: 0.8772
Epoch 6 Global_step 529000	Train_loss: 0.3549	Eval_AUC: 0.8794
Epoch 6 Global_step 530000	Train_loss: 0.3567	Eval_AUC: 0.8770
Epoch 6 Global_step 531000	Train_loss: 0.3515	Eval_AUC: 0.8781
Epoch 6 Global_step 532000	Train_loss: 0.3588	Eval_AUC: 0.8730
Epoch 6 Global_step 533000	Train_loss: 0.3553	Eval_AUC: 0.8772
Epoch 6 Global_step 534000	Train_loss: 0.3623	Eval_AUC: 0.8740
Epoch 6 Global_step 535000	Train_loss: 0.3613	Eval_AUC: 0.8765
Epoch 6 Global_step 536000	Train_loss: 0.3569	Eval_AUC: 0.8764
Epoch 6 Global_step 537000	Train_loss: 0.3599	Eval_AUC: 0.8699
Epoch 6 Global_step 538000	Train_loss: 0.3607	Eval_AUC: 0.8746
Epoch 6 Global_step 539000	Train_loss: 0.3568	Eval_AUC: 0.8755
Epoch 6 Global_step 540000	Train_loss: 0.3577	Eval_AUC: 0.8760
Epoch 6 Global_step 541000	Train_loss: 0.3604	Eval_AUC: 0.8765
Epoch 6 Global_step 542000	Train_loss: 0.3540	Eval_AUC: 0.8755
Epoch 6 Global_step 543000	Train_loss: 0.3616	Eval_AUC: 0.8753
Epoch 6 Global_step 544000	Train_loss: 0.3595	Eval_AUC: 0.8700
Epoch 6 Global_step 545000	Train_loss: 0.3580	Eval_AUC: 0.8746
Epoch 6 Global_step 546000	Train_loss: 0.3611	Eval_AUC: 0.8769
Epoch 6 Global_step 547000	Train_loss: 0.3536	Eval_AUC: 0.8756
Epoch 6 Global_step 548000	Train_loss: 0.3658	Eval_AUC: 0.8753
Epoch 6 Global_step 549000	Train_loss: 0.3561	Eval_AUC: 0.8750
Epoch 6 Global_step 550000	Train_loss: 0.3640	Eval_AUC: 0.8726
Epoch 6 Global_step 551000	Train_loss: 0.3542	Eval_AUC: 0.8750
Epoch 6 Global_step 552000	Train_loss: 0.3564	Eval_AUC: 0.8783
Epoch 6 Global_step 553000	Train_loss: 0.3589	Eval_AUC: 0.8755
Epoch 6 Global_step 554000	Train_loss: 0.3621	Eval_AUC: 0.8780
Epoch 6 Global_step 555000	Train_loss: 0.3596	Eval_AUC: 0.8729
Epoch 6 Global_step 556000	Train_loss: 0.3557	Eval_AUC: 0.8753
Epoch 6 Global_step 557000	Train_loss: 0.3588	Eval_AUC: 0.8782
Epoch 6 Global_step 558000	Train_loss: 0.3584	Eval_AUC: 0.8791
Epoch 6 Global_step 559000	Train_loss: 0.3590	Eval_AUC: 0.8785
Epoch 6 Global_step 560000	Train_loss: 0.3574	Eval_AUC: 0.8756
Epoch 6 Global_step 561000	Train_loss: 0.3629	Eval_AUC: 0.8741
Epoch 6 Global_step 562000	Train_loss: 0.3627	Eval_AUC: 0.8749
Epoch 6 Global_step 563000	Train_loss: 0.3545	Eval_AUC: 0.8726
Epoch 6 Global_step 564000	Train_loss: 0.3571	Eval_AUC: 0.8744
Epoch 6 Global_step 565000	Train_loss: 0.3627	Eval_AUC: 0.8762
Epoch 6 Global_step 566000	Train_loss: 0.3567	Eval_AUC: 0.8775
Epoch 6 Global_step 567000	Train_loss: 0.3600	Eval_AUC: 0.8768
Epoch 6 Global_step 568000	Train_loss: 0.3600	Eval_AUC: 0.8750
Epoch 6 Global_step 569000	Train_loss: 0.3620	Eval_AUC: 0.8745
Epoch 6 Global_step 570000	Train_loss: 0.3623	Eval_AUC: 0.8789
Epoch 6 DONE	Cost time: 58269.68
Epoch 7 Global_step 571000	Train_loss: 0.3565	Eval_AUC: 0.8789
Epoch 7 Global_step 572000	Train_loss: 0.3500	Eval_AUC: 0.8742
Epoch 7 Global_step 573000	Train_loss: 0.3465	Eval_AUC: 0.8762
Epoch 7 Global_step 574000	Train_loss: 0.3484	Eval_AUC: 0.8768
Epoch 7 Global_step 575000	Train_loss: 0.3487	Eval_AUC: 0.8742
Epoch 7 Global_step 576000	Train_loss: 0.3475	Eval_AUC: 0.8769
Epoch 7 Global_step 577000	Train_loss: 0.3483	Eval_AUC: 0.8770
Epoch 7 Global_step 578000	Train_loss: 0.3451	Eval_AUC: 0.8758
Epoch 7 Global_step 579000	Train_loss: 0.3501	Eval_AUC: 0.8765
Epoch 7 Global_step 580000	Train_loss: 0.3480	Eval_AUC: 0.8732
Epoch 7 Global_step 581000	Train_loss: 0.3464	Eval_AUC: 0.8783
Epoch 7 Global_step 582000	Train_loss: 0.3481	Eval_AUC: 0.8818
model saved at save_path/atrank-582000
Epoch 7 Global_step 583000	Train_loss: 0.3480	Eval_AUC: 0.8761
Epoch 7 Global_step 584000	Train_loss: 0.3513	Eval_AUC: 0.8751
Epoch 7 Global_step 585000	Train_loss: 0.3450	Eval_AUC: 0.8783
Epoch 7 Global_step 586000	Train_loss: 0.3464	Eval_AUC: 0.8756
Epoch 7 Global_step 587000	Train_loss: 0.3531	Eval_AUC: 0.8777
Epoch 7 Global_step 588000	Train_loss: 0.3522	Eval_AUC: 0.8727
Epoch 7 Global_step 589000	Train_loss: 0.3520	Eval_AUC: 0.8777
Epoch 7 Global_step 590000	Train_loss: 0.3440	Eval_AUC: 0.8781
Epoch 7 Global_step 591000	Train_loss: 0.3522	Eval_AUC: 0.8768
Epoch 7 Global_step 592000	Train_loss: 0.3519	Eval_AUC: 0.8774
Epoch 7 Global_step 593000	Train_loss: 0.3517	Eval_AUC: 0.8783
Epoch 7 Global_step 594000	Train_loss: 0.3443	Eval_AUC: 0.8773
Epoch 7 Global_step 595000	Train_loss: 0.3477	Eval_AUC: 0.8766
Epoch 7 Global_step 596000	Train_loss: 0.3508	Eval_AUC: 0.8723
Epoch 7 Global_step 597000	Train_loss: 0.3516	Eval_AUC: 0.8764
Epoch 7 Global_step 598000	Train_loss: 0.3535	Eval_AUC: 0.8796
Epoch 7 Global_step 599000	Train_loss: 0.3489	Eval_AUC: 0.8732
Epoch 7 Global_step 600000	Train_loss: 0.3528	Eval_AUC: 0.8756
Epoch 7 Global_step 601000	Train_loss: 0.3486	Eval_AUC: 0.8783
Epoch 7 Global_step 602000	Train_loss: 0.3484	Eval_AUC: 0.8786
Epoch 7 Global_step 603000	Train_loss: 0.3504	Eval_AUC: 0.8769
Epoch 7 Global_step 604000	Train_loss: 0.3493	Eval_AUC: 0.8804
Epoch 7 Global_step 605000	Train_loss: 0.3477	Eval_AUC: 0.8773
Epoch 7 Global_step 606000	Train_loss: 0.3483	Eval_AUC: 0.8795
Epoch 7 Global_step 607000	Train_loss: 0.3484	Eval_AUC: 0.8735
Epoch 7 Global_step 608000	Train_loss: 0.3468	Eval_AUC: 0.8772
Epoch 7 Global_step 609000	Train_loss: 0.3513	Eval_AUC: 0.8754
Epoch 7 Global_step 610000	Train_loss: 0.3513	Eval_AUC: 0.8733
Epoch 7 Global_step 611000	Train_loss: 0.3509	Eval_AUC: 0.8760
Epoch 7 Global_step 612000	Train_loss: 0.3481	Eval_AUC: 0.8794
Epoch 7 Global_step 613000	Train_loss: 0.3526	Eval_AUC: 0.8781
Epoch 7 Global_step 614000	Train_loss: 0.3491	Eval_AUC: 0.8788
Epoch 7 Global_step 615000	Train_loss: 0.3499	Eval_AUC: 0.8747
Epoch 7 Global_step 616000	Train_loss: 0.3516	Eval_AUC: 0.8778
Epoch 7 Global_step 617000	Train_loss: 0.3507	Eval_AUC: 0.8752
Epoch 7 Global_step 618000	Train_loss: 0.3506	Eval_AUC: 0.8734
Epoch 7 Global_step 619000	Train_loss: 0.3489	Eval_AUC: 0.8761
Epoch 7 Global_step 620000	Train_loss: 0.3546	Eval_AUC: 0.8733
Epoch 7 Global_step 621000	Train_loss: 0.3500	Eval_AUC: 0.8785
Epoch 7 Global_step 622000	Train_loss: 0.3470	Eval_AUC: 0.8732
Epoch 7 Global_step 623000	Train_loss: 0.3503	Eval_AUC: 0.8762
Epoch 7 Global_step 624000	Train_loss: 0.3544	Eval_AUC: 0.8761
Epoch 7 Global_step 625000	Train_loss: 0.3549	Eval_AUC: 0.8751
Epoch 7 Global_step 626000	Train_loss: 0.3505	Eval_AUC: 0.8763
Epoch 7 Global_step 627000	Train_loss: 0.3555	Eval_AUC: 0.8767
Epoch 7 Global_step 628000	Train_loss: 0.3524	Eval_AUC: 0.8763
Epoch 7 Global_step 629000	Train_loss: 0.3535	Eval_AUC: 0.8764
Epoch 7 Global_step 630000	Train_loss: 0.3485	Eval_AUC: 0.8778
Epoch 7 Global_step 631000	Train_loss: 0.3486	Eval_AUC: 0.8785
Epoch 7 Global_step 632000	Train_loss: 0.3486	Eval_AUC: 0.8772
Epoch 7 Global_step 633000	Train_loss: 0.3528	Eval_AUC: 0.8744
Epoch 7 Global_step 634000	Train_loss: 0.3486	Eval_AUC: 0.8760
Epoch 7 Global_step 635000	Train_loss: 0.3507	Eval_AUC: 0.8758
Epoch 7 Global_step 636000	Train_loss: 0.3547	Eval_AUC: 0.8736
Epoch 7 Global_step 637000	Train_loss: 0.3576	Eval_AUC: 0.8775
Epoch 7 Global_step 638000	Train_loss: 0.3517	Eval_AUC: 0.8766
Epoch 7 Global_step 639000	Train_loss: 0.3531	Eval_AUC: 0.8747
Epoch 7 Global_step 640000	Train_loss: 0.3535	Eval_AUC: 0.8782
Epoch 7 Global_step 641000	Train_loss: 0.3514	Eval_AUC: 0.8772
Epoch 7 Global_step 642000	Train_loss: 0.3549	Eval_AUC: 0.8795
Epoch 7 Global_step 643000	Train_loss: 0.3532	Eval_AUC: 0.8728
Epoch 7 Global_step 644000	Train_loss: 0.3561	Eval_AUC: 0.8793
Epoch 7 Global_step 645000	Train_loss: 0.3539	Eval_AUC: 0.8766
Epoch 7 Global_step 646000	Train_loss: 0.3515	Eval_AUC: 0.8781
Epoch 7 Global_step 647000	Train_loss: 0.3516	Eval_AUC: 0.8805
Epoch 7 Global_step 648000	Train_loss: 0.3485	Eval_AUC: 0.8776
Epoch 7 Global_step 649000	Train_loss: 0.3525	Eval_AUC: 0.8709
Epoch 7 Global_step 650000	Train_loss: 0.3498	Eval_AUC: 0.8736
Epoch 7 Global_step 651000	Train_loss: 0.3485	Eval_AUC: 0.8790
Epoch 7 Global_step 652000	Train_loss: 0.3549	Eval_AUC: 0.8785
Epoch 7 DONE	Cost time: 66680.51
Epoch 8 Global_step 653000	Train_loss: 0.3375	Eval_AUC: 0.8796
Epoch 8 Global_step 654000	Train_loss: 0.3415	Eval_AUC: 0.8761
Epoch 8 Global_step 655000	Train_loss: 0.3435	Eval_AUC: 0.8744
Epoch 8 Global_step 656000	Train_loss: 0.3374	Eval_AUC: 0.8758
Epoch 8 Global_step 657000	Train_loss: 0.3388	Eval_AUC: 0.8803
Epoch 8 Global_step 658000	Train_loss: 0.3446	Eval_AUC: 0.8795
Epoch 8 Global_step 659000	Train_loss: 0.3442	Eval_AUC: 0.8777
Epoch 8 Global_step 660000	Train_loss: 0.3351	Eval_AUC: 0.8767
Epoch 8 Global_step 661000	Train_loss: 0.3348	Eval_AUC: 0.8776
Epoch 8 Global_step 662000	Train_loss: 0.3368	Eval_AUC: 0.8742
Epoch 8 Global_step 663000	Train_loss: 0.3431	Eval_AUC: 0.8759
Epoch 8 Global_step 664000	Train_loss: 0.3371	Eval_AUC: 0.8770
Epoch 8 Global_step 665000	Train_loss: 0.3429	Eval_AUC: 0.8770
Epoch 8 Global_step 666000	Train_loss: 0.3379	Eval_AUC: 0.8772
Epoch 8 Global_step 667000	Train_loss: 0.3426	Eval_AUC: 0.8769
Epoch 8 Global_step 668000	Train_loss: 0.3373	Eval_AUC: 0.8753
Epoch 8 Global_step 669000	Train_loss: 0.3415	Eval_AUC: 0.8763
Epoch 8 Global_step 670000	Train_loss: 0.3382	Eval_AUC: 0.8768
Epoch 8 Global_step 671000	Train_loss: 0.3360	Eval_AUC: 0.8723
Epoch 8 Global_step 672000	Train_loss: 0.3405	Eval_AUC: 0.8796
Epoch 8 Global_step 673000	Train_loss: 0.3416	Eval_AUC: 0.8774
Epoch 8 Global_step 674000	Train_loss: 0.3412	Eval_AUC: 0.8766
Epoch 8 Global_step 675000	Train_loss: 0.3443	Eval_AUC: 0.8741
Epoch 8 Global_step 676000	Train_loss: 0.3451	Eval_AUC: 0.8789
Epoch 8 Global_step 677000	Train_loss: 0.3398	Eval_AUC: 0.8752
Epoch 8 Global_step 678000	Train_loss: 0.3435	Eval_AUC: 0.8716
Epoch 8 Global_step 679000	Train_loss: 0.3415	Eval_AUC: 0.8783
Epoch 8 Global_step 680000	Train_loss: 0.3375	Eval_AUC: 0.8780
Epoch 8 Global_step 681000	Train_loss: 0.3391	Eval_AUC: 0.8781
Epoch 8 Global_step 682000	Train_loss: 0.3462	Eval_AUC: 0.8738
Epoch 8 Global_step 683000	Train_loss: 0.3430	Eval_AUC: 0.8764
Epoch 8 Global_step 684000	Train_loss: 0.3486	Eval_AUC: 0.8759
Epoch 8 Global_step 685000	Train_loss: 0.3398	Eval_AUC: 0.8724
Epoch 8 Global_step 686000	Train_loss: 0.3436	Eval_AUC: 0.8748
Epoch 8 Global_step 687000	Train_loss: 0.3445	Eval_AUC: 0.8769
Epoch 8 Global_step 688000	Train_loss: 0.3458	Eval_AUC: 0.8758
Epoch 8 Global_step 689000	Train_loss: 0.3384	Eval_AUC: 0.8753
Epoch 8 Global_step 690000	Train_loss: 0.3433	Eval_AUC: 0.8766
Epoch 8 Global_step 691000	Train_loss: 0.3415	Eval_AUC: 0.8772
Epoch 8 Global_step 692000	Train_loss: 0.3385	Eval_AUC: 0.8776
Epoch 8 Global_step 693000	Train_loss: 0.3465	Eval_AUC: 0.8747
Epoch 8 Global_step 694000	Train_loss: 0.3453	Eval_AUC: 0.8759
Epoch 8 Global_step 695000	Train_loss: 0.3441	Eval_AUC: 0.8734
Epoch 8 Global_step 696000	Train_loss: 0.3445	Eval_AUC: 0.8784
Epoch 8 Global_step 697000	Train_loss: 0.3471	Eval_AUC: 0.8764
Epoch 8 Global_step 698000	Train_loss: 0.3436	Eval_AUC: 0.8784
Epoch 8 Global_step 699000	Train_loss: 0.3441	Eval_AUC: 0.8763
Epoch 8 Global_step 700000	Train_loss: 0.3449	Eval_AUC: 0.8777
Epoch 8 Global_step 701000	Train_loss: 0.3409	Eval_AUC: 0.8783
Epoch 8 Global_step 702000	Train_loss: 0.3450	Eval_AUC: 0.8744
Epoch 8 Global_step 703000	Train_loss: 0.3417	Eval_AUC: 0.8772
Epoch 8 Global_step 704000	Train_loss: 0.3489	Eval_AUC: 0.8770
Epoch 8 Global_step 705000	Train_loss: 0.3448	Eval_AUC: 0.8764
Epoch 8 Global_step 706000	Train_loss: 0.3439	Eval_AUC: 0.8752
Epoch 8 Global_step 707000	Train_loss: 0.3431	Eval_AUC: 0.8758
Epoch 8 Global_step 708000	Train_loss: 0.3408	Eval_AUC: 0.8779
Epoch 8 Global_step 709000	Train_loss: 0.3430	Eval_AUC: 0.8776
Epoch 8 Global_step 710000	Train_loss: 0.3402	Eval_AUC: 0.8741
Epoch 8 Global_step 711000	Train_loss: 0.3461	Eval_AUC: 0.8745
Epoch 8 Global_step 712000	Train_loss: 0.3426	Eval_AUC: 0.8786
Epoch 8 Global_step 713000	Train_loss: 0.3525	Eval_AUC: 0.8785
Epoch 8 Global_step 714000	Train_loss: 0.3439	Eval_AUC: 0.8742
Epoch 8 Global_step 715000	Train_loss: 0.3421	Eval_AUC: 0.8796
Epoch 8 Global_step 716000	Train_loss: 0.3456	Eval_AUC: 0.8783
Epoch 8 Global_step 717000	Train_loss: 0.3419	Eval_AUC: 0.8738
Epoch 8 Global_step 718000	Train_loss: 0.3452	Eval_AUC: 0.8785
Epoch 8 Global_step 719000	Train_loss: 0.3485	Eval_AUC: 0.8779
Epoch 8 Global_step 720000	Train_loss: 0.3456	Eval_AUC: 0.8803
Epoch 8 Global_step 721000	Train_loss: 0.3464	Eval_AUC: 0.8772
Epoch 8 Global_step 722000	Train_loss: 0.3453	Eval_AUC: 0.8732
Epoch 8 Global_step 723000	Train_loss: 0.3469	Eval_AUC: 0.8790
Epoch 8 Global_step 724000	Train_loss: 0.3440	Eval_AUC: 0.8777
Epoch 8 Global_step 725000	Train_loss: 0.3432	Eval_AUC: 0.8768
Epoch 8 Global_step 726000	Train_loss: 0.3475	Eval_AUC: 0.8761
Epoch 8 Global_step 727000	Train_loss: 0.3432	Eval_AUC: 0.8784
Epoch 8 Global_step 728000	Train_loss: 0.3471	Eval_AUC: 0.8724
Epoch 8 Global_step 729000	Train_loss: 0.3490	Eval_AUC: 0.8775
Epoch 8 Global_step 730000	Train_loss: 0.3448	Eval_AUC: 0.8792
Epoch 8 Global_step 731000	Train_loss: 0.3477	Eval_AUC: 0.8750
Epoch 8 Global_step 732000	Train_loss: 0.3432	Eval_AUC: 0.8791
Epoch 8 Global_step 733000	Train_loss: 0.3477	Eval_AUC: 0.8783
Epoch 8 DONE	Cost time: 75018.96
Epoch 9 Global_step 734000	Train_loss: 0.3428	Eval_AUC: 0.8776
Epoch 9 Global_step 735000	Train_loss: 0.3289	Eval_AUC: 0.8758
Epoch 9 Global_step 736000	Train_loss: 0.3263	Eval_AUC: 0.8763
Epoch 9 Global_step 737000	Train_loss: 0.3301	Eval_AUC: 0.8762
Epoch 9 Global_step 738000	Train_loss: 0.3273	Eval_AUC: 0.8765
Epoch 9 Global_step 739000	Train_loss: 0.3316	Eval_AUC: 0.8764
Epoch 9 Global_step 740000	Train_loss: 0.3289	Eval_AUC: 0.8728
Epoch 9 Global_step 741000	Train_loss: 0.3295	Eval_AUC: 0.8752
Epoch 9 Global_step 742000	Train_loss: 0.3327	Eval_AUC: 0.8775
Epoch 9 Global_step 743000	Train_loss: 0.3308	Eval_AUC: 0.8752
Epoch 9 Global_step 744000	Train_loss: 0.3348	Eval_AUC: 0.8745
Epoch 9 Global_step 745000	Train_loss: 0.3305	Eval_AUC: 0.8747
Epoch 9 Global_step 746000	Train_loss: 0.3325	Eval_AUC: 0.8773
Epoch 9 Global_step 747000	Train_loss: 0.3355	Eval_AUC: 0.8764
Epoch 9 Global_step 748000	Train_loss: 0.3312	Eval_AUC: 0.8772
Epoch 9 Global_step 749000	Train_loss: 0.3301	Eval_AUC: 0.8766
Epoch 9 Global_step 750000	Train_loss: 0.3329	Eval_AUC: 0.8734
Epoch 9 Global_step 751000	Train_loss: 0.3307	Eval_AUC: 0.8724
Epoch 9 Global_step 752000	Train_loss: 0.3351	Eval_AUC: 0.8738
Epoch 9 Global_step 753000	Train_loss: 0.3289	Eval_AUC: 0.8759
Epoch 9 Global_step 754000	Train_loss: 0.3329	Eval_AUC: 0.8767
Epoch 9 Global_step 755000	Train_loss: 0.3331	Eval_AUC: 0.8741
Epoch 9 Global_step 756000	Train_loss: 0.3320	Eval_AUC: 0.8755
Epoch 9 Global_step 757000	Train_loss: 0.3290	Eval_AUC: 0.8730
Epoch 9 Global_step 758000	Train_loss: 0.3320	Eval_AUC: 0.8758
Epoch 9 Global_step 759000	Train_loss: 0.3369	Eval_AUC: 0.8758
Epoch 9 Global_step 760000	Train_loss: 0.3334	Eval_AUC: 0.8739
Epoch 9 Global_step 761000	Train_loss: 0.3315	Eval_AUC: 0.8767
Epoch 9 Global_step 762000	Train_loss: 0.3320	Eval_AUC: 0.8767
Epoch 9 Global_step 763000	Train_loss: 0.3358	Eval_AUC: 0.8712
Epoch 9 Global_step 764000	Train_loss: 0.3322	Eval_AUC: 0.8761
Epoch 9 Global_step 765000	Train_loss: 0.3315	Eval_AUC: 0.8777
Epoch 9 Global_step 766000	Train_loss: 0.3368	Eval_AUC: 0.8790
Epoch 9 Global_step 767000	Train_loss: 0.3364	Eval_AUC: 0.8785
Epoch 9 Global_step 768000	Train_loss: 0.3326	Eval_AUC: 0.8756
Epoch 9 Global_step 769000	Train_loss: 0.3386	Eval_AUC: 0.8730
Epoch 9 Global_step 770000	Train_loss: 0.3376	Eval_AUC: 0.8798
Epoch 9 Global_step 771000	Train_loss: 0.3361	Eval_AUC: 0.8773
Epoch 9 Global_step 772000	Train_loss: 0.3341	Eval_AUC: 0.8789
Epoch 9 Global_step 773000	Train_loss: 0.3366	Eval_AUC: 0.8776
Epoch 9 Global_step 774000	Train_loss: 0.3407	Eval_AUC: 0.8776
Epoch 9 Global_step 775000	Train_loss: 0.3391	Eval_AUC: 0.8755
Epoch 9 Global_step 776000	Train_loss: 0.3373	Eval_AUC: 0.8750
Epoch 9 Global_step 777000	Train_loss: 0.3370	Eval_AUC: 0.8764
Epoch 9 Global_step 778000	Train_loss: 0.3323	Eval_AUC: 0.8768
Epoch 9 Global_step 779000	Train_loss: 0.3323	Eval_AUC: 0.8754
Epoch 9 Global_step 780000	Train_loss: 0.3360	Eval_AUC: 0.8763
Epoch 9 Global_step 781000	Train_loss: 0.3343	Eval_AUC: 0.8773
Epoch 9 Global_step 782000	Train_loss: 0.3374	Eval_AUC: 0.8735
Epoch 9 Global_step 783000	Train_loss: 0.3376	Eval_AUC: 0.8776
Epoch 9 Global_step 784000	Train_loss: 0.3384	Eval_AUC: 0.8780
Epoch 9 Global_step 785000	Train_loss: 0.3377	Eval_AUC: 0.8766
Epoch 9 Global_step 786000	Train_loss: 0.3372	Eval_AUC: 0.8774
Epoch 9 Global_step 787000	Train_loss: 0.3406	Eval_AUC: 0.8769
Epoch 9 Global_step 788000	Train_loss: 0.3387	Eval_AUC: 0.8793
Epoch 9 Global_step 789000	Train_loss: 0.3385	Eval_AUC: 0.8740
Epoch 9 Global_step 790000	Train_loss: 0.3358	Eval_AUC: 0.8745
Epoch 9 Global_step 791000	Train_loss: 0.3401	Eval_AUC: 0.8778
Epoch 9 Global_step 792000	Train_loss: 0.3335	Eval_AUC: 0.8778
Epoch 9 Global_step 793000	Train_loss: 0.3421	Eval_AUC: 0.8751
Epoch 9 Global_step 794000	Train_loss: 0.3352	Eval_AUC: 0.8777
Epoch 9 Global_step 795000	Train_loss: 0.3402	Eval_AUC: 0.8791
Epoch 9 Global_step 796000	Train_loss: 0.3325	Eval_AUC: 0.8758
Epoch 9 Global_step 797000	Train_loss: 0.3412	Eval_AUC: 0.8803
Epoch 9 Global_step 798000	Train_loss: 0.3377	Eval_AUC: 0.8772
Epoch 9 Global_step 799000	Train_loss: 0.3383	Eval_AUC: 0.8781
Epoch 9 Global_step 800000	Train_loss: 0.3388	Eval_AUC: 0.8743
Epoch 9 Global_step 801000	Train_loss: 0.3340	Eval_AUC: 0.8784
Epoch 9 Global_step 802000	Train_loss: 0.3353	Eval_AUC: 0.8724
Epoch 9 Global_step 803000	Train_loss: 0.3382	Eval_AUC: 0.8780
Epoch 9 Global_step 804000	Train_loss: 0.3340	Eval_AUC: 0.8770
Epoch 9 Global_step 805000	Train_loss: 0.3383	Eval_AUC: 0.8777
Epoch 9 Global_step 806000	Train_loss: 0.3418	Eval_AUC: 0.8770
Epoch 9 Global_step 807000	Train_loss: 0.3416	Eval_AUC: 0.8790
Epoch 9 Global_step 808000	Train_loss: 0.3387	Eval_AUC: 0.8770
Epoch 9 Global_step 809000	Train_loss: 0.3413	Eval_AUC: 0.8765
Epoch 9 Global_step 810000	Train_loss: 0.3401	Eval_AUC: 0.8782
Epoch 9 Global_step 811000	Train_loss: 0.3450	Eval_AUC: 0.8794
Epoch 9 Global_step 812000	Train_loss: 0.3443	Eval_AUC: 0.8787
Epoch 9 Global_step 813000	Train_loss: 0.3387	Eval_AUC: 0.8770
Epoch 9 Global_step 814000	Train_loss: 0.3421	Eval_AUC: 0.8784
Epoch 9 Global_step 815000	Train_loss: 0.3381	Eval_AUC: 0.8738
Epoch 9 DONE	Cost time: 83428.95
Epoch 10 Global_step 816000	Train_loss: 0.3241	Eval_AUC: 0.8754
Epoch 10 Global_step 817000	Train_loss: 0.3226	Eval_AUC: 0.8759
Epoch 10 Global_step 818000	Train_loss: 0.3211	Eval_AUC: 0.8747
Epoch 10 Global_step 819000	Train_loss: 0.3238	Eval_AUC: 0.8754
Epoch 10 Global_step 820000	Train_loss: 0.3174	Eval_AUC: 0.8729
Epoch 10 Global_step 821000	Train_loss: 0.3190	Eval_AUC: 0.8751
Epoch 10 Global_step 822000	Train_loss: 0.3195	Eval_AUC: 0.8768
Epoch 10 Global_step 823000	Train_loss: 0.3180	Eval_AUC: 0.8730
Epoch 10 Global_step 824000	Train_loss: 0.3231	Eval_AUC: 0.8766
Epoch 10 Global_step 825000	Train_loss: 0.3239	Eval_AUC: 0.8728
Epoch 10 Global_step 826000	Train_loss: 0.3230	Eval_AUC: 0.8762
Epoch 10 Global_step 827000	Train_loss: 0.3205	Eval_AUC: 0.8732
Epoch 10 Global_step 828000	Train_loss: 0.3217	Eval_AUC: 0.8731
Epoch 10 Global_step 829000	Train_loss: 0.3211	Eval_AUC: 0.8729
Epoch 10 Global_step 830000	Train_loss: 0.3224	Eval_AUC: 0.8765
Epoch 10 Global_step 831000	Train_loss: 0.3235	Eval_AUC: 0.8789
Epoch 10 Global_step 832000	Train_loss: 0.3225	Eval_AUC: 0.8766
Epoch 10 Global_step 833000	Train_loss: 0.3203	Eval_AUC: 0.8794
Epoch 10 Global_step 834000	Train_loss: 0.3214	Eval_AUC: 0.8762
Epoch 10 Global_step 835000	Train_loss: 0.3226	Eval_AUC: 0.8720
Epoch 10 Global_step 836000	Train_loss: 0.3220	Eval_AUC: 0.8733
Epoch 10 Global_step 837000	Train_loss: 0.3259	Eval_AUC: 0.8735
Epoch 10 Global_step 838000	Train_loss: 0.3248	Eval_AUC: 0.8718
Epoch 10 Global_step 839000	Train_loss: 0.3233	Eval_AUC: 0.8713
Epoch 10 Global_step 840000	Train_loss: 0.3255	Eval_AUC: 0.8735
Epoch 10 Global_step 841000	Train_loss: 0.3275	Eval_AUC: 0.8742
Epoch 10 Global_step 842000	Train_loss: 0.3263	Eval_AUC: 0.8749
Epoch 10 Global_step 843000	Train_loss: 0.3265	Eval_AUC: 0.8780
Epoch 10 Global_step 844000	Train_loss: 0.3233	Eval_AUC: 0.8745
Epoch 10 Global_step 845000	Train_loss: 0.3276	Eval_AUC: 0.8778
Epoch 10 Global_step 846000	Train_loss: 0.3270	Eval_AUC: 0.8763
Epoch 10 Global_step 847000	Train_loss: 0.3255	Eval_AUC: 0.8773
Epoch 10 Global_step 848000	Train_loss: 0.3256	Eval_AUC: 0.8746
Epoch 10 Global_step 849000	Train_loss: 0.3296	Eval_AUC: 0.8774
Epoch 10 Global_step 850000	Train_loss: 0.3296	Eval_AUC: 0.8794
Epoch 10 Global_step 851000	Train_loss: 0.3307	Eval_AUC: 0.8785
Epoch 10 Global_step 852000	Train_loss: 0.3287	Eval_AUC: 0.8705
Epoch 10 Global_step 853000	Train_loss: 0.3258	Eval_AUC: 0.8729
Epoch 10 Global_step 854000	Train_loss: 0.3317	Eval_AUC: 0.8766
Epoch 10 Global_step 855000	Train_loss: 0.3286	Eval_AUC: 0.8739
Epoch 10 Global_step 856000	Train_loss: 0.3284	Eval_AUC: 0.8771
Epoch 10 Global_step 857000	Train_loss: 0.3282	Eval_AUC: 0.8733
Epoch 10 Global_step 858000	Train_loss: 0.3275	Eval_AUC: 0.8707
Epoch 10 Global_step 859000	Train_loss: 0.3253	Eval_AUC: 0.8772
Epoch 10 Global_step 860000	Train_loss: 0.3200	Eval_AUC: 0.8778
Epoch 10 Global_step 861000	Train_loss: 0.3326	Eval_AUC: 0.8770
Epoch 10 Global_step 862000	Train_loss: 0.3306	Eval_AUC: 0.8799
Epoch 10 Global_step 863000	Train_loss: 0.3325	Eval_AUC: 0.8742
Epoch 10 Global_step 864000	Train_loss: 0.3273	Eval_AUC: 0.8775
Epoch 10 Global_step 865000	Train_loss: 0.3305	Eval_AUC: 0.8773
Epoch 10 Global_step 866000	Train_loss: 0.3298	Eval_AUC: 0.8780
Epoch 10 Global_step 867000	Train_loss: 0.3269	Eval_AUC: 0.8705
Epoch 10 Global_step 868000	Train_loss: 0.3318	Eval_AUC: 0.8734
Epoch 10 Global_step 869000	Train_loss: 0.3348	Eval_AUC: 0.8764
Epoch 10 Global_step 870000	Train_loss: 0.3316	Eval_AUC: 0.8765
Epoch 10 Global_step 871000	Train_loss: 0.3312	Eval_AUC: 0.8724
Epoch 10 Global_step 872000	Train_loss: 0.3283	Eval_AUC: 0.8776
Epoch 10 Global_step 873000	Train_loss: 0.3302	Eval_AUC: 0.8722
Epoch 10 Global_step 874000	Train_loss: 0.3325	Eval_AUC: 0.8788
Epoch 10 Global_step 875000	Train_loss: 0.3290	Eval_AUC: 0.8736
Epoch 10 Global_step 876000	Train_loss: 0.3309	Eval_AUC: 0.8775
Epoch 10 Global_step 877000	Train_loss: 0.3345	Eval_AUC: 0.8768
Epoch 10 Global_step 878000	Train_loss: 0.3345	Eval_AUC: 0.8773
Epoch 10 Global_step 879000	Train_loss: 0.3325	Eval_AUC: 0.8740
Epoch 10 Global_step 880000	Train_loss: 0.3277	Eval_AUC: 0.8719
Epoch 10 Global_step 881000	Train_loss: 0.3312	Eval_AUC: 0.8719
Epoch 10 Global_step 882000	Train_loss: 0.3312	Eval_AUC: 0.8776
Epoch 10 Global_step 883000	Train_loss: 0.3305	Eval_AUC: 0.8758
Epoch 10 Global_step 884000	Train_loss: 0.3344	Eval_AUC: 0.8725
Epoch 10 Global_step 885000	Train_loss: 0.3314	Eval_AUC: 0.8753
Epoch 10 Global_step 886000	Train_loss: 0.3320	Eval_AUC: 0.8780
Epoch 10 Global_step 887000	Train_loss: 0.3304	Eval_AUC: 0.8779
Epoch 10 Global_step 888000	Train_loss: 0.3341	Eval_AUC: 0.8769
Epoch 10 Global_step 889000	Train_loss: 0.3307	Eval_AUC: 0.8806
Epoch 10 Global_step 890000	Train_loss: 0.3301	Eval_AUC: 0.8744
Epoch 10 Global_step 891000	Train_loss: 0.3299	Eval_AUC: 0.8744
Epoch 10 Global_step 892000	Train_loss: 0.3321	Eval_AUC: 0.8791
Epoch 10 Global_step 893000	Train_loss: 0.3331	Eval_AUC: 0.8758
Epoch 10 Global_step 894000	Train_loss: 0.3386	Eval_AUC: 0.8771
Epoch 10 Global_step 895000	Train_loss: 0.3369	Eval_AUC: 0.8765
Epoch 10 Global_step 896000	Train_loss: 0.3332	Eval_AUC: 0.8772
Epoch 10 DONE	Cost time: 91766.80
Epoch 11 Global_step 897000	Train_loss: 0.3293	Eval_AUC: 0.8773
Epoch 11 Global_step 898000	Train_loss: 0.3160	Eval_AUC: 0.8743
Epoch 11 Global_step 899000	Train_loss: 0.3133	Eval_AUC: 0.8719
Epoch 11 Global_step 900000	Train_loss: 0.3121	Eval_AUC: 0.8775
Epoch 11 Global_step 901000	Train_loss: 0.3165	Eval_AUC: 0.8780
Epoch 11 Global_step 902000	Train_loss: 0.3139	Eval_AUC: 0.8766
Epoch 11 Global_step 903000	Train_loss: 0.3131	Eval_AUC: 0.8729
Epoch 11 Global_step 904000	Train_loss: 0.3140	Eval_AUC: 0.8754
Epoch 11 Global_step 905000	Train_loss: 0.3117	Eval_AUC: 0.8741
Epoch 11 Global_step 906000	Train_loss: 0.3152	Eval_AUC: 0.8724
Epoch 11 Global_step 907000	Train_loss: 0.3125	Eval_AUC: 0.8716
Epoch 11 Global_step 908000	Train_loss: 0.3156	Eval_AUC: 0.8725
Epoch 11 Global_step 909000	Train_loss: 0.3145	Eval_AUC: 0.8757
Epoch 11 Global_step 910000	Train_loss: 0.3118	Eval_AUC: 0.8726
Epoch 11 Global_step 911000	Train_loss: 0.3134	Eval_AUC: 0.8757
Epoch 11 Global_step 912000	Train_loss: 0.3177	Eval_AUC: 0.8740
Epoch 11 Global_step 913000	Train_loss: 0.3121	Eval_AUC: 0.8778
Epoch 11 Global_step 914000	Train_loss: 0.3111	Eval_AUC: 0.8751
Epoch 11 Global_step 915000	Train_loss: 0.3166	Eval_AUC: 0.8735
Epoch 11 Global_step 916000	Train_loss: 0.3136	Eval_AUC: 0.8749
Epoch 11 Global_step 917000	Train_loss: 0.3129	Eval_AUC: 0.8700
Epoch 11 Global_step 918000	Train_loss: 0.3185	Eval_AUC: 0.8773
Epoch 11 Global_step 919000	Train_loss: 0.3188	Eval_AUC: 0.8742
Epoch 11 Global_step 920000	Train_loss: 0.3187	Eval_AUC: 0.8743
Epoch 11 Global_step 921000	Train_loss: 0.3146	Eval_AUC: 0.8747
Epoch 11 Global_step 922000	Train_loss: 0.3106	Eval_AUC: 0.8777
Epoch 11 Global_step 923000	Train_loss: 0.3140	Eval_AUC: 0.8713
Epoch 11 Global_step 924000	Train_loss: 0.3136	Eval_AUC: 0.8759
Epoch 11 Global_step 925000	Train_loss: 0.3176	Eval_AUC: 0.8761
Epoch 11 Global_step 926000	Train_loss: 0.3207	Eval_AUC: 0.8758
Epoch 11 Global_step 927000	Train_loss: 0.3185	Eval_AUC: 0.8699
Epoch 11 Global_step 928000	Train_loss: 0.3144	Eval_AUC: 0.8755
Epoch 11 Global_step 929000	Train_loss: 0.3144	Eval_AUC: 0.8743
Epoch 11 Global_step 930000	Train_loss: 0.3168	Eval_AUC: 0.8750
Epoch 11 Global_step 931000	Train_loss: 0.3170	Eval_AUC: 0.8737
Epoch 11 Global_step 932000	Train_loss: 0.3196	Eval_AUC: 0.8749
Epoch 11 Global_step 933000	Train_loss: 0.3205	Eval_AUC: 0.8741
Epoch 11 Global_step 934000	Train_loss: 0.3182	Eval_AUC: 0.8725
Epoch 11 Global_step 935000	Train_loss: 0.3166	Eval_AUC: 0.8749
Epoch 11 Global_step 936000	Train_loss: 0.3209	Eval_AUC: 0.8764
Epoch 11 Global_step 937000	Train_loss: 0.3228	Eval_AUC: 0.8726
Epoch 11 Global_step 938000	Train_loss: 0.3231	Eval_AUC: 0.8733
Epoch 11 Global_step 939000	Train_loss: 0.3203	Eval_AUC: 0.8771
Epoch 11 Global_step 940000	Train_loss: 0.3190	Eval_AUC: 0.8732
Epoch 11 Global_step 941000	Train_loss: 0.3219	Eval_AUC: 0.8726
Epoch 11 Global_step 942000	Train_loss: 0.3217	Eval_AUC: 0.8761
Epoch 11 Global_step 943000	Train_loss: 0.3207	Eval_AUC: 0.8709
Epoch 11 Global_step 944000	Train_loss: 0.3225	Eval_AUC: 0.8769
Epoch 11 Global_step 945000	Train_loss: 0.3257	Eval_AUC: 0.8727
Epoch 11 Global_step 946000	Train_loss: 0.3184	Eval_AUC: 0.8751
Epoch 11 Global_step 947000	Train_loss: 0.3227	Eval_AUC: 0.8740
Epoch 11 Global_step 948000	Train_loss: 0.3229	Eval_AUC: 0.8764
Epoch 11 Global_step 949000	Train_loss: 0.3249	Eval_AUC: 0.8750
Epoch 11 Global_step 950000	Train_loss: 0.3200	Eval_AUC: 0.8699
Epoch 11 Global_step 951000	Train_loss: 0.3219	Eval_AUC: 0.8755
Epoch 11 Global_step 952000	Train_loss: 0.3223	Eval_AUC: 0.8762
Epoch 11 Global_step 953000	Train_loss: 0.3248	Eval_AUC: 0.8754
Epoch 11 Global_step 954000	Train_loss: 0.3237	Eval_AUC: 0.8713
Epoch 11 Global_step 955000	Train_loss: 0.3258	Eval_AUC: 0.8756
Epoch 11 Global_step 956000	Train_loss: 0.3246	Eval_AUC: 0.8752
Epoch 11 Global_step 957000	Train_loss: 0.3231	Eval_AUC: 0.8769
Epoch 11 Global_step 958000	Train_loss: 0.3258	Eval_AUC: 0.8735
Epoch 11 Global_step 959000	Train_loss: 0.3292	Eval_AUC: 0.8792
Epoch 11 Global_step 960000	Train_loss: 0.3236	Eval_AUC: 0.8783
Epoch 11 Global_step 961000	Train_loss: 0.3215	Eval_AUC: 0.8780
Epoch 11 Global_step 962000	Train_loss: 0.3224	Eval_AUC: 0.8754
Epoch 11 Global_step 963000	Train_loss: 0.3250	Eval_AUC: 0.8758
Epoch 11 Global_step 964000	Train_loss: 0.3229	Eval_AUC: 0.8789
Epoch 11 Global_step 965000	Train_loss: 0.3236	Eval_AUC: 0.8753
Epoch 11 Global_step 966000	Train_loss: 0.3240	Eval_AUC: 0.8753
Epoch 11 Global_step 967000	Train_loss: 0.3292	Eval_AUC: 0.8744
Epoch 11 Global_step 968000	Train_loss: 0.3223	Eval_AUC: 0.8725
Epoch 11 Global_step 969000	Train_loss: 0.3233	Eval_AUC: 0.8748
Epoch 11 Global_step 970000	Train_loss: 0.3245	Eval_AUC: 0.8748
Epoch 11 Global_step 971000	Train_loss: 0.3281	Eval_AUC: 0.8747
Epoch 11 Global_step 972000	Train_loss: 0.3270	Eval_AUC: 0.8718
Epoch 11 Global_step 973000	Train_loss: 0.3246	Eval_AUC: 0.8756
Epoch 11 Global_step 974000	Train_loss: 0.3296	Eval_AUC: 0.8761
Epoch 11 Global_step 975000	Train_loss: 0.3270	Eval_AUC: 0.8798
Epoch 11 Global_step 976000	Train_loss: 0.3281	Eval_AUC: 0.8772
Epoch 11 Global_step 977000	Train_loss: 0.3235	Eval_AUC: 0.8733
Epoch 11 Global_step 978000	Train_loss: 0.3273	Eval_AUC: 0.8748
Epoch 11 DONE	Cost time: 100173.21
Epoch 12 Global_step 979000	Train_loss: 0.3055	Eval_AUC: 0.8755
Epoch 12 Global_step 980000	Train_loss: 0.2998	Eval_AUC: 0.8767
Epoch 12 Global_step 981000	Train_loss: 0.2989	Eval_AUC: 0.8744
Epoch 12 Global_step 982000	Train_loss: 0.3022	Eval_AUC: 0.8736
Epoch 12 Global_step 983000	Train_loss: 0.3054	Eval_AUC: 0.8741
Epoch 12 Global_step 984000	Train_loss: 0.3007	Eval_AUC: 0.8769
Epoch 12 Global_step 985000	Train_loss: 0.3047	Eval_AUC: 0.8705
Epoch 12 Global_step 986000	Train_loss: 0.3028	Eval_AUC: 0.8772
Epoch 12 Global_step 987000	Train_loss: 0.3029	Eval_AUC: 0.8723
Epoch 12 Global_step 988000	Train_loss: 0.3059	Eval_AUC: 0.8759
Epoch 12 Global_step 989000	Train_loss: 0.3044	Eval_AUC: 0.8758
Epoch 12 Global_step 990000	Train_loss: 0.3058	Eval_AUC: 0.8712
Epoch 12 Global_step 991000	Train_loss: 0.3059	Eval_AUC: 0.8701
Epoch 12 Global_step 992000	Train_loss: 0.3071	Eval_AUC: 0.8716
Epoch 12 Global_step 993000	Train_loss: 0.3062	Eval_AUC: 0.8729
Epoch 12 Global_step 994000	Train_loss: 0.3031	Eval_AUC: 0.8689
Epoch 12 Global_step 995000	Train_loss: 0.3058	Eval_AUC: 0.8700
Epoch 12 Global_step 996000	Train_loss: 0.3021	Eval_AUC: 0.8769
Epoch 12 Global_step 997000	Train_loss: 0.3078	Eval_AUC: 0.8760
Epoch 12 Global_step 998000	Train_loss: 0.3119	Eval_AUC: 0.8740
Epoch 12 Global_step 999000	Train_loss: 0.3055	Eval_AUC: 0.8734
Epoch 12 Global_step 1000000	Train_loss: 0.3094	Eval_AUC: 0.8724
Epoch 12 Global_step 1001000	Train_loss: 0.3035	Eval_AUC: 0.8698
Epoch 12 Global_step 1002000	Train_loss: 0.3091	Eval_AUC: 0.8732
Epoch 12 Global_step 1003000	Train_loss: 0.3110	Eval_AUC: 0.8694
Epoch 12 Global_step 1004000	Train_loss: 0.3100	Eval_AUC: 0.8733
Epoch 12 Global_step 1005000	Train_loss: 0.3100	Eval_AUC: 0.8748
Epoch 12 Global_step 1006000	Train_loss: 0.3143	Eval_AUC: 0.8715
Epoch 12 Global_step 1007000	Train_loss: 0.3095	Eval_AUC: 0.8754
Epoch 12 Global_step 1008000	Train_loss: 0.3088	Eval_AUC: 0.8710
Epoch 12 Global_step 1009000	Train_loss: 0.3078	Eval_AUC: 0.8693
Epoch 12 Global_step 1010000	Train_loss: 0.3084	Eval_AUC: 0.8732
Epoch 12 Global_step 1011000	Train_loss: 0.3113	Eval_AUC: 0.8723
Epoch 12 Global_step 1012000	Train_loss: 0.3120	Eval_AUC: 0.8756
Epoch 12 Global_step 1013000	Train_loss: 0.3126	Eval_AUC: 0.8746
Epoch 12 Global_step 1014000	Train_loss: 0.3110	Eval_AUC: 0.8712
Epoch 12 Global_step 1015000	Train_loss: 0.3104	Eval_AUC: 0.8729
Epoch 12 Global_step 1016000	Train_loss: 0.3128	Eval_AUC: 0.8733
Epoch 12 Global_step 1017000	Train_loss: 0.3103	Eval_AUC: 0.8707
Epoch 12 Global_step 1018000	Train_loss: 0.3162	Eval_AUC: 0.8739
Epoch 12 Global_step 1019000	Train_loss: 0.3097	Eval_AUC: 0.8717
Epoch 12 Global_step 1020000	Train_loss: 0.3123	Eval_AUC: 0.8708
Epoch 12 Global_step 1021000	Train_loss: 0.3115	Eval_AUC: 0.8752
Epoch 12 Global_step 1022000	Train_loss: 0.3143	Eval_AUC: 0.8742
Epoch 12 Global_step 1023000	Train_loss: 0.3141	Eval_AUC: 0.8753
Epoch 12 Global_step 1024000	Train_loss: 0.3165	Eval_AUC: 0.8756
Epoch 12 Global_step 1025000	Train_loss: 0.3137	Eval_AUC: 0.8757
Epoch 12 Global_step 1026000	Train_loss: 0.3151	Eval_AUC: 0.8729
Epoch 12 Global_step 1027000	Train_loss: 0.3144	Eval_AUC: 0.8714
Epoch 12 Global_step 1028000	Train_loss: 0.3160	Eval_AUC: 0.8697
Epoch 12 Global_step 1029000	Train_loss: 0.3146	Eval_AUC: 0.8773
Epoch 12 Global_step 1030000	Train_loss: 0.3138	Eval_AUC: 0.8737
Epoch 12 Global_step 1031000	Train_loss: 0.3123	Eval_AUC: 0.8715
Epoch 12 Global_step 1032000	Train_loss: 0.3132	Eval_AUC: 0.8717
Epoch 12 Global_step 1033000	Train_loss: 0.3167	Eval_AUC: 0.8728
Epoch 12 Global_step 1034000	Train_loss: 0.3201	Eval_AUC: 0.8739
Epoch 12 Global_step 1035000	Train_loss: 0.3153	Eval_AUC: 0.8757
Epoch 12 Global_step 1036000	Train_loss: 0.3167	Eval_AUC: 0.8755
Epoch 12 Global_step 1037000	Train_loss: 0.3173	Eval_AUC: 0.8751
Epoch 12 Global_step 1038000	Train_loss: 0.3196	Eval_AUC: 0.8766
Epoch 12 Global_step 1039000	Train_loss: 0.3149	Eval_AUC: 0.8739
Epoch 12 Global_step 1040000	Train_loss: 0.3152	Eval_AUC: 0.8738
Epoch 12 Global_step 1041000	Train_loss: 0.3149	Eval_AUC: 0.8741
Epoch 12 Global_step 1042000	Train_loss: 0.3168	Eval_AUC: 0.8737
Epoch 12 Global_step 1043000	Train_loss: 0.3149	Eval_AUC: 0.8720
Epoch 12 Global_step 1044000	Train_loss: 0.3184	Eval_AUC: 0.8783
Epoch 12 Global_step 1045000	Train_loss: 0.3190	Eval_AUC: 0.8767
Epoch 12 Global_step 1046000	Train_loss: 0.3160	Eval_AUC: 0.8749
Epoch 12 Global_step 1047000	Train_loss: 0.3175	Eval_AUC: 0.8734
Epoch 12 Global_step 1048000	Train_loss: 0.3124	Eval_AUC: 0.8741
Epoch 12 Global_step 1049000	Train_loss: 0.3194	Eval_AUC: 0.8698
Epoch 12 Global_step 1050000	Train_loss: 0.3174	Eval_AUC: 0.8746
Epoch 12 Global_step 1051000	Train_loss: 0.3177	Eval_AUC: 0.8723
Epoch 12 Global_step 1052000	Train_loss: 0.3137	Eval_AUC: 0.8724
Epoch 12 Global_step 1053000	Train_loss: 0.3201	Eval_AUC: 0.8687
Epoch 12 Global_step 1054000	Train_loss: 0.3203	Eval_AUC: 0.8721
Epoch 12 Global_step 1055000	Train_loss: 0.3208	Eval_AUC: 0.8737
Epoch 12 Global_step 1056000	Train_loss: 0.3193	Eval_AUC: 0.8762
Epoch 12 Global_step 1057000	Train_loss: 0.3173	Eval_AUC: 0.8746
Epoch 12 Global_step 1058000	Train_loss: 0.3215	Eval_AUC: 0.8703
Epoch 12 Global_step 1059000	Train_loss: 0.3223	Eval_AUC: 0.8787
Epoch 12 DONE	Cost time: 108514.56
Epoch 13 Global_step 1060000	Train_loss: 0.3141	Eval_AUC: 0.8708
Epoch 13 Global_step 1061000	Train_loss: 0.2931	Eval_AUC: 0.8721
Epoch 13 Global_step 1062000	Train_loss: 0.2942	Eval_AUC: 0.8711
Epoch 13 Global_step 1063000	Train_loss: 0.2934	Eval_AUC: 0.8759
Epoch 13 Global_step 1064000	Train_loss: 0.2890	Eval_AUC: 0.8755
Epoch 13 Global_step 1065000	Train_loss: 0.2925	Eval_AUC: 0.8749
Epoch 13 Global_step 1066000	Train_loss: 0.2919	Eval_AUC: 0.8724
Epoch 13 Global_step 1067000	Train_loss: 0.2956	Eval_AUC: 0.8746
Epoch 13 Global_step 1068000	Train_loss: 0.2975	Eval_AUC: 0.8723
Epoch 13 Global_step 1069000	Train_loss: 0.2986	Eval_AUC: 0.8706
Epoch 13 Global_step 1070000	Train_loss: 0.2976	Eval_AUC: 0.8712
Epoch 13 Global_step 1071000	Train_loss: 0.2978	Eval_AUC: 0.8749
Epoch 13 Global_step 1072000	Train_loss: 0.2964	Eval_AUC: 0.8707
Epoch 13 Global_step 1073000	Train_loss: 0.2954	Eval_AUC: 0.8732
Epoch 13 Global_step 1074000	Train_loss: 0.2984	Eval_AUC: 0.8716
Epoch 13 Global_step 1075000	Train_loss: 0.2966	Eval_AUC: 0.8720
Epoch 13 Global_step 1076000	Train_loss: 0.2952	Eval_AUC: 0.8683
Epoch 13 Global_step 1077000	Train_loss: 0.2909	Eval_AUC: 0.8750
Epoch 13 Global_step 1078000	Train_loss: 0.2962	Eval_AUC: 0.8721
Epoch 13 Global_step 1079000	Train_loss: 0.2961	Eval_AUC: 0.8727
Epoch 13 Global_step 1080000	Train_loss: 0.2990	Eval_AUC: 0.8721
Epoch 13 Global_step 1081000	Train_loss: 0.3037	Eval_AUC: 0.8699
Epoch 13 Global_step 1082000	Train_loss: 0.2975	Eval_AUC: 0.8750
Epoch 13 Global_step 1083000	Train_loss: 0.3004	Eval_AUC: 0.8743
Epoch 13 Global_step 1084000	Train_loss: 0.3003	Eval_AUC: 0.8732
Epoch 13 Global_step 1085000	Train_loss: 0.2982	Eval_AUC: 0.8712
Epoch 13 Global_step 1086000	Train_loss: 0.3004	Eval_AUC: 0.8747
Epoch 13 Global_step 1087000	Train_loss: 0.3022	Eval_AUC: 0.8739
Epoch 13 Global_step 1088000	Train_loss: 0.3029	Eval_AUC: 0.8695
Epoch 13 Global_step 1089000	Train_loss: 0.3053	Eval_AUC: 0.8707
Epoch 13 Global_step 1090000	Train_loss: 0.3048	Eval_AUC: 0.8739
Epoch 13 Global_step 1091000	Train_loss: 0.3001	Eval_AUC: 0.8759
Epoch 13 Global_step 1092000	Train_loss: 0.3011	Eval_AUC: 0.8696
Epoch 13 Global_step 1093000	Train_loss: 0.3015	Eval_AUC: 0.8725
Epoch 13 Global_step 1094000	Train_loss: 0.3039	Eval_AUC: 0.8673
Epoch 13 Global_step 1095000	Train_loss: 0.3067	Eval_AUC: 0.8702
Epoch 13 Global_step 1096000	Train_loss: 0.3025	Eval_AUC: 0.8716
Epoch 13 Global_step 1097000	Train_loss: 0.3075	Eval_AUC: 0.8708
Epoch 13 Global_step 1098000	Train_loss: 0.3044	Eval_AUC: 0.8740
Epoch 13 Global_step 1099000	Train_loss: 0.3073	Eval_AUC: 0.8736
Epoch 13 Global_step 1100000	Train_loss: 0.3066	Eval_AUC: 0.8717
Epoch 13 Global_step 1101000	Train_loss: 0.3033	Eval_AUC: 0.8777
Epoch 13 Global_step 1102000	Train_loss: 0.3037	Eval_AUC: 0.8710
Epoch 13 Global_step 1103000	Train_loss: 0.3032	Eval_AUC: 0.8701
Epoch 13 Global_step 1104000	Train_loss: 0.3083	Eval_AUC: 0.8748
Epoch 13 Global_step 1105000	Train_loss: 0.3082	Eval_AUC: 0.8740
Epoch 13 Global_step 1106000	Train_loss: 0.3103	Eval_AUC: 0.8682
Epoch 13 Global_step 1107000	Train_loss: 0.3051	Eval_AUC: 0.8748
Epoch 13 Global_step 1108000	Train_loss: 0.3045	Eval_AUC: 0.8739
Epoch 13 Global_step 1109000	Train_loss: 0.3077	Eval_AUC: 0.8746
Epoch 13 Global_step 1110000	Train_loss: 0.3051	Eval_AUC: 0.8726
Epoch 13 Global_step 1111000	Train_loss: 0.3077	Eval_AUC: 0.8767
Epoch 13 Global_step 1112000	Train_loss: 0.3031	Eval_AUC: 0.8725
Epoch 13 Global_step 1113000	Train_loss: 0.3084	Eval_AUC: 0.8709
Epoch 13 Global_step 1114000	Train_loss: 0.3098	Eval_AUC: 0.8735
Epoch 13 Global_step 1115000	Train_loss: 0.3072	Eval_AUC: 0.8726
Epoch 13 Global_step 1116000	Train_loss: 0.3075	Eval_AUC: 0.8742
Epoch 13 Global_step 1117000	Train_loss: 0.3059	Eval_AUC: 0.8729
Epoch 13 Global_step 1118000	Train_loss: 0.3094	Eval_AUC: 0.8754
Epoch 13 Global_step 1119000	Train_loss: 0.3099	Eval_AUC: 0.8722
Epoch 13 Global_step 1120000	Train_loss: 0.3090	Eval_AUC: 0.8725
Epoch 13 Global_step 1121000	Train_loss: 0.3104	Eval_AUC: 0.8741
Epoch 13 Global_step 1122000	Train_loss: 0.3100	Eval_AUC: 0.8769
Epoch 13 Global_step 1123000	Train_loss: 0.3082	Eval_AUC: 0.8767
Epoch 13 Global_step 1124000	Train_loss: 0.3132	Eval_AUC: 0.8743
Epoch 13 Global_step 1125000	Train_loss: 0.3127	Eval_AUC: 0.8771
Epoch 13 Global_step 1126000	Train_loss: 0.3059	Eval_AUC: 0.8739
Epoch 13 Global_step 1127000	Train_loss: 0.3133	Eval_AUC: 0.8748
Epoch 13 Global_step 1128000	Train_loss: 0.3088	Eval_AUC: 0.8763
Epoch 13 Global_step 1129000	Train_loss: 0.3083	Eval_AUC: 0.8749
Epoch 13 Global_step 1130000	Train_loss: 0.3076	Eval_AUC: 0.8728
Epoch 13 Global_step 1131000	Train_loss: 0.3139	Eval_AUC: 0.8718
Epoch 13 Global_step 1132000	Train_loss: 0.3129	Eval_AUC: 0.8756
Epoch 13 Global_step 1133000	Train_loss: 0.3108	Eval_AUC: 0.8733
Epoch 13 Global_step 1134000	Train_loss: 0.3100	Eval_AUC: 0.8744
Epoch 13 Global_step 1135000	Train_loss: 0.3077	Eval_AUC: 0.8725
Epoch 13 Global_step 1136000	Train_loss: 0.3116	Eval_AUC: 0.8715
Epoch 13 Global_step 1137000	Train_loss: 0.3125	Eval_AUC: 0.8745
Epoch 13 Global_step 1138000	Train_loss: 0.3123	Eval_AUC: 0.8706
Epoch 13 Global_step 1139000	Train_loss: 0.3145	Eval_AUC: 0.8741
Epoch 13 Global_step 1140000	Train_loss: 0.3140	Eval_AUC: 0.8690
Epoch 13 Global_step 1141000	Train_loss: 0.3144	Eval_AUC: 0.8763
Epoch 13 DONE	Cost time: 116921.61
Epoch 14 Global_step 1142000	Train_loss: 0.2924	Eval_AUC: 0.8757
Epoch 14 Global_step 1143000	Train_loss: 0.2833	Eval_AUC: 0.8738
Epoch 14 Global_step 1144000	Train_loss: 0.2884	Eval_AUC: 0.8747
Epoch 14 Global_step 1145000	Train_loss: 0.2831	Eval_AUC: 0.8713
Epoch 14 Global_step 1146000	Train_loss: 0.2843	Eval_AUC: 0.8701
Epoch 14 Global_step 1147000	Train_loss: 0.2862	Eval_AUC: 0.8717
Epoch 14 Global_step 1148000	Train_loss: 0.2909	Eval_AUC: 0.8759
Epoch 14 Global_step 1149000	Train_loss: 0.2863	Eval_AUC: 0.8731
Epoch 14 Global_step 1150000	Train_loss: 0.2832	Eval_AUC: 0.8713
Epoch 14 Global_step 1151000	Train_loss: 0.2895	Eval_AUC: 0.8714
Epoch 14 Global_step 1152000	Train_loss: 0.2831	Eval_AUC: 0.8748
Epoch 14 Global_step 1153000	Train_loss: 0.2897	Eval_AUC: 0.8719
Epoch 14 Global_step 1154000	Train_loss: 0.2908	Eval_AUC: 0.8706
Epoch 14 Global_step 1155000	Train_loss: 0.2877	Eval_AUC: 0.8715
Epoch 14 Global_step 1156000	Train_loss: 0.2866	Eval_AUC: 0.8734
Epoch 14 Global_step 1157000	Train_loss: 0.2886	Eval_AUC: 0.8695
Epoch 14 Global_step 1158000	Train_loss: 0.2935	Eval_AUC: 0.8715
Epoch 14 Global_step 1159000	Train_loss: 0.2887	Eval_AUC: 0.8734
Epoch 14 Global_step 1160000	Train_loss: 0.2906	Eval_AUC: 0.8658
Epoch 14 Global_step 1161000	Train_loss: 0.2932	Eval_AUC: 0.8675
Epoch 14 Global_step 1162000	Train_loss: 0.2866	Eval_AUC: 0.8720
Epoch 14 Global_step 1163000	Train_loss: 0.2935	Eval_AUC: 0.8693
Epoch 14 Global_step 1164000	Train_loss: 0.2952	Eval_AUC: 0.8734
Epoch 14 Global_step 1165000	Train_loss: 0.2942	Eval_AUC: 0.8718
Epoch 14 Global_step 1166000	Train_loss: 0.2927	Eval_AUC: 0.8717
Epoch 14 Global_step 1167000	Train_loss: 0.2952	Eval_AUC: 0.8730
Epoch 14 Global_step 1168000	Train_loss: 0.2931	Eval_AUC: 0.8726
Epoch 14 Global_step 1169000	Train_loss: 0.2942	Eval_AUC: 0.8721
Epoch 14 Global_step 1170000	Train_loss: 0.2920	Eval_AUC: 0.8670
Epoch 14 Global_step 1171000	Train_loss: 0.2900	Eval_AUC: 0.8684
Epoch 14 Global_step 1172000	Train_loss: 0.2929	Eval_AUC: 0.8678
Epoch 14 Global_step 1173000	Train_loss: 0.2987	Eval_AUC: 0.8674
Epoch 14 Global_step 1174000	Train_loss: 0.2964	Eval_AUC: 0.8709
Epoch 14 Global_step 1175000	Train_loss: 0.2949	Eval_AUC: 0.8693
Epoch 14 Global_step 1176000	Train_loss: 0.2960	Eval_AUC: 0.8685
Epoch 14 Global_step 1177000	Train_loss: 0.2951	Eval_AUC: 0.8729
Epoch 14 Global_step 1178000	Train_loss: 0.2972	Eval_AUC: 0.8702
Epoch 14 Global_step 1179000	Train_loss: 0.2954	Eval_AUC: 0.8729
Epoch 14 Global_step 1180000	Train_loss: 0.2979	Eval_AUC: 0.8709
Epoch 14 Global_step 1181000	Train_loss: 0.2983	Eval_AUC: 0.8741
Epoch 14 Global_step 1182000	Train_loss: 0.2975	Eval_AUC: 0.8724
Epoch 14 Global_step 1183000	Train_loss: 0.3003	Eval_AUC: 0.8681
Epoch 14 Global_step 1184000	Train_loss: 0.3000	Eval_AUC: 0.8710
Epoch 14 Global_step 1185000	Train_loss: 0.2963	Eval_AUC: 0.8697
Epoch 14 Global_step 1186000	Train_loss: 0.2952	Eval_AUC: 0.8675
Epoch 14 Global_step 1187000	Train_loss: 0.2958	Eval_AUC: 0.8720
Epoch 14 Global_step 1188000	Train_loss: 0.2991	Eval_AUC: 0.8740
Epoch 14 Global_step 1189000	Train_loss: 0.2994	Eval_AUC: 0.8757
Epoch 14 Global_step 1190000	Train_loss: 0.3003	Eval_AUC: 0.8727
Epoch 14 Global_step 1191000	Train_loss: 0.3023	Eval_AUC: 0.8687
Epoch 14 Global_step 1192000	Train_loss: 0.2985	Eval_AUC: 0.8707
Epoch 14 Global_step 1193000	Train_loss: 0.2966	Eval_AUC: 0.8735
Epoch 14 Global_step 1194000	Train_loss: 0.2982	Eval_AUC: 0.8738
Epoch 14 Global_step 1195000	Train_loss: 0.3036	Eval_AUC: 0.8717
Epoch 14 Global_step 1196000	Train_loss: 0.3013	Eval_AUC: 0.8692
Epoch 14 Global_step 1197000	Train_loss: 0.3031	Eval_AUC: 0.8737
Epoch 14 Global_step 1198000	Train_loss: 0.3012	Eval_AUC: 0.8734
Epoch 14 Global_step 1199000	Train_loss: 0.3034	Eval_AUC: 0.8696
Epoch 14 Global_step 1200000	Train_loss: 0.2986	Eval_AUC: 0.8723
Epoch 14 Global_step 1201000	Train_loss: 0.3012	Eval_AUC: 0.8714
Epoch 14 Global_step 1202000	Train_loss: 0.3027	Eval_AUC: 0.8731
Epoch 14 Global_step 1203000	Train_loss: 0.3004	Eval_AUC: 0.8674
Epoch 14 Global_step 1204000	Train_loss: 0.3038	Eval_AUC: 0.8680
Epoch 14 Global_step 1205000	Train_loss: 0.3004	Eval_AUC: 0.8738
Epoch 14 Global_step 1206000	Train_loss: 0.2966	Eval_AUC: 0.8718
Epoch 14 Global_step 1207000	Train_loss: 0.3031	Eval_AUC: 0.8767
Epoch 14 Global_step 1208000	Train_loss: 0.3047	Eval_AUC: 0.8715
Epoch 14 Global_step 1209000	Train_loss: 0.3017	Eval_AUC: 0.8742
Epoch 14 Global_step 1210000	Train_loss: 0.3018	Eval_AUC: 0.8727
Epoch 14 Global_step 1211000	Train_loss: 0.3022	Eval_AUC: 0.8727
Epoch 14 Global_step 1212000	Train_loss: 0.3010	Eval_AUC: 0.8737
Epoch 14 Global_step 1213000	Train_loss: 0.3042	Eval_AUC: 0.8725
Epoch 14 Global_step 1214000	Train_loss: 0.3047	Eval_AUC: 0.8768
Epoch 14 Global_step 1215000	Train_loss: 0.3044	Eval_AUC: 0.8750
Epoch 14 Global_step 1216000	Train_loss: 0.3024	Eval_AUC: 0.8711
Epoch 14 Global_step 1217000	Train_loss: 0.3085	Eval_AUC: 0.8708
Epoch 14 Global_step 1218000	Train_loss: 0.3047	Eval_AUC: 0.8695
Epoch 14 Global_step 1219000	Train_loss: 0.3040	Eval_AUC: 0.8735
Epoch 14 Global_step 1220000	Train_loss: 0.3057	Eval_AUC: 0.8746
Epoch 14 Global_step 1221000	Train_loss: 0.3034	Eval_AUC: 0.8718
Epoch 14 Global_step 1222000	Train_loss: 0.3048	Eval_AUC: 0.8747
Epoch 14 DONE	Cost time: 125257.77
Epoch 15 Global_step 1223000	Train_loss: 0.3034	Eval_AUC: 0.8683
Epoch 15 Global_step 1224000	Train_loss: 0.2708	Eval_AUC: 0.8699
Epoch 15 Global_step 1225000	Train_loss: 0.2742	Eval_AUC: 0.8689
Epoch 15 Global_step 1226000	Train_loss: 0.2781	Eval_AUC: 0.8656
Epoch 15 Global_step 1227000	Train_loss: 0.2757	Eval_AUC: 0.8729
Epoch 15 Global_step 1228000	Train_loss: 0.2753	Eval_AUC: 0.8722
Epoch 15 Global_step 1229000	Train_loss: 0.2754	Eval_AUC: 0.8726
Epoch 15 Global_step 1230000	Train_loss: 0.2769	Eval_AUC: 0.8725
Epoch 15 Global_step 1231000	Train_loss: 0.2783	Eval_AUC: 0.8687
Epoch 15 Global_step 1232000	Train_loss: 0.2828	Eval_AUC: 0.8693
Epoch 15 Global_step 1233000	Train_loss: 0.2775	Eval_AUC: 0.8721
Epoch 15 Global_step 1234000	Train_loss: 0.2810	Eval_AUC: 0.8687
Epoch 15 Global_step 1235000	Train_loss: 0.2807	Eval_AUC: 0.8682
Epoch 15 Global_step 1236000	Train_loss: 0.2788	Eval_AUC: 0.8675
Epoch 15 Global_step 1237000	Train_loss: 0.2807	Eval_AUC: 0.8704
Epoch 15 Global_step 1238000	Train_loss: 0.2842	Eval_AUC: 0.8701
Epoch 15 Global_step 1239000	Train_loss: 0.2818	Eval_AUC: 0.8704
Epoch 15 Global_step 1240000	Train_loss: 0.2872	Eval_AUC: 0.8701
Epoch 15 Global_step 1241000	Train_loss: 0.2813	Eval_AUC: 0.8713
Epoch 15 Global_step 1242000	Train_loss: 0.2827	Eval_AUC: 0.8705
Epoch 15 Global_step 1243000	Train_loss: 0.2812	Eval_AUC: 0.8700
Epoch 15 Global_step 1244000	Train_loss: 0.2844	Eval_AUC: 0.8723
Epoch 15 Global_step 1245000	Train_loss: 0.2807	Eval_AUC: 0.8697
Epoch 15 Global_step 1246000	Train_loss: 0.2865	Eval_AUC: 0.8694
Epoch 15 Global_step 1247000	Train_loss: 0.2872	Eval_AUC: 0.8721
Epoch 15 Global_step 1248000	Train_loss: 0.2896	Eval_AUC: 0.8682
Epoch 15 Global_step 1249000	Train_loss: 0.2870	Eval_AUC: 0.8707
Epoch 15 Global_step 1250000	Train_loss: 0.2813	Eval_AUC: 0.8687
Epoch 15 Global_step 1251000	Train_loss: 0.2853	Eval_AUC: 0.8667
Epoch 15 Global_step 1252000	Train_loss: 0.2866	Eval_AUC: 0.8674
Epoch 15 Global_step 1253000	Train_loss: 0.2874	Eval_AUC: 0.8685
Epoch 15 Global_step 1254000	Train_loss: 0.2840	Eval_AUC: 0.8724
Epoch 15 Global_step 1255000	Train_loss: 0.2921	Eval_AUC: 0.8715
Epoch 15 Global_step 1256000	Train_loss: 0.2841	Eval_AUC: 0.8707
Epoch 15 Global_step 1257000	Train_loss: 0.2893	Eval_AUC: 0.8721
Epoch 15 Global_step 1258000	Train_loss: 0.2854	Eval_AUC: 0.8707
Epoch 15 Global_step 1259000	Train_loss: 0.2870	Eval_AUC: 0.8705
Epoch 15 Global_step 1260000	Train_loss: 0.2929	Eval_AUC: 0.8700
Epoch 15 Global_step 1261000	Train_loss: 0.2870	Eval_AUC: 0.8719
Epoch 15 Global_step 1262000	Train_loss: 0.2931	Eval_AUC: 0.8739
Epoch 15 Global_step 1263000	Train_loss: 0.2885	Eval_AUC: 0.8720
Epoch 15 Global_step 1264000	Train_loss: 0.2861	Eval_AUC: 0.8697
Epoch 15 Global_step 1265000	Train_loss: 0.2911	Eval_AUC: 0.8660
Epoch 15 Global_step 1266000	Train_loss: 0.2913	Eval_AUC: 0.8694
Epoch 15 Global_step 1267000	Train_loss: 0.2902	Eval_AUC: 0.8687
Epoch 15 Global_step 1268000	Train_loss: 0.2859	Eval_AUC: 0.8718
Epoch 15 Global_step 1269000	Train_loss: 0.2912	Eval_AUC: 0.8689
Epoch 15 Global_step 1270000	Train_loss: 0.2900	Eval_AUC: 0.8657
Epoch 15 Global_step 1271000	Train_loss: 0.2970	Eval_AUC: 0.8684
Epoch 15 Global_step 1272000	Train_loss: 0.2963	Eval_AUC: 0.8680
Epoch 15 Global_step 1273000	Train_loss: 0.2929	Eval_AUC: 0.8669
Epoch 15 Global_step 1274000	Train_loss: 0.2925	Eval_AUC: 0.8711
Epoch 15 Global_step 1275000	Train_loss: 0.2881	Eval_AUC: 0.8666
Epoch 15 Global_step 1276000	Train_loss: 0.2949	Eval_AUC: 0.8688
Epoch 15 Global_step 1277000	Train_loss: 0.2887	Eval_AUC: 0.8693
Epoch 15 Global_step 1278000	Train_loss: 0.2922	Eval_AUC: 0.8735
Epoch 15 Global_step 1279000	Train_loss: 0.2973	Eval_AUC: 0.8709
Epoch 15 Global_step 1280000	Train_loss: 0.2912	Eval_AUC: 0.8705
Epoch 15 Global_step 1281000	Train_loss: 0.2924	Eval_AUC: 0.8735
Epoch 15 Global_step 1282000	Train_loss: 0.2980	Eval_AUC: 0.8683
Epoch 15 Global_step 1283000	Train_loss: 0.2934	Eval_AUC: 0.8731
Epoch 15 Global_step 1284000	Train_loss: 0.2942	Eval_AUC: 0.8697
Epoch 15 Global_step 1285000	Train_loss: 0.2972	Eval_AUC: 0.8686
Epoch 15 Global_step 1286000	Train_loss: 0.2975	Eval_AUC: 0.8718
Epoch 15 Global_step 1287000	Train_loss: 0.2932	Eval_AUC: 0.8710
Epoch 15 Global_step 1288000	Train_loss: 0.2951	Eval_AUC: 0.8684
Epoch 15 Global_step 1289000	Train_loss: 0.2954	Eval_AUC: 0.8691
Epoch 15 Global_step 1290000	Train_loss: 0.2961	Eval_AUC: 0.8705
Epoch 15 Global_step 1291000	Train_loss: 0.2959	Eval_AUC: 0.8724
Epoch 15 Global_step 1292000	Train_loss: 0.2942	Eval_AUC: 0.8687
Epoch 15 Global_step 1293000	Train_loss: 0.2960	Eval_AUC: 0.8710
Epoch 15 Global_step 1294000	Train_loss: 0.2965	Eval_AUC: 0.8723
Epoch 15 Global_step 1295000	Train_loss: 0.2956	Eval_AUC: 0.8716
Epoch 15 Global_step 1296000	Train_loss: 0.2983	Eval_AUC: 0.8678
Epoch 15 Global_step 1297000	Train_loss: 0.2965	Eval_AUC: 0.8703
Epoch 15 Global_step 1298000	Train_loss: 0.2938	Eval_AUC: 0.8692
Epoch 15 Global_step 1299000	Train_loss: 0.2988	Eval_AUC: 0.8753
Epoch 15 Global_step 1300000	Train_loss: 0.2916	Eval_AUC: 0.8720
Epoch 15 Global_step 1301000	Train_loss: 0.2994	Eval_AUC: 0.8700
Epoch 15 Global_step 1302000	Train_loss: 0.2959	Eval_AUC: 0.8711
Epoch 15 Global_step 1303000	Train_loss: 0.2931	Eval_AUC: 0.8728
Epoch 15 Global_step 1304000	Train_loss: 0.3013	Eval_AUC: 0.8684
Epoch 15 DONE	Cost time: 133103.32
Epoch 16 Global_step 1305000	Train_loss: 0.2792	Eval_AUC: 0.8711
Epoch 16 Global_step 1306000	Train_loss: 0.2639	Eval_AUC: 0.8725
Epoch 16 Global_step 1307000	Train_loss: 0.2719	Eval_AUC: 0.8675
Epoch 16 Global_step 1308000	Train_loss: 0.2666	Eval_AUC: 0.8722
Epoch 16 Global_step 1309000	Train_loss: 0.2656	Eval_AUC: 0.8682
Epoch 16 Global_step 1310000	Train_loss: 0.2660	Eval_AUC: 0.8686
Epoch 16 Global_step 1311000	Train_loss: 0.2702	Eval_AUC: 0.8653
Epoch 16 Global_step 1312000	Train_loss: 0.2713	Eval_AUC: 0.8605
Epoch 16 Global_step 1313000	Train_loss: 0.2705	Eval_AUC: 0.8680
Epoch 16 Global_step 1314000	Train_loss: 0.2743	Eval_AUC: 0.8705
Epoch 16 Global_step 1315000	Train_loss: 0.2712	Eval_AUC: 0.8673
Epoch 16 Global_step 1316000	Train_loss: 0.2742	Eval_AUC: 0.8654
Epoch 16 Global_step 1317000	Train_loss: 0.2716	Eval_AUC: 0.8669
Epoch 16 Global_step 1318000	Train_loss: 0.2725	Eval_AUC: 0.8643
Epoch 16 Global_step 1319000	Train_loss: 0.2748	Eval_AUC: 0.8707
Epoch 16 Global_step 1320000	Train_loss: 0.2734	Eval_AUC: 0.8667
Epoch 16 Global_step 1321000	Train_loss: 0.2707	Eval_AUC: 0.8698
Epoch 16 Global_step 1322000	Train_loss: 0.2762	Eval_AUC: 0.8678
Epoch 16 Global_step 1323000	Train_loss: 0.2779	Eval_AUC: 0.8707
Epoch 16 Global_step 1324000	Train_loss: 0.2746	Eval_AUC: 0.8700
Epoch 16 Global_step 1325000	Train_loss: 0.2762	Eval_AUC: 0.8659
Epoch 16 Global_step 1326000	Train_loss: 0.2741	Eval_AUC: 0.8699
Epoch 16 Global_step 1327000	Train_loss: 0.2758	Eval_AUC: 0.8689
Epoch 16 Global_step 1328000	Train_loss: 0.2764	Eval_AUC: 0.8663
Epoch 16 Global_step 1329000	Train_loss: 0.2769	Eval_AUC: 0.8704
Epoch 16 Global_step 1330000	Train_loss: 0.2788	Eval_AUC: 0.8700
Epoch 16 Global_step 1331000	Train_loss: 0.2791	Eval_AUC: 0.8691
Epoch 16 Global_step 1332000	Train_loss: 0.2811	Eval_AUC: 0.8664
Epoch 16 Global_step 1333000	Train_loss: 0.2771	Eval_AUC: 0.8675
Epoch 16 Global_step 1334000	Train_loss: 0.2821	Eval_AUC: 0.8699
Epoch 16 Global_step 1335000	Train_loss: 0.2826	Eval_AUC: 0.8694
Epoch 16 Global_step 1336000	Train_loss: 0.2782	Eval_AUC: 0.8706
Epoch 16 Global_step 1337000	Train_loss: 0.2751	Eval_AUC: 0.8688
Epoch 16 Global_step 1338000	Train_loss: 0.2789	Eval_AUC: 0.8670
Epoch 16 Global_step 1339000	Train_loss: 0.2767	Eval_AUC: 0.8698
Epoch 16 Global_step 1340000	Train_loss: 0.2781	Eval_AUC: 0.8674
Epoch 16 Global_step 1341000	Train_loss: 0.2791	Eval_AUC: 0.8653
Epoch 16 Global_step 1342000	Train_loss: 0.2800	Eval_AUC: 0.8675
Epoch 16 Global_step 1343000	Train_loss: 0.2821	Eval_AUC: 0.8697
Epoch 16 Global_step 1344000	Train_loss: 0.2807	Eval_AUC: 0.8672
Epoch 16 Global_step 1345000	Train_loss: 0.2789	Eval_AUC: 0.8693
Epoch 16 Global_step 1346000	Train_loss: 0.2819	Eval_AUC: 0.8665
Epoch 16 Global_step 1347000	Train_loss: 0.2823	Eval_AUC: 0.8630
Epoch 16 Global_step 1348000	Train_loss: 0.2833	Eval_AUC: 0.8676
Epoch 16 Global_step 1349000	Train_loss: 0.2837	Eval_AUC: 0.8718
Epoch 16 Global_step 1350000	Train_loss: 0.2824	Eval_AUC: 0.8708
Epoch 16 Global_step 1351000	Train_loss: 0.2859	Eval_AUC: 0.8690
Epoch 16 Global_step 1352000	Train_loss: 0.2825	Eval_AUC: 0.8690
Epoch 16 Global_step 1353000	Train_loss: 0.2861	Eval_AUC: 0.8700
Epoch 16 Global_step 1354000	Train_loss: 0.2834	Eval_AUC: 0.8698
Epoch 16 Global_step 1355000	Train_loss: 0.2849	Eval_AUC: 0.8703
Epoch 16 Global_step 1356000	Train_loss: 0.2873	Eval_AUC: 0.8703
Epoch 16 Global_step 1357000	Train_loss: 0.2839	Eval_AUC: 0.8660
Epoch 16 Global_step 1358000	Train_loss: 0.2799	Eval_AUC: 0.8650
Epoch 16 Global_step 1359000	Train_loss: 0.2874	Eval_AUC: 0.8686
Epoch 16 Global_step 1360000	Train_loss: 0.2912	Eval_AUC: 0.8698
Epoch 16 Global_step 1361000	Train_loss: 0.2817	Eval_AUC: 0.8689
Epoch 16 Global_step 1362000	Train_loss: 0.2875	Eval_AUC: 0.8667
Epoch 16 Global_step 1363000	Train_loss: 0.2835	Eval_AUC: 0.8719
Epoch 16 Global_step 1364000	Train_loss: 0.2867	Eval_AUC: 0.8690
Epoch 16 Global_step 1365000	Train_loss: 0.2871	Eval_AUC: 0.8699
Epoch 16 Global_step 1366000	Train_loss: 0.2872	Eval_AUC: 0.8687
Epoch 16 Global_step 1367000	Train_loss: 0.2866	Eval_AUC: 0.8695
Epoch 16 Global_step 1368000	Train_loss: 0.2847	Eval_AUC: 0.8681
Epoch 16 Global_step 1369000	Train_loss: 0.2875	Eval_AUC: 0.8679
Epoch 16 Global_step 1370000	Train_loss: 0.2935	Eval_AUC: 0.8704
Epoch 16 Global_step 1371000	Train_loss: 0.2926	Eval_AUC: 0.8680
Epoch 16 Global_step 1372000	Train_loss: 0.2909	Eval_AUC: 0.8672
Epoch 16 Global_step 1373000	Train_loss: 0.2905	Eval_AUC: 0.8715
Epoch 16 Global_step 1374000	Train_loss: 0.2888	Eval_AUC: 0.8690
Epoch 16 Global_step 1375000	Train_loss: 0.2844	Eval_AUC: 0.8691
Epoch 16 Global_step 1376000	Train_loss: 0.2881	Eval_AUC: 0.8666
Epoch 16 Global_step 1377000	Train_loss: 0.2935	Eval_AUC: 0.8664
Epoch 16 Global_step 1378000	Train_loss: 0.2884	Eval_AUC: 0.8724
Epoch 16 Global_step 1379000	Train_loss: 0.2921	Eval_AUC: 0.8707
Epoch 16 Global_step 1380000	Train_loss: 0.2891	Eval_AUC: 0.8711
Epoch 16 Global_step 1381000	Train_loss: 0.2922	Eval_AUC: 0.8683
Epoch 16 Global_step 1382000	Train_loss: 0.2945	Eval_AUC: 0.8705
Epoch 16 Global_step 1383000	Train_loss: 0.2920	Eval_AUC: 0.8703
Epoch 16 Global_step 1384000	Train_loss: 0.2948	Eval_AUC: 0.8698
Epoch 16 Global_step 1385000	Train_loss: 0.2906	Eval_AUC: 0.8701
Epoch 16 DONE	Cost time: 140279.32
Epoch 17 Global_step 1386000	Train_loss: 0.2877	Eval_AUC: 0.8707
Epoch 17 Global_step 1387000	Train_loss: 0.2601	Eval_AUC: 0.8689
Epoch 17 Global_step 1388000	Train_loss: 0.2618	Eval_AUC: 0.8712
Epoch 17 Global_step 1389000	Train_loss: 0.2594	Eval_AUC: 0.8654
Epoch 17 Global_step 1390000	Train_loss: 0.2634	Eval_AUC: 0.8670
Epoch 17 Global_step 1391000	Train_loss: 0.2629	Eval_AUC: 0.8682
Epoch 17 Global_step 1392000	Train_loss: 0.2601	Eval_AUC: 0.8655
Epoch 17 Global_step 1393000	Train_loss: 0.2601	Eval_AUC: 0.8679
Epoch 17 Global_step 1394000	Train_loss: 0.2660	Eval_AUC: 0.8634
Epoch 17 Global_step 1395000	Train_loss: 0.2619	Eval_AUC: 0.8674
Epoch 17 Global_step 1396000	Train_loss: 0.2658	Eval_AUC: 0.8681
Epoch 17 Global_step 1397000	Train_loss: 0.2615	Eval_AUC: 0.8678
Epoch 17 Global_step 1398000	Train_loss: 0.2649	Eval_AUC: 0.8672
Epoch 17 Global_step 1399000	Train_loss: 0.2673	Eval_AUC: 0.8668
Epoch 17 Global_step 1400000	Train_loss: 0.2654	Eval_AUC: 0.8708
Epoch 17 Global_step 1401000	Train_loss: 0.2645	Eval_AUC: 0.8688
Epoch 17 Global_step 1402000	Train_loss: 0.2648	Eval_AUC: 0.8665
Epoch 17 Global_step 1403000	Train_loss: 0.2687	Eval_AUC: 0.8687
Epoch 17 Global_step 1404000	Train_loss: 0.2710	Eval_AUC: 0.8665
Epoch 17 Global_step 1405000	Train_loss: 0.2669	Eval_AUC: 0.8695
Epoch 17 Global_step 1406000	Train_loss: 0.2707	Eval_AUC: 0.8652
Epoch 17 Global_step 1407000	Train_loss: 0.2702	Eval_AUC: 0.8683
Epoch 17 Global_step 1408000	Train_loss: 0.2679	Eval_AUC: 0.8665
Epoch 17 Global_step 1409000	Train_loss: 0.2666	Eval_AUC: 0.8682
Epoch 17 Global_step 1410000	Train_loss: 0.2699	Eval_AUC: 0.8652
Epoch 17 Global_step 1411000	Train_loss: 0.2679	Eval_AUC: 0.8693
Epoch 17 Global_step 1412000	Train_loss: 0.2703	Eval_AUC: 0.8660
Epoch 17 Global_step 1413000	Train_loss: 0.2717	Eval_AUC: 0.8686
Epoch 17 Global_step 1414000	Train_loss: 0.2667	Eval_AUC: 0.8671
Epoch 17 Global_step 1415000	Train_loss: 0.2670	Eval_AUC: 0.8677
Epoch 17 Global_step 1416000	Train_loss: 0.2731	Eval_AUC: 0.8675
Epoch 17 Global_step 1417000	Train_loss: 0.2742	Eval_AUC: 0.8706
Epoch 17 Global_step 1418000	Train_loss: 0.2726	Eval_AUC: 0.8651
Epoch 17 Global_step 1419000	Train_loss: 0.2737	Eval_AUC: 0.8684
Epoch 17 Global_step 1420000	Train_loss: 0.2743	Eval_AUC: 0.8666
Epoch 17 Global_step 1421000	Train_loss: 0.2744	Eval_AUC: 0.8689
Epoch 17 Global_step 1422000	Train_loss: 0.2710	Eval_AUC: 0.8690
Epoch 17 Global_step 1423000	Train_loss: 0.2736	Eval_AUC: 0.8679
Epoch 17 Global_step 1424000	Train_loss: 0.2717	Eval_AUC: 0.8687
Epoch 17 Global_step 1425000	Train_loss: 0.2729	Eval_AUC: 0.8625
Epoch 17 Global_step 1426000	Train_loss: 0.2766	Eval_AUC: 0.8719
Epoch 17 Global_step 1427000	Train_loss: 0.2760	Eval_AUC: 0.8653
Epoch 17 Global_step 1428000	Train_loss: 0.2759	Eval_AUC: 0.8625
Epoch 17 Global_step 1429000	Train_loss: 0.2751	Eval_AUC: 0.8689
Epoch 17 Global_step 1430000	Train_loss: 0.2760	Eval_AUC: 0.8689
Epoch 17 Global_step 1431000	Train_loss: 0.2755	Eval_AUC: 0.8676
Epoch 17 Global_step 1432000	Train_loss: 0.2736	Eval_AUC: 0.8699
Epoch 17 Global_step 1433000	Train_loss: 0.2746	Eval_AUC: 0.8674
Epoch 17 Global_step 1434000	Train_loss: 0.2770	Eval_AUC: 0.8709
Epoch 17 Global_step 1435000	Train_loss: 0.2777	Eval_AUC: 0.8657
Epoch 17 Global_step 1436000	Train_loss: 0.2743	Eval_AUC: 0.8672
Epoch 17 Global_step 1437000	Train_loss: 0.2752	Eval_AUC: 0.8668
Epoch 17 Global_step 1438000	Train_loss: 0.2766	Eval_AUC: 0.8640
Epoch 17 Global_step 1439000	Train_loss: 0.2779	Eval_AUC: 0.8689
Epoch 17 Global_step 1440000	Train_loss: 0.2801	Eval_AUC: 0.8645
Epoch 17 Global_step 1441000	Train_loss: 0.2790	Eval_AUC: 0.8668
Epoch 17 Global_step 1442000	Train_loss: 0.2788	Eval_AUC: 0.8697
Epoch 17 Global_step 1443000	Train_loss: 0.2804	Eval_AUC: 0.8635
Epoch 17 Global_step 1444000	Train_loss: 0.2763	Eval_AUC: 0.8650
Epoch 17 Global_step 1445000	Train_loss: 0.2793	Eval_AUC: 0.8674
Epoch 17 Global_step 1446000	Train_loss: 0.2765	Eval_AUC: 0.8697
Epoch 17 Global_step 1447000	Train_loss: 0.2791	Eval_AUC: 0.8672
Epoch 17 Global_step 1448000	Train_loss: 0.2822	Eval_AUC: 0.8670
Epoch 17 Global_step 1449000	Train_loss: 0.2829	Eval_AUC: 0.8676
Epoch 17 Global_step 1450000	Train_loss: 0.2793	Eval_AUC: 0.8686
Epoch 17 Global_step 1451000	Train_loss: 0.2800	Eval_AUC: 0.8652
Epoch 17 Global_step 1452000	Train_loss: 0.2851	Eval_AUC: 0.8664
Epoch 17 Global_step 1453000	Train_loss: 0.2794	Eval_AUC: 0.8653
Epoch 17 Global_step 1454000	Train_loss: 0.2825	Eval_AUC: 0.8696
Epoch 17 Global_step 1455000	Train_loss: 0.2788	Eval_AUC: 0.8673
Epoch 17 Global_step 1456000	Train_loss: 0.2820	Eval_AUC: 0.8742
Epoch 17 Global_step 1457000	Train_loss: 0.2835	Eval_AUC: 0.8690
Epoch 17 Global_step 1458000	Train_loss: 0.2823	Eval_AUC: 0.8694
Epoch 17 Global_step 1459000	Train_loss: 0.2846	Eval_AUC: 0.8679
Epoch 17 Global_step 1460000	Train_loss: 0.2833	Eval_AUC: 0.8693
Epoch 17 Global_step 1461000	Train_loss: 0.2811	Eval_AUC: 0.8688
Epoch 17 Global_step 1462000	Train_loss: 0.2809	Eval_AUC: 0.8702
Epoch 17 Global_step 1463000	Train_loss: 0.2848	Eval_AUC: 0.8662
Epoch 17 Global_step 1464000	Train_loss: 0.2827	Eval_AUC: 0.8672
Epoch 17 Global_step 1465000	Train_loss: 0.2844	Eval_AUC: 0.8696
Epoch 17 Global_step 1466000	Train_loss: 0.2818	Eval_AUC: 0.8719
Epoch 17 Global_step 1467000	Train_loss: 0.2843	Eval_AUC: 0.8690
Epoch 17 DONE	Cost time: 147515.74
Epoch 18 Global_step 1468000	Train_loss: 0.2661	Eval_AUC: 0.8675
Epoch 18 Global_step 1469000	Train_loss: 0.2521	Eval_AUC: 0.8668
Epoch 18 Global_step 1470000	Train_loss: 0.2517	Eval_AUC: 0.8639
Epoch 18 Global_step 1471000	Train_loss: 0.2494	Eval_AUC: 0.8642
Epoch 18 Global_step 1472000	Train_loss: 0.2520	Eval_AUC: 0.8649
Epoch 18 Global_step 1473000	Train_loss: 0.2550	Eval_AUC: 0.8670
Epoch 18 Global_step 1474000	Train_loss: 0.2468	Eval_AUC: 0.8654
Epoch 18 Global_step 1475000	Train_loss: 0.2541	Eval_AUC: 0.8626
Epoch 18 Global_step 1476000	Train_loss: 0.2566	Eval_AUC: 0.8641
Epoch 18 Global_step 1477000	Train_loss: 0.2595	Eval_AUC: 0.8647
Epoch 18 Global_step 1478000	Train_loss: 0.2562	Eval_AUC: 0.8656
Epoch 18 Global_step 1479000	Train_loss: 0.2537	Eval_AUC: 0.8674
Epoch 18 Global_step 1480000	Train_loss: 0.2557	Eval_AUC: 0.8682
Epoch 18 Global_step 1481000	Train_loss: 0.2567	Eval_AUC: 0.8643
Epoch 18 Global_step 1482000	Train_loss: 0.2562	Eval_AUC: 0.8647
Epoch 18 Global_step 1483000	Train_loss: 0.2620	Eval_AUC: 0.8634
Epoch 18 Global_step 1484000	Train_loss: 0.2590	Eval_AUC: 0.8648
Epoch 18 Global_step 1485000	Train_loss: 0.2602	Eval_AUC: 0.8624
Epoch 18 Global_step 1486000	Train_loss: 0.2606	Eval_AUC: 0.8631
Epoch 18 Global_step 1487000	Train_loss: 0.2626	Eval_AUC: 0.8637
Epoch 18 Global_step 1488000	Train_loss: 0.2624	Eval_AUC: 0.8566
Epoch 18 Global_step 1489000	Train_loss: 0.2606	Eval_AUC: 0.8638
Epoch 18 Global_step 1490000	Train_loss: 0.2579	Eval_AUC: 0.8658
Epoch 18 Global_step 1491000	Train_loss: 0.2629	Eval_AUC: 0.8669
Epoch 18 Global_step 1492000	Train_loss: 0.2622	Eval_AUC: 0.8696
Epoch 18 Global_step 1493000	Train_loss: 0.2639	Eval_AUC: 0.8652
Epoch 18 Global_step 1494000	Train_loss: 0.2642	Eval_AUC: 0.8628
Epoch 18 Global_step 1495000	Train_loss: 0.2640	Eval_AUC: 0.8632
Epoch 18 Global_step 1496000	Train_loss: 0.2609	Eval_AUC: 0.8645
Epoch 18 Global_step 1497000	Train_loss: 0.2633	Eval_AUC: 0.8690
Epoch 18 Global_step 1498000	Train_loss: 0.2616	Eval_AUC: 0.8657
Epoch 18 Global_step 1499000	Train_loss: 0.2640	Eval_AUC: 0.8625
Epoch 18 Global_step 1500000	Train_loss: 0.2657	Eval_AUC: 0.8640
Epoch 18 Global_step 1501000	Train_loss: 0.2652	Eval_AUC: 0.8663
Epoch 18 Global_step 1502000	Train_loss: 0.2643	Eval_AUC: 0.8653
Epoch 18 Global_step 1503000	Train_loss: 0.2684	Eval_AUC: 0.8671
Epoch 18 Global_step 1504000	Train_loss: 0.2674	Eval_AUC: 0.8662
Epoch 18 Global_step 1505000	Train_loss: 0.2653	Eval_AUC: 0.8694
Epoch 18 Global_step 1506000	Train_loss: 0.2654	Eval_AUC: 0.8649
Epoch 18 Global_step 1507000	Train_loss: 0.2659	Eval_AUC: 0.8675
Epoch 18 Global_step 1508000	Train_loss: 0.2688	Eval_AUC: 0.8672
Epoch 18 Global_step 1509000	Train_loss: 0.2674	Eval_AUC: 0.8659
Epoch 18 Global_step 1510000	Train_loss: 0.2698	Eval_AUC: 0.8647
Epoch 18 Global_step 1511000	Train_loss: 0.2699	Eval_AUC: 0.8650
Epoch 18 Global_step 1512000	Train_loss: 0.2686	Eval_AUC: 0.8688
Epoch 18 Global_step 1513000	Train_loss: 0.2677	Eval_AUC: 0.8650
Epoch 18 Global_step 1514000	Train_loss: 0.2643	Eval_AUC: 0.8666
Epoch 18 Global_step 1515000	Train_loss: 0.2645	Eval_AUC: 0.8681
Epoch 18 Global_step 1516000	Train_loss: 0.2658	Eval_AUC: 0.8667
Epoch 18 Global_step 1517000	Train_loss: 0.2725	Eval_AUC: 0.8670
Epoch 18 Global_step 1518000	Train_loss: 0.2698	Eval_AUC: 0.8665
Epoch 18 Global_step 1519000	Train_loss: 0.2667	Eval_AUC: 0.8622
Epoch 18 Global_step 1520000	Train_loss: 0.2714	Eval_AUC: 0.8653
Epoch 18 Global_step 1521000	Train_loss: 0.2739	Eval_AUC: 0.8639
Epoch 18 Global_step 1522000	Train_loss: 0.2724	Eval_AUC: 0.8660
Epoch 18 Global_step 1523000	Train_loss: 0.2730	Eval_AUC: 0.8702
Epoch 18 Global_step 1524000	Train_loss: 0.2722	Eval_AUC: 0.8639
Epoch 18 Global_step 1525000	Train_loss: 0.2717	Eval_AUC: 0.8680
Epoch 18 Global_step 1526000	Train_loss: 0.2711	Eval_AUC: 0.8675
Epoch 18 Global_step 1527000	Train_loss: 0.2750	Eval_AUC: 0.8685
Epoch 18 Global_step 1528000	Train_loss: 0.2735	Eval_AUC: 0.8626
Epoch 18 Global_step 1529000	Train_loss: 0.2752	Eval_AUC: 0.8680
Epoch 18 Global_step 1530000	Train_loss: 0.2744	Eval_AUC: 0.8711
Epoch 18 Global_step 1531000	Train_loss: 0.2732	Eval_AUC: 0.8668
Epoch 18 Global_step 1532000	Train_loss: 0.2688	Eval_AUC: 0.8679
Epoch 18 Global_step 1533000	Train_loss: 0.2768	Eval_AUC: 0.8657
Epoch 18 Global_step 1534000	Train_loss: 0.2763	Eval_AUC: 0.8646
Epoch 18 Global_step 1535000	Train_loss: 0.2737	Eval_AUC: 0.8697
Epoch 18 Global_step 1536000	Train_loss: 0.2740	Eval_AUC: 0.8669
Epoch 18 Global_step 1537000	Train_loss: 0.2760	Eval_AUC: 0.8647
Epoch 18 Global_step 1538000	Train_loss: 0.2759	Eval_AUC: 0.8645
Epoch 18 Global_step 1539000	Train_loss: 0.2773	Eval_AUC: 0.8638
Epoch 18 Global_step 1540000	Train_loss: 0.2790	Eval_AUC: 0.8623
Epoch 18 Global_step 1541000	Train_loss: 0.2786	Eval_AUC: 0.8675
Epoch 18 Global_step 1542000	Train_loss: 0.2761	Eval_AUC: 0.8675
Epoch 18 Global_step 1543000	Train_loss: 0.2778	Eval_AUC: 0.8699
Epoch 18 Global_step 1544000	Train_loss: 0.2786	Eval_AUC: 0.8684
Epoch 18 Global_step 1545000	Train_loss: 0.2782	Eval_AUC: 0.8670
Epoch 18 Global_step 1546000	Train_loss: 0.2767	Eval_AUC: 0.8612
Epoch 18 Global_step 1547000	Train_loss: 0.2763	Eval_AUC: 0.8659
Epoch 18 Global_step 1548000	Train_loss: 0.2773	Eval_AUC: 0.8690
Epoch 18 DONE	Cost time: 154690.14
Epoch 19 Global_step 1549000	Train_loss: 0.2787	Eval_AUC: 0.8646
Epoch 19 Global_step 1550000	Train_loss: 0.2487	Eval_AUC: 0.8622
Epoch 19 Global_step 1551000	Train_loss: 0.2468	Eval_AUC: 0.8608
Epoch 19 Global_step 1552000	Train_loss: 0.2438	Eval_AUC: 0.8671
Epoch 19 Global_step 1553000	Train_loss: 0.2456	Eval_AUC: 0.8618
Epoch 19 Global_step 1554000	Train_loss: 0.2472	Eval_AUC: 0.8671
Epoch 19 Global_step 1555000	Train_loss: 0.2471	Eval_AUC: 0.8644
Epoch 19 Global_step 1556000	Train_loss: 0.2448	Eval_AUC: 0.8612
Epoch 19 Global_step 1557000	Train_loss: 0.2450	Eval_AUC: 0.8667
Epoch 19 Global_step 1558000	Train_loss: 0.2495	Eval_AUC: 0.8594
Epoch 19 Global_step 1559000	Train_loss: 0.2475	Eval_AUC: 0.8591
Epoch 19 Global_step 1560000	Train_loss: 0.2521	Eval_AUC: 0.8629
Epoch 19 Global_step 1561000	Train_loss: 0.2486	Eval_AUC: 0.8600
Epoch 19 Global_step 1562000	Train_loss: 0.2468	Eval_AUC: 0.8633
Epoch 19 Global_step 1563000	Train_loss: 0.2502	Eval_AUC: 0.8612
Epoch 19 Global_step 1564000	Train_loss: 0.2495	Eval_AUC: 0.8590
Epoch 19 Global_step 1565000	Train_loss: 0.2499	Eval_AUC: 0.8650
Epoch 19 Global_step 1566000	Train_loss: 0.2506	Eval_AUC: 0.8647
Epoch 19 Global_step 1567000	Train_loss: 0.2540	Eval_AUC: 0.8657
Epoch 19 Global_step 1568000	Train_loss: 0.2552	Eval_AUC: 0.8631
Epoch 19 Global_step 1569000	Train_loss: 0.2524	Eval_AUC: 0.8593
Epoch 19 Global_step 1570000	Train_loss: 0.2520	Eval_AUC: 0.8586
Epoch 19 Global_step 1571000	Train_loss: 0.2547	Eval_AUC: 0.8654
Epoch 19 Global_step 1572000	Train_loss: 0.2545	Eval_AUC: 0.8618
Epoch 19 Global_step 1573000	Train_loss: 0.2498	Eval_AUC: 0.8634
Epoch 19 Global_step 1574000	Train_loss: 0.2532	Eval_AUC: 0.8625
Epoch 19 Global_step 1575000	Train_loss: 0.2550	Eval_AUC: 0.8661
Epoch 19 Global_step 1576000	Train_loss: 0.2586	Eval_AUC: 0.8642
Epoch 19 Global_step 1577000	Train_loss: 0.2556	Eval_AUC: 0.8647
Epoch 19 Global_step 1578000	Train_loss: 0.2581	Eval_AUC: 0.8658
Epoch 19 Global_step 1579000	Train_loss: 0.2610	Eval_AUC: 0.8652
Epoch 19 Global_step 1580000	Train_loss: 0.2647	Eval_AUC: 0.8637
Epoch 19 Global_step 1581000	Train_loss: 0.2580	Eval_AUC: 0.8653
Epoch 19 Global_step 1582000	Train_loss: 0.2559	Eval_AUC: 0.8628
Epoch 19 Global_step 1583000	Train_loss: 0.2551	Eval_AUC: 0.8621
Epoch 19 Global_step 1584000	Train_loss: 0.2614	Eval_AUC: 0.8663
Epoch 19 Global_step 1585000	Train_loss: 0.2584	Eval_AUC: 0.8634
Epoch 19 Global_step 1586000	Train_loss: 0.2604	Eval_AUC: 0.8690
Epoch 19 Global_step 1587000	Train_loss: 0.2553	Eval_AUC: 0.8687
Epoch 19 Global_step 1588000	Train_loss: 0.2585	Eval_AUC: 0.8655
Epoch 19 Global_step 1589000	Train_loss: 0.2596	Eval_AUC: 0.8621
Epoch 19 Global_step 1590000	Train_loss: 0.2633	Eval_AUC: 0.8647
Epoch 19 Global_step 1591000	Train_loss: 0.2649	Eval_AUC: 0.8625
Epoch 19 Global_step 1592000	Train_loss: 0.2605	Eval_AUC: 0.8654
Epoch 19 Global_step 1593000	Train_loss: 0.2637	Eval_AUC: 0.8659
Epoch 19 Global_step 1594000	Train_loss: 0.2626	Eval_AUC: 0.8652
Epoch 19 Global_step 1595000	Train_loss: 0.2575	Eval_AUC: 0.8672
Epoch 19 Global_step 1596000	Train_loss: 0.2614	Eval_AUC: 0.8646
Epoch 19 Global_step 1597000	Train_loss: 0.2620	Eval_AUC: 0.8635
Epoch 19 Global_step 1598000	Train_loss: 0.2654	Eval_AUC: 0.8645
Epoch 19 Global_step 1599000	Train_loss: 0.2613	Eval_AUC: 0.8626
Epoch 19 Global_step 1600000	Train_loss: 0.2623	Eval_AUC: 0.8643
Epoch 19 Global_step 1601000	Train_loss: 0.2595	Eval_AUC: 0.8687
Epoch 19 Global_step 1602000	Train_loss: 0.2658	Eval_AUC: 0.8628
Epoch 19 Global_step 1603000	Train_loss: 0.2645	Eval_AUC: 0.8631
Epoch 19 Global_step 1604000	Train_loss: 0.2689	Eval_AUC: 0.8664
Epoch 19 Global_step 1605000	Train_loss: 0.2649	Eval_AUC: 0.8659
Epoch 19 Global_step 1606000	Train_loss: 0.2655	Eval_AUC: 0.8634
Epoch 19 Global_step 1607000	Train_loss: 0.2657	Eval_AUC: 0.8663
Epoch 19 Global_step 1608000	Train_loss: 0.2654	Eval_AUC: 0.8654
Epoch 19 Global_step 1609000	Train_loss: 0.2700	Eval_AUC: 0.8642
Epoch 19 Global_step 1610000	Train_loss: 0.2638	Eval_AUC: 0.8659
Epoch 19 Global_step 1611000	Train_loss: 0.2652	Eval_AUC: 0.8665
Epoch 19 Global_step 1612000	Train_loss: 0.2682	Eval_AUC: 0.8638
Epoch 19 Global_step 1613000	Train_loss: 0.2699	Eval_AUC: 0.8619
Epoch 19 Global_step 1614000	Train_loss: 0.2676	Eval_AUC: 0.8654
Epoch 19 Global_step 1615000	Train_loss: 0.2684	Eval_AUC: 0.8668
Epoch 19 Global_step 1616000	Train_loss: 0.2679	Eval_AUC: 0.8588
Epoch 19 Global_step 1617000	Train_loss: 0.2663	Eval_AUC: 0.8662
Epoch 19 Global_step 1618000	Train_loss: 0.2659	Eval_AUC: 0.8632
Epoch 19 Global_step 1619000	Train_loss: 0.2689	Eval_AUC: 0.8653
Epoch 19 Global_step 1620000	Train_loss: 0.2707	Eval_AUC: 0.8670
Epoch 19 Global_step 1621000	Train_loss: 0.2672	Eval_AUC: 0.8683
Epoch 19 Global_step 1622000	Train_loss: 0.2673	Eval_AUC: 0.8659
Epoch 19 Global_step 1623000	Train_loss: 0.2671	Eval_AUC: 0.8659
Epoch 19 Global_step 1624000	Train_loss: 0.2721	Eval_AUC: 0.8643
Epoch 19 Global_step 1625000	Train_loss: 0.2684	Eval_AUC: 0.8665
Epoch 19 Global_step 1626000	Train_loss: 0.2690	Eval_AUC: 0.8645
Epoch 19 Global_step 1627000	Train_loss: 0.2693	Eval_AUC: 0.8681
Epoch 19 Global_step 1628000	Train_loss: 0.2669	Eval_AUC: 0.8665
Epoch 19 Global_step 1629000	Train_loss: 0.2706	Eval_AUC: 0.8658
Epoch 19 Global_step 1630000	Train_loss: 0.2722	Eval_AUC: 0.8645
Epoch 19 DONE	Cost time: 161924.05
Epoch 20 Global_step 1631000	Train_loss: 0.2549	Eval_AUC: 0.8683
Epoch 20 Global_step 1632000	Train_loss: 0.2361	Eval_AUC: 0.8633
Epoch 20 Global_step 1633000	Train_loss: 0.2356	Eval_AUC: 0.8633
Epoch 20 Global_step 1634000	Train_loss: 0.2363	Eval_AUC: 0.8650
Epoch 20 Global_step 1635000	Train_loss: 0.2370	Eval_AUC: 0.8627
Epoch 20 Global_step 1636000	Train_loss: 0.2405	Eval_AUC: 0.8593
Epoch 20 Global_step 1637000	Train_loss: 0.2364	Eval_AUC: 0.8593
Epoch 20 Global_step 1638000	Train_loss: 0.2418	Eval_AUC: 0.8617
Epoch 20 Global_step 1639000	Train_loss: 0.2462	Eval_AUC: 0.8626
Epoch 20 Global_step 1640000	Train_loss: 0.2411	Eval_AUC: 0.8614
Epoch 20 Global_step 1641000	Train_loss: 0.2468	Eval_AUC: 0.8616
Epoch 20 Global_step 1642000	Train_loss: 0.2427	Eval_AUC: 0.8624
Epoch 20 Global_step 1643000	Train_loss: 0.2432	Eval_AUC: 0.8601
Epoch 20 Global_step 1644000	Train_loss: 0.2462	Eval_AUC: 0.8630
Epoch 20 Global_step 1645000	Train_loss: 0.2435	Eval_AUC: 0.8632
Epoch 20 Global_step 1646000	Train_loss: 0.2410	Eval_AUC: 0.8610
Epoch 20 Global_step 1647000	Train_loss: 0.2443	Eval_AUC: 0.8626
Epoch 20 Global_step 1648000	Train_loss: 0.2418	Eval_AUC: 0.8633
Epoch 20 Global_step 1649000	Train_loss: 0.2448	Eval_AUC: 0.8615
Epoch 20 Global_step 1650000	Train_loss: 0.2476	Eval_AUC: 0.8628
Epoch 20 Global_step 1651000	Train_loss: 0.2473	Eval_AUC: 0.8594
Epoch 20 Global_step 1652000	Train_loss: 0.2483	Eval_AUC: 0.8633
Epoch 20 Global_step 1653000	Train_loss: 0.2465	Eval_AUC: 0.8602
Epoch 20 Global_step 1654000	Train_loss: 0.2484	Eval_AUC: 0.8637
Epoch 20 Global_step 1655000	Train_loss: 0.2539	Eval_AUC: 0.8621
Epoch 20 Global_step 1656000	Train_loss: 0.2477	Eval_AUC: 0.8649
Epoch 20 Global_step 1657000	Train_loss: 0.2518	Eval_AUC: 0.8608
Epoch 20 Global_step 1658000	Train_loss: 0.2503	Eval_AUC: 0.8619
Epoch 20 Global_step 1659000	Train_loss: 0.2480	Eval_AUC: 0.8638
Epoch 20 Global_step 1660000	Train_loss: 0.2492	Eval_AUC: 0.8592
Epoch 20 Global_step 1661000	Train_loss: 0.2504	Eval_AUC: 0.8624
Epoch 20 Global_step 1662000	Train_loss: 0.2516	Eval_AUC: 0.8647
Epoch 20 Global_step 1663000	Train_loss: 0.2537	Eval_AUC: 0.8622
Epoch 20 Global_step 1664000	Train_loss: 0.2471	Eval_AUC: 0.8613
Epoch 20 Global_step 1665000	Train_loss: 0.2499	Eval_AUC: 0.8617
Epoch 20 Global_step 1666000	Train_loss: 0.2534	Eval_AUC: 0.8615
Epoch 20 Global_step 1667000	Train_loss: 0.2505	Eval_AUC: 0.8556
Epoch 20 Global_step 1668000	Train_loss: 0.2530	Eval_AUC: 0.8619
Epoch 20 Global_step 1669000	Train_loss: 0.2508	Eval_AUC: 0.8635
Epoch 20 Global_step 1670000	Train_loss: 0.2521	Eval_AUC: 0.8648
Epoch 20 Global_step 1671000	Train_loss: 0.2544	Eval_AUC: 0.8644
Epoch 20 Global_step 1672000	Train_loss: 0.2576	Eval_AUC: 0.8662
Epoch 20 Global_step 1673000	Train_loss: 0.2573	Eval_AUC: 0.8660
Epoch 20 Global_step 1674000	Train_loss: 0.2539	Eval_AUC: 0.8616
Epoch 20 Global_step 1675000	Train_loss: 0.2549	Eval_AUC: 0.8639
Epoch 20 Global_step 1676000	Train_loss: 0.2568	Eval_AUC: 0.8633
Epoch 20 Global_step 1677000	Train_loss: 0.2574	Eval_AUC: 0.8680
Epoch 20 Global_step 1678000	Train_loss: 0.2544	Eval_AUC: 0.8584
Epoch 20 Global_step 1679000	Train_loss: 0.2561	Eval_AUC: 0.8628
Epoch 20 Global_step 1680000	Train_loss: 0.2532	Eval_AUC: 0.8643
Epoch 20 Global_step 1681000	Train_loss: 0.2563	Eval_AUC: 0.8613
Epoch 20 Global_step 1682000	Train_loss: 0.2582	Eval_AUC: 0.8634
Epoch 20 Global_step 1683000	Train_loss: 0.2585	Eval_AUC: 0.8665
Epoch 20 Global_step 1684000	Train_loss: 0.2564	Eval_AUC: 0.8582
Epoch 20 Global_step 1685000	Train_loss: 0.2585	Eval_AUC: 0.8654
Epoch 20 Global_step 1686000	Train_loss: 0.2611	Eval_AUC: 0.8633
Epoch 20 Global_step 1687000	Train_loss: 0.2600	Eval_AUC: 0.8613
Epoch 20 Global_step 1688000	Train_loss: 0.2553	Eval_AUC: 0.8617
Epoch 20 Global_step 1689000	Train_loss: 0.2578	Eval_AUC: 0.8608
Epoch 20 Global_step 1690000	Train_loss: 0.2577	Eval_AUC: 0.8652
Epoch 20 Global_step 1691000	Train_loss: 0.2592	Eval_AUC: 0.8617
Epoch 20 Global_step 1692000	Train_loss: 0.2616	Eval_AUC: 0.8596
Epoch 20 Global_step 1693000	Train_loss: 0.2554	Eval_AUC: 0.8678
Epoch 20 Global_step 1694000	Train_loss: 0.2584	Eval_AUC: 0.8627
Epoch 20 Global_step 1695000	Train_loss: 0.2612	Eval_AUC: 0.8687
Epoch 20 Global_step 1696000	Train_loss: 0.2578	Eval_AUC: 0.8611
Epoch 20 Global_step 1697000	Train_loss: 0.2618	Eval_AUC: 0.8630
Epoch 20 Global_step 1698000	Train_loss: 0.2610	Eval_AUC: 0.8608
Epoch 20 Global_step 1699000	Train_loss: 0.2655	Eval_AUC: 0.8624
Epoch 20 Global_step 1700000	Train_loss: 0.2607	Eval_AUC: 0.8683
Epoch 20 Global_step 1701000	Train_loss: 0.2632	Eval_AUC: 0.8630
Epoch 20 Global_step 1702000	Train_loss: 0.2649	Eval_AUC: 0.8632
Epoch 20 Global_step 1703000	Train_loss: 0.2649	Eval_AUC: 0.8643
Epoch 20 Global_step 1704000	Train_loss: 0.2646	Eval_AUC: 0.8599
Epoch 20 Global_step 1705000	Train_loss: 0.2631	Eval_AUC: 0.8663
Epoch 20 Global_step 1706000	Train_loss: 0.2621	Eval_AUC: 0.8656
Epoch 20 Global_step 1707000	Train_loss: 0.2598	Eval_AUC: 0.8624
Epoch 20 Global_step 1708000	Train_loss: 0.2615	Eval_AUC: 0.8602
Epoch 20 Global_step 1709000	Train_loss: 0.2620	Eval_AUC: 0.8645
Epoch 20 Global_step 1710000	Train_loss: 0.2607	Eval_AUC: 0.8653
Epoch 20 Global_step 1711000	Train_loss: 0.2627	Eval_AUC: 0.8620
Epoch 20 Global_step 1712000	Train_loss: 0.2626	Eval_AUC: 0.8646
Epoch 20 DONE	Cost time: 169160.11
Epoch 21 Global_step 1713000	Train_loss: 0.2322	Eval_AUC: 0.8640
Epoch 21 Global_step 1714000	Train_loss: 0.2307	Eval_AUC: 0.8607
Epoch 21 Global_step 1715000	Train_loss: 0.2288	Eval_AUC: 0.8612
Epoch 21 Global_step 1716000	Train_loss: 0.2328	Eval_AUC: 0.8606
Epoch 21 Global_step 1717000	Train_loss: 0.2319	Eval_AUC: 0.8622
Epoch 21 Global_step 1718000	Train_loss: 0.2336	Eval_AUC: 0.8616
Epoch 21 Global_step 1719000	Train_loss: 0.2347	Eval_AUC: 0.8617
Epoch 21 Global_step 1720000	Train_loss: 0.2360	Eval_AUC: 0.8565
Epoch 21 Global_step 1721000	Train_loss: 0.2332	Eval_AUC: 0.8596
Epoch 21 Global_step 1722000	Train_loss: 0.2361	Eval_AUC: 0.8585
Epoch 21 Global_step 1723000	Train_loss: 0.2378	Eval_AUC: 0.8592
Epoch 21 Global_step 1724000	Train_loss: 0.2342	Eval_AUC: 0.8576
Epoch 21 Global_step 1725000	Train_loss: 0.2327	Eval_AUC: 0.8652
Epoch 21 Global_step 1726000	Train_loss: 0.2349	Eval_AUC: 0.8624
Epoch 21 Global_step 1727000	Train_loss: 0.2372	Eval_AUC: 0.8606
Epoch 21 Global_step 1728000	Train_loss: 0.2399	Eval_AUC: 0.8595
Epoch 21 Global_step 1729000	Train_loss: 0.2382	Eval_AUC: 0.8590
Epoch 21 Global_step 1730000	Train_loss: 0.2372	Eval_AUC: 0.8609
Epoch 21 Global_step 1731000	Train_loss: 0.2373	Eval_AUC: 0.8626
Epoch 21 Global_step 1732000	Train_loss: 0.2381	Eval_AUC: 0.8629
Epoch 21 Global_step 1733000	Train_loss: 0.2395	Eval_AUC: 0.8636
Epoch 21 Global_step 1734000	Train_loss: 0.2425	Eval_AUC: 0.8638
Epoch 21 Global_step 1735000	Train_loss: 0.2424	Eval_AUC: 0.8612
Epoch 21 Global_step 1736000	Train_loss: 0.2388	Eval_AUC: 0.8660
Epoch 21 Global_step 1737000	Train_loss: 0.2423	Eval_AUC: 0.8656
Epoch 21 Global_step 1738000	Train_loss: 0.2433	Eval_AUC: 0.8648
Epoch 21 Global_step 1739000	Train_loss: 0.2425	Eval_AUC: 0.8585
Epoch 21 Global_step 1740000	Train_loss: 0.2410	Eval_AUC: 0.8613
Epoch 21 Global_step 1741000	Train_loss: 0.2460	Eval_AUC: 0.8673
Epoch 21 Global_step 1742000	Train_loss: 0.2421	Eval_AUC: 0.8633
Epoch 21 Global_step 1743000	Train_loss: 0.2418	Eval_AUC: 0.8587
Epoch 21 Global_step 1744000	Train_loss: 0.2428	Eval_AUC: 0.8638
Epoch 21 Global_step 1745000	Train_loss: 0.2429	Eval_AUC: 0.8570
Epoch 21 Global_step 1746000	Train_loss: 0.2436	Eval_AUC: 0.8640
Epoch 21 Global_step 1747000	Train_loss: 0.2452	Eval_AUC: 0.8617
Epoch 21 Global_step 1748000	Train_loss: 0.2452	Eval_AUC: 0.8653
Epoch 21 Global_step 1749000	Train_loss: 0.2473	Eval_AUC: 0.8608
Epoch 21 Global_step 1750000	Train_loss: 0.2474	Eval_AUC: 0.8617
Epoch 21 Global_step 1751000	Train_loss: 0.2425	Eval_AUC: 0.8598
Epoch 21 Global_step 1752000	Train_loss: 0.2455	Eval_AUC: 0.8575
Epoch 21 Global_step 1753000	Train_loss: 0.2432	Eval_AUC: 0.8618
Epoch 21 Global_step 1754000	Train_loss: 0.2488	Eval_AUC: 0.8541
Epoch 21 Global_step 1755000	Train_loss: 0.2494	Eval_AUC: 0.8628
Epoch 21 Global_step 1756000	Train_loss: 0.2490	Eval_AUC: 0.8626
Epoch 21 Global_step 1757000	Train_loss: 0.2502	Eval_AUC: 0.8626
Epoch 21 Global_step 1758000	Train_loss: 0.2497	Eval_AUC: 0.8595
Epoch 21 Global_step 1759000	Train_loss: 0.2494	Eval_AUC: 0.8596
Epoch 21 Global_step 1760000	Train_loss: 0.2464	Eval_AUC: 0.8631
Epoch 21 Global_step 1761000	Train_loss: 0.2500	Eval_AUC: 0.8625
Epoch 21 Global_step 1762000	Train_loss: 0.2517	Eval_AUC: 0.8582
Epoch 21 Global_step 1763000	Train_loss: 0.2504	Eval_AUC: 0.8583
Epoch 21 Global_step 1764000	Train_loss: 0.2498	Eval_AUC: 0.8607
Epoch 21 Global_step 1765000	Train_loss: 0.2530	Eval_AUC: 0.8608
Epoch 21 Global_step 1766000	Train_loss: 0.2531	Eval_AUC: 0.8608
Epoch 21 Global_step 1767000	Train_loss: 0.2506	Eval_AUC: 0.8571
Epoch 21 Global_step 1768000	Train_loss: 0.2536	Eval_AUC: 0.8629
Epoch 21 Global_step 1769000	Train_loss: 0.2531	Eval_AUC: 0.8629
Epoch 21 Global_step 1770000	Train_loss: 0.2529	Eval_AUC: 0.8619
Epoch 21 Global_step 1771000	Train_loss: 0.2543	Eval_AUC: 0.8632
Epoch 21 Global_step 1772000	Train_loss: 0.2542	Eval_AUC: 0.8648
Epoch 21 Global_step 1773000	Train_loss: 0.2531	Eval_AUC: 0.8596
Epoch 21 Global_step 1774000	Train_loss: 0.2539	Eval_AUC: 0.8654
Epoch 21 Global_step 1775000	Train_loss: 0.2518	Eval_AUC: 0.8623
Epoch 21 Global_step 1776000	Train_loss: 0.2552	Eval_AUC: 0.8642
Epoch 21 Global_step 1777000	Train_loss: 0.2581	Eval_AUC: 0.8603
Epoch 21 Global_step 1778000	Train_loss: 0.2536	Eval_AUC: 0.8583
Epoch 21 Global_step 1779000	Train_loss: 0.2538	Eval_AUC: 0.8637
Epoch 21 Global_step 1780000	Train_loss: 0.2533	Eval_AUC: 0.8619
Epoch 21 Global_step 1781000	Train_loss: 0.2547	Eval_AUC: 0.8640
Epoch 21 Global_step 1782000	Train_loss: 0.2540	Eval_AUC: 0.8670
Epoch 21 Global_step 1783000	Train_loss: 0.2563	Eval_AUC: 0.8624
Epoch 21 Global_step 1784000	Train_loss: 0.2575	Eval_AUC: 0.8639
Epoch 21 Global_step 1785000	Train_loss: 0.2554	Eval_AUC: 0.8630
Epoch 21 Global_step 1786000	Train_loss: 0.2566	Eval_AUC: 0.8612
Epoch 21 Global_step 1787000	Train_loss: 0.2593	Eval_AUC: 0.8634
Epoch 21 Global_step 1788000	Train_loss: 0.2590	Eval_AUC: 0.8636
Epoch 21 Global_step 1789000	Train_loss: 0.2551	Eval_AUC: 0.8627
Epoch 21 Global_step 1790000	Train_loss: 0.2586	Eval_AUC: 0.8620
Epoch 21 Global_step 1791000	Train_loss: 0.2564	Eval_AUC: 0.8638
Epoch 21 Global_step 1792000	Train_loss: 0.2562	Eval_AUC: 0.8672
Epoch 21 Global_step 1793000	Train_loss: 0.2544	Eval_AUC: 0.8595
Epoch 21 DONE	Cost time: 176337.40
Epoch 22 Global_step 1794000	Train_loss: 0.2422	Eval_AUC: 0.8619
Epoch 22 Global_step 1795000	Train_loss: 0.2247	Eval_AUC: 0.8620
Epoch 22 Global_step 1796000	Train_loss: 0.2243	Eval_AUC: 0.8573
Epoch 22 Global_step 1797000	Train_loss: 0.2248	Eval_AUC: 0.8633
Epoch 22 Global_step 1798000	Train_loss: 0.2263	Eval_AUC: 0.8547
Epoch 22 Global_step 1799000	Train_loss: 0.2286	Eval_AUC: 0.8606
Epoch 22 Global_step 1800000	Train_loss: 0.2298	Eval_AUC: 0.8612
Epoch 22 Global_step 1801000	Train_loss: 0.2279	Eval_AUC: 0.8612
Epoch 22 Global_step 1802000	Train_loss: 0.2295	Eval_AUC: 0.8616
Epoch 22 Global_step 1803000	Train_loss: 0.2319	Eval_AUC: 0.8577
Epoch 22 Global_step 1804000	Train_loss: 0.2256	Eval_AUC: 0.8624
Epoch 22 Global_step 1805000	Train_loss: 0.2285	Eval_AUC: 0.8606
Epoch 22 Global_step 1806000	Train_loss: 0.2309	Eval_AUC: 0.8607
Epoch 22 Global_step 1807000	Train_loss: 0.2288	Eval_AUC: 0.8583
Epoch 22 Global_step 1808000	Train_loss: 0.2320	Eval_AUC: 0.8613
Epoch 22 Global_step 1809000	Train_loss: 0.2346	Eval_AUC: 0.8611
Epoch 22 Global_step 1810000	Train_loss: 0.2282	Eval_AUC: 0.8580
Epoch 22 Global_step 1811000	Train_loss: 0.2329	Eval_AUC: 0.8630
Epoch 22 Global_step 1812000	Train_loss: 0.2302	Eval_AUC: 0.8588
Epoch 22 Global_step 1813000	Train_loss: 0.2302	Eval_AUC: 0.8581
Epoch 22 Global_step 1814000	Train_loss: 0.2304	Eval_AUC: 0.8564
Epoch 22 Global_step 1815000	Train_loss: 0.2378	Eval_AUC: 0.8597
Epoch 22 Global_step 1816000	Train_loss: 0.2337	Eval_AUC: 0.8601
Epoch 22 Global_step 1817000	Train_loss: 0.2344	Eval_AUC: 0.8585
Epoch 22 Global_step 1818000	Train_loss: 0.2345	Eval_AUC: 0.8639
Epoch 22 Global_step 1819000	Train_loss: 0.2331	Eval_AUC: 0.8615
Epoch 22 Global_step 1820000	Train_loss: 0.2355	Eval_AUC: 0.8591
Epoch 22 Global_step 1821000	Train_loss: 0.2378	Eval_AUC: 0.8608
Epoch 22 Global_step 1822000	Train_loss: 0.2366	Eval_AUC: 0.8613
Epoch 22 Global_step 1823000	Train_loss: 0.2365	Eval_AUC: 0.8613
Epoch 22 Global_step 1824000	Train_loss: 0.2348	Eval_AUC: 0.8588
Epoch 22 Global_step 1825000	Train_loss: 0.2403	Eval_AUC: 0.8554
Epoch 22 Global_step 1826000	Train_loss: 0.2356	Eval_AUC: 0.8614
Epoch 22 Global_step 1827000	Train_loss: 0.2376	Eval_AUC: 0.8608
Epoch 22 Global_step 1828000	Train_loss: 0.2390	Eval_AUC: 0.8592
Epoch 22 Global_step 1829000	Train_loss: 0.2360	Eval_AUC: 0.8599
Epoch 22 Global_step 1830000	Train_loss: 0.2397	Eval_AUC: 0.8636
Epoch 22 Global_step 1831000	Train_loss: 0.2408	Eval_AUC: 0.8559
Epoch 22 Global_step 1832000	Train_loss: 0.2398	Eval_AUC: 0.8601
Epoch 22 Global_step 1833000	Train_loss: 0.2446	Eval_AUC: 0.8656
Epoch 22 Global_step 1834000	Train_loss: 0.2420	Eval_AUC: 0.8534
Epoch 22 Global_step 1835000	Train_loss: 0.2449	Eval_AUC: 0.8561
Epoch 22 Global_step 1836000	Train_loss: 0.2407	Eval_AUC: 0.8611
Epoch 22 Global_step 1837000	Train_loss: 0.2441	Eval_AUC: 0.8593
Epoch 22 Global_step 1838000	Train_loss: 0.2371	Eval_AUC: 0.8637
Epoch 22 Global_step 1839000	Train_loss: 0.2422	Eval_AUC: 0.8650
Epoch 22 Global_step 1840000	Train_loss: 0.2446	Eval_AUC: 0.8590
Epoch 22 Global_step 1841000	Train_loss: 0.2399	Eval_AUC: 0.8588
Epoch 22 Global_step 1842000	Train_loss: 0.2452	Eval_AUC: 0.8549
Epoch 22 Global_step 1843000	Train_loss: 0.2418	Eval_AUC: 0.8637
Epoch 22 Global_step 1844000	Train_loss: 0.2409	Eval_AUC: 0.8631
Epoch 22 Global_step 1845000	Train_loss: 0.2437	Eval_AUC: 0.8583
Epoch 22 Global_step 1846000	Train_loss: 0.2436	Eval_AUC: 0.8569
Epoch 22 Global_step 1847000	Train_loss: 0.2465	Eval_AUC: 0.8595
Epoch 22 Global_step 1848000	Train_loss: 0.2460	Eval_AUC: 0.8569
Epoch 22 Global_step 1849000	Train_loss: 0.2430	Eval_AUC: 0.8616
Epoch 22 Global_step 1850000	Train_loss: 0.2454	Eval_AUC: 0.8585
Epoch 22 Global_step 1851000	Train_loss: 0.2457	Eval_AUC: 0.8584
Epoch 22 Global_step 1852000	Train_loss: 0.2443	Eval_AUC: 0.8588
Epoch 22 Global_step 1853000	Train_loss: 0.2492	Eval_AUC: 0.8626
Epoch 22 Global_step 1854000	Train_loss: 0.2458	Eval_AUC: 0.8623
Epoch 22 Global_step 1855000	Train_loss: 0.2469	Eval_AUC: 0.8621
Epoch 22 Global_step 1856000	Train_loss: 0.2446	Eval_AUC: 0.8611
Epoch 22 Global_step 1857000	Train_loss: 0.2476	Eval_AUC: 0.8601
Epoch 22 Global_step 1858000	Train_loss: 0.2489	Eval_AUC: 0.8623
Epoch 22 Global_step 1859000	Train_loss: 0.2492	Eval_AUC: 0.8617
Epoch 22 Global_step 1860000	Train_loss: 0.2487	Eval_AUC: 0.8626
Epoch 22 Global_step 1861000	Train_loss: 0.2507	Eval_AUC: 0.8620
Epoch 22 Global_step 1862000	Train_loss: 0.2476	Eval_AUC: 0.8571
Epoch 22 Global_step 1863000	Train_loss: 0.2480	Eval_AUC: 0.8595
Epoch 22 Global_step 1864000	Train_loss: 0.2501	Eval_AUC: 0.8590
Epoch 22 Global_step 1865000	Train_loss: 0.2483	Eval_AUC: 0.8640
Epoch 22 Global_step 1866000	Train_loss: 0.2470	Eval_AUC: 0.8604
Epoch 22 Global_step 1867000	Train_loss: 0.2484	Eval_AUC: 0.8605
Epoch 22 Global_step 1868000	Train_loss: 0.2486	Eval_AUC: 0.8566
Epoch 22 Global_step 1869000	Train_loss: 0.2496	Eval_AUC: 0.8622
Epoch 22 Global_step 1870000	Train_loss: 0.2505	Eval_AUC: 0.8635
Epoch 22 Global_step 1871000	Train_loss: 0.2530	Eval_AUC: 0.8631
Epoch 22 Global_step 1872000	Train_loss: 0.2489	Eval_AUC: 0.8633
Epoch 22 Global_step 1873000	Train_loss: 0.2534	Eval_AUC: 0.8625
Epoch 22 Global_step 1874000	Train_loss: 0.2510	Eval_AUC: 0.8573
Epoch 22 Global_step 1875000	Train_loss: 0.2507	Eval_AUC: 0.8613
Epoch 22 DONE	Cost time: 183573.65
Epoch 23 Global_step 1876000	Train_loss: 0.2248	Eval_AUC: 0.8577
Epoch 23 Global_step 1877000	Train_loss: 0.2195	Eval_AUC: 0.8580
Epoch 23 Global_step 1878000	Train_loss: 0.2180	Eval_AUC: 0.8620
Epoch 23 Global_step 1879000	Train_loss: 0.2190	Eval_AUC: 0.8598
Epoch 23 Global_step 1880000	Train_loss: 0.2196	Eval_AUC: 0.8618
Epoch 23 Global_step 1881000	Train_loss: 0.2196	Eval_AUC: 0.8561
Epoch 23 Global_step 1882000	Train_loss: 0.2211	Eval_AUC: 0.8605
Epoch 23 Global_step 1883000	Train_loss: 0.2181	Eval_AUC: 0.8579
Epoch 23 Global_step 1884000	Train_loss: 0.2251	Eval_AUC: 0.8618
Epoch 23 Global_step 1885000	Train_loss: 0.2230	Eval_AUC: 0.8563
Epoch 23 Global_step 1886000	Train_loss: 0.2222	Eval_AUC: 0.8551
Epoch 23 Global_step 1887000	Train_loss: 0.2211	Eval_AUC: 0.8612
Epoch 23 Global_step 1888000	Train_loss: 0.2209	Eval_AUC: 0.8579
Epoch 23 Global_step 1889000	Train_loss: 0.2267	Eval_AUC: 0.8608
Epoch 23 Global_step 1890000	Train_loss: 0.2245	Eval_AUC: 0.8578
Epoch 23 Global_step 1891000	Train_loss: 0.2267	Eval_AUC: 0.8585
Epoch 23 Global_step 1892000	Train_loss: 0.2294	Eval_AUC: 0.8578
Epoch 23 Global_step 1893000	Train_loss: 0.2272	Eval_AUC: 0.8554
Epoch 23 Global_step 1894000	Train_loss: 0.2232	Eval_AUC: 0.8618
Epoch 23 Global_step 1895000	Train_loss: 0.2238	Eval_AUC: 0.8561
Epoch 23 Global_step 1896000	Train_loss: 0.2267	Eval_AUC: 0.8547
Epoch 23 Global_step 1897000	Train_loss: 0.2301	Eval_AUC: 0.8555
Epoch 23 Global_step 1898000	Train_loss: 0.2303	Eval_AUC: 0.8590
Epoch 23 Global_step 1899000	Train_loss: 0.2292	Eval_AUC: 0.8587
Epoch 23 Global_step 1900000	Train_loss: 0.2301	Eval_AUC: 0.8571
Epoch 23 Global_step 1901000	Train_loss: 0.2277	Eval_AUC: 0.8578
Epoch 23 Global_step 1902000	Train_loss: 0.2308	Eval_AUC: 0.8597
Epoch 23 Global_step 1903000	Train_loss: 0.2279	Eval_AUC: 0.8601
Epoch 23 Global_step 1904000	Train_loss: 0.2309	Eval_AUC: 0.8589
Epoch 23 Global_step 1905000	Train_loss: 0.2340	Eval_AUC: 0.8593
Epoch 23 Global_step 1906000	Train_loss: 0.2309	Eval_AUC: 0.8600
Epoch 23 Global_step 1907000	Train_loss: 0.2310	Eval_AUC: 0.8576
Epoch 23 Global_step 1908000	Train_loss: 0.2333	Eval_AUC: 0.8626
Epoch 23 Global_step 1909000	Train_loss: 0.2319	Eval_AUC: 0.8604
Epoch 23 Global_step 1910000	Train_loss: 0.2326	Eval_AUC: 0.8565
Epoch 23 Global_step 1911000	Train_loss: 0.2343	Eval_AUC: 0.8623
Epoch 23 Global_step 1912000	Train_loss: 0.2305	Eval_AUC: 0.8552
Epoch 23 Global_step 1913000	Train_loss: 0.2334	Eval_AUC: 0.8545
Epoch 23 Global_step 1914000	Train_loss: 0.2364	Eval_AUC: 0.8621
Epoch 23 Global_step 1915000	Train_loss: 0.2370	Eval_AUC: 0.8584
Epoch 23 Global_step 1916000	Train_loss: 0.2338	Eval_AUC: 0.8605
Epoch 23 Global_step 1917000	Train_loss: 0.2345	Eval_AUC: 0.8569
Epoch 23 Global_step 1918000	Train_loss: 0.2354	Eval_AUC: 0.8609
Epoch 23 Global_step 1919000	Train_loss: 0.2325	Eval_AUC: 0.8590
Epoch 23 Global_step 1920000	Train_loss: 0.2357	Eval_AUC: 0.8576
Epoch 23 Global_step 1921000	Train_loss: 0.2370	Eval_AUC: 0.8589
Epoch 23 Global_step 1922000	Train_loss: 0.2365	Eval_AUC: 0.8570
Epoch 23 Global_step 1923000	Train_loss: 0.2409	Eval_AUC: 0.8576
Epoch 23 Global_step 1924000	Train_loss: 0.2395	Eval_AUC: 0.8628
Epoch 23 Global_step 1925000	Train_loss: 0.2383	Eval_AUC: 0.8587
Epoch 23 Global_step 1926000	Train_loss: 0.2361	Eval_AUC: 0.8633
Epoch 23 Global_step 1927000	Train_loss: 0.2381	Eval_AUC: 0.8634
Epoch 23 Global_step 1928000	Train_loss: 0.2392	Eval_AUC: 0.8625
Epoch 23 Global_step 1929000	Train_loss: 0.2357	Eval_AUC: 0.8604
Epoch 23 Global_step 1930000	Train_loss: 0.2375	Eval_AUC: 0.8542
Epoch 23 Global_step 1931000	Train_loss: 0.2386	Eval_AUC: 0.8606
Epoch 23 Global_step 1932000	Train_loss: 0.2388	Eval_AUC: 0.8632
Epoch 23 Global_step 1933000	Train_loss: 0.2401	Eval_AUC: 0.8573
Epoch 23 Global_step 1934000	Train_loss: 0.2452	Eval_AUC: 0.8617
Epoch 23 Global_step 1935000	Train_loss: 0.2395	Eval_AUC: 0.8549
Epoch 23 Global_step 1936000	Train_loss: 0.2435	Eval_AUC: 0.8629
Epoch 23 Global_step 1937000	Train_loss: 0.2401	Eval_AUC: 0.8607
Epoch 23 Global_step 1938000	Train_loss: 0.2429	Eval_AUC: 0.8609
Epoch 23 Global_step 1939000	Train_loss: 0.2414	Eval_AUC: 0.8616
Epoch 23 Global_step 1940000	Train_loss: 0.2413	Eval_AUC: 0.8573
Epoch 23 Global_step 1941000	Train_loss: 0.2395	Eval_AUC: 0.8632
Epoch 23 Global_step 1942000	Train_loss: 0.2405	Eval_AUC: 0.8593
Epoch 23 Global_step 1943000	Train_loss: 0.2407	Eval_AUC: 0.8574
Epoch 23 Global_step 1944000	Train_loss: 0.2426	Eval_AUC: 0.8567
Epoch 23 Global_step 1945000	Train_loss: 0.2404	Eval_AUC: 0.8609
Epoch 23 Global_step 1946000	Train_loss: 0.2412	Eval_AUC: 0.8602
Epoch 23 Global_step 1947000	Train_loss: 0.2407	Eval_AUC: 0.8627
Epoch 23 Global_step 1948000	Train_loss: 0.2454	Eval_AUC: 0.8592
Epoch 23 Global_step 1949000	Train_loss: 0.2458	Eval_AUC: 0.8581
Epoch 23 Global_step 1950000	Train_loss: 0.2379	Eval_AUC: 0.8563
Epoch 23 Global_step 1951000	Train_loss: 0.2462	Eval_AUC: 0.8616
Epoch 23 Global_step 1952000	Train_loss: 0.2463	Eval_AUC: 0.8644
Epoch 23 Global_step 1953000	Train_loss: 0.2429	Eval_AUC: 0.8566
Epoch 23 Global_step 1954000	Train_loss: 0.2444	Eval_AUC: 0.8624
Epoch 23 Global_step 1955000	Train_loss: 0.2451	Eval_AUC: 0.8594
Epoch 23 Global_step 1956000	Train_loss: 0.2468	Eval_AUC: 0.8609
Epoch 23 DONE	Cost time: 190733.00
Epoch 24 Global_step 1957000	Train_loss: 0.2316	Eval_AUC: 0.8603
Epoch 24 Global_step 1958000	Train_loss: 0.2099	Eval_AUC: 0.8617
Epoch 24 Global_step 1959000	Train_loss: 0.2178	Eval_AUC: 0.8582
Epoch 24 Global_step 1960000	Train_loss: 0.2112	Eval_AUC: 0.8569
Epoch 24 Global_step 1961000	Train_loss: 0.2151	Eval_AUC: 0.8547
Epoch 24 Global_step 1962000	Train_loss: 0.2170	Eval_AUC: 0.8557
Epoch 24 Global_step 1963000	Train_loss: 0.2189	Eval_AUC: 0.8579
Epoch 24 Global_step 1964000	Train_loss: 0.2163	Eval_AUC: 0.8562
Epoch 24 Global_step 1965000	Train_loss: 0.2150	Eval_AUC: 0.8544
Epoch 24 Global_step 1966000	Train_loss: 0.2168	Eval_AUC: 0.8595
Epoch 24 Global_step 1967000	Train_loss: 0.2146	Eval_AUC: 0.8563
Epoch 24 Global_step 1968000	Train_loss: 0.2187	Eval_AUC: 0.8540
Epoch 24 Global_step 1969000	Train_loss: 0.2215	Eval_AUC: 0.8571
Epoch 24 Global_step 1970000	Train_loss: 0.2176	Eval_AUC: 0.8558
Epoch 24 Global_step 1971000	Train_loss: 0.2171	Eval_AUC: 0.8601
Epoch 24 Global_step 1972000	Train_loss: 0.2174	Eval_AUC: 0.8608
Epoch 24 Global_step 1973000	Train_loss: 0.2197	Eval_AUC: 0.8584
Epoch 24 Global_step 1974000	Train_loss: 0.2201	Eval_AUC: 0.8565
Epoch 24 Global_step 1975000	Train_loss: 0.2181	Eval_AUC: 0.8553
Epoch 24 Global_step 1976000	Train_loss: 0.2196	Eval_AUC: 0.8589
Epoch 24 Global_step 1977000	Train_loss: 0.2237	Eval_AUC: 0.8572
Epoch 24 Global_step 1978000	Train_loss: 0.2227	Eval_AUC: 0.8532
Epoch 24 Global_step 1979000	Train_loss: 0.2214	Eval_AUC: 0.8581
Epoch 24 Global_step 1980000	Train_loss: 0.2249	Eval_AUC: 0.8564
Epoch 24 Global_step 1981000	Train_loss: 0.2250	Eval_AUC: 0.8545
Epoch 24 Global_step 1982000	Train_loss: 0.2237	Eval_AUC: 0.8561
Epoch 24 Global_step 1983000	Train_loss: 0.2234	Eval_AUC: 0.8515
Epoch 24 Global_step 1984000	Train_loss: 0.2266	Eval_AUC: 0.8545
Epoch 24 Global_step 1985000	Train_loss: 0.2258	Eval_AUC: 0.8545
Epoch 24 Global_step 1986000	Train_loss: 0.2257	Eval_AUC: 0.8558
Epoch 24 Global_step 1987000	Train_loss: 0.2237	Eval_AUC: 0.8586
Epoch 24 Global_step 1988000	Train_loss: 0.2247	Eval_AUC: 0.8606
Epoch 24 Global_step 1989000	Train_loss: 0.2232	Eval_AUC: 0.8583
Epoch 24 Global_step 1990000	Train_loss: 0.2277	Eval_AUC: 0.8555
Epoch 24 Global_step 1991000	Train_loss: 0.2260	Eval_AUC: 0.8588
Epoch 24 Global_step 1992000	Train_loss: 0.2225	Eval_AUC: 0.8561
Epoch 24 Global_step 1993000	Train_loss: 0.2283	Eval_AUC: 0.8609
Epoch 24 Global_step 1994000	Train_loss: 0.2297	Eval_AUC: 0.8559
Epoch 24 Global_step 1995000	Train_loss: 0.2281	Eval_AUC: 0.8565
Epoch 24 Global_step 1996000	Train_loss: 0.2275	Eval_AUC: 0.8603
Epoch 24 Global_step 1997000	Train_loss: 0.2275	Eval_AUC: 0.8592
Epoch 24 Global_step 1998000	Train_loss: 0.2260	Eval_AUC: 0.8601
Epoch 24 Global_step 1999000	Train_loss: 0.2300	Eval_AUC: 0.8573
Epoch 24 Global_step 2000000	Train_loss: 0.2308	Eval_AUC: 0.8540
Epoch 24 Global_step 2001000	Train_loss: 0.2324	Eval_AUC: 0.8571
Epoch 24 Global_step 2002000	Train_loss: 0.2275	Eval_AUC: 0.8609
Epoch 24 Global_step 2003000	Train_loss: 0.2290	Eval_AUC: 0.8571
Epoch 24 Global_step 2004000	Train_loss: 0.2279	Eval_AUC: 0.8598
Epoch 24 Global_step 2005000	Train_loss: 0.2308	Eval_AUC: 0.8561
Epoch 24 Global_step 2006000	Train_loss: 0.2307	Eval_AUC: 0.8571
Epoch 24 Global_step 2007000	Train_loss: 0.2314	Eval_AUC: 0.8570
Epoch 24 Global_step 2008000	Train_loss: 0.2301	Eval_AUC: 0.8544
Epoch 24 Global_step 2009000	Train_loss: 0.2329	Eval_AUC: 0.8575
Epoch 24 Global_step 2010000	Train_loss: 0.2273	Eval_AUC: 0.8556
Epoch 24 Global_step 2011000	Train_loss: 0.2334	Eval_AUC: 0.8606
Epoch 24 Global_step 2012000	Train_loss: 0.2301	Eval_AUC: 0.8563
Epoch 24 Global_step 2013000	Train_loss: 0.2310	Eval_AUC: 0.8540
Epoch 24 Global_step 2014000	Train_loss: 0.2324	Eval_AUC: 0.8548
Epoch 24 Global_step 2015000	Train_loss: 0.2349	Eval_AUC: 0.8606
Epoch 24 Global_step 2016000	Train_loss: 0.2339	Eval_AUC: 0.8573
Epoch 24 Global_step 2017000	Train_loss: 0.2370	Eval_AUC: 0.8614
Epoch 24 Global_step 2018000	Train_loss: 0.2343	Eval_AUC: 0.8575
Epoch 24 Global_step 2019000	Train_loss: 0.2326	Eval_AUC: 0.8622
Epoch 24 Global_step 2020000	Train_loss: 0.2343	Eval_AUC: 0.8604
Epoch 24 Global_step 2021000	Train_loss: 0.2371	Eval_AUC: 0.8590
Epoch 24 Global_step 2022000	Train_loss: 0.2385	Eval_AUC: 0.8578
Epoch 24 Global_step 2023000	Train_loss: 0.2369	Eval_AUC: 0.8576
Epoch 24 Global_step 2024000	Train_loss: 0.2346	Eval_AUC: 0.8625
Epoch 24 Global_step 2025000	Train_loss: 0.2385	Eval_AUC: 0.8529
Epoch 24 Global_step 2026000	Train_loss: 0.2367	Eval_AUC: 0.8596
Epoch 24 Global_step 2027000	Train_loss: 0.2349	Eval_AUC: 0.8600
Epoch 24 Global_step 2028000	Train_loss: 0.2389	Eval_AUC: 0.8602
Epoch 24 Global_step 2029000	Train_loss: 0.2332	Eval_AUC: 0.8619
Epoch 24 Global_step 2030000	Train_loss: 0.2366	Eval_AUC: 0.8543
Epoch 24 Global_step 2031000	Train_loss: 0.2366	Eval_AUC: 0.8607
Epoch 24 Global_step 2032000	Train_loss: 0.2389	Eval_AUC: 0.8559
Epoch 24 Global_step 2033000	Train_loss: 0.2403	Eval_AUC: 0.8561
Epoch 24 Global_step 2034000	Train_loss: 0.2378	Eval_AUC: 0.8565
Epoch 24 Global_step 2035000	Train_loss: 0.2409	Eval_AUC: 0.8609
Epoch 24 Global_step 2036000	Train_loss: 0.2400	Eval_AUC: 0.8626
Epoch 24 Global_step 2037000	Train_loss: 0.2395	Eval_AUC: 0.8573
Epoch 24 Global_step 2038000	Train_loss: 0.2372	Eval_AUC: 0.8558
Epoch 24 DONE	Cost time: 197944.50
Epoch 25 Global_step 2039000	Train_loss: 0.2109	Eval_AUC: 0.8578
Epoch 25 Global_step 2040000	Train_loss: 0.2062	Eval_AUC: 0.8599
Epoch 25 Global_step 2041000	Train_loss: 0.2087	Eval_AUC: 0.8587
Epoch 25 Global_step 2042000	Train_loss: 0.2091	Eval_AUC: 0.8550
Epoch 25 Global_step 2043000	Train_loss: 0.2078	Eval_AUC: 0.8539
Epoch 25 Global_step 2044000	Train_loss: 0.2117	Eval_AUC: 0.8569
Epoch 25 Global_step 2045000	Train_loss: 0.2071	Eval_AUC: 0.8559
Epoch 25 Global_step 2046000	Train_loss: 0.2096	Eval_AUC: 0.8521
Epoch 25 Global_step 2047000	Train_loss: 0.2123	Eval_AUC: 0.8546
Epoch 25 Global_step 2048000	Train_loss: 0.2126	Eval_AUC: 0.8573
Epoch 25 Global_step 2049000	Train_loss: 0.2097	Eval_AUC: 0.8554
Epoch 25 Global_step 2050000	Train_loss: 0.2125	Eval_AUC: 0.8547
Epoch 25 Global_step 2051000	Train_loss: 0.2089	Eval_AUC: 0.8522
Epoch 25 Global_step 2052000	Train_loss: 0.2167	Eval_AUC: 0.8513
Epoch 25 Global_step 2053000	Train_loss: 0.2153	Eval_AUC: 0.8546
Epoch 25 Global_step 2054000	Train_loss: 0.2147	Eval_AUC: 0.8538
Epoch 25 Global_step 2055000	Train_loss: 0.2163	Eval_AUC: 0.8589
Epoch 25 Global_step 2056000	Train_loss: 0.2148	Eval_AUC: 0.8531
Epoch 25 Global_step 2057000	Train_loss: 0.2159	Eval_AUC: 0.8568
Epoch 25 Global_step 2058000	Train_loss: 0.2217	Eval_AUC: 0.8525
Epoch 25 Global_step 2059000	Train_loss: 0.2169	Eval_AUC: 0.8526
Epoch 25 Global_step 2060000	Train_loss: 0.2155	Eval_AUC: 0.8545
Epoch 25 Global_step 2061000	Train_loss: 0.2142	Eval_AUC: 0.8621
Epoch 25 Global_step 2062000	Train_loss: 0.2185	Eval_AUC: 0.8579
Epoch 25 Global_step 2063000	Train_loss: 0.2164	Eval_AUC: 0.8554
Epoch 25 Global_step 2064000	Train_loss: 0.2175	Eval_AUC: 0.8511
Epoch 25 Global_step 2065000	Train_loss: 0.2180	Eval_AUC: 0.8563
Epoch 25 Global_step 2066000	Train_loss: 0.2211	Eval_AUC: 0.8562
Epoch 25 Global_step 2067000	Train_loss: 0.2199	Eval_AUC: 0.8582
Epoch 25 Global_step 2068000	Train_loss: 0.2163	Eval_AUC: 0.8604
Epoch 25 Global_step 2069000	Train_loss: 0.2192	Eval_AUC: 0.8554
Epoch 25 Global_step 2070000	Train_loss: 0.2201	Eval_AUC: 0.8584
Epoch 25 Global_step 2071000	Train_loss: 0.2181	Eval_AUC: 0.8573
Epoch 25 Global_step 2072000	Train_loss: 0.2227	Eval_AUC: 0.8557
Epoch 25 Global_step 2073000	Train_loss: 0.2234	Eval_AUC: 0.8526
Epoch 25 Global_step 2074000	Train_loss: 0.2210	Eval_AUC: 0.8545
Epoch 25 Global_step 2075000	Train_loss: 0.2195	Eval_AUC: 0.8574
Epoch 25 Global_step 2076000	Train_loss: 0.2208	Eval_AUC: 0.8577
Epoch 25 Global_step 2077000	Train_loss: 0.2247	Eval_AUC: 0.8551
Epoch 25 Global_step 2078000	Train_loss: 0.2252	Eval_AUC: 0.8538
Epoch 25 Global_step 2079000	Train_loss: 0.2205	Eval_AUC: 0.8592
Epoch 25 Global_step 2080000	Train_loss: 0.2241	Eval_AUC: 0.8505
Epoch 25 Global_step 2081000	Train_loss: 0.2241	Eval_AUC: 0.8583
Epoch 25 Global_step 2082000	Train_loss: 0.2222	Eval_AUC: 0.8544
Epoch 25 Global_step 2083000	Train_loss: 0.2217	Eval_AUC: 0.8590
Epoch 25 Global_step 2084000	Train_loss: 0.2232	Eval_AUC: 0.8577
Epoch 25 Global_step 2085000	Train_loss: 0.2244	Eval_AUC: 0.8561
Epoch 25 Global_step 2086000	Train_loss: 0.2260	Eval_AUC: 0.8599
Epoch 25 Global_step 2087000	Train_loss: 0.2202	Eval_AUC: 0.8593
Epoch 25 Global_step 2088000	Train_loss: 0.2228	Eval_AUC: 0.8554
Epoch 25 Global_step 2089000	Train_loss: 0.2260	Eval_AUC: 0.8570
Epoch 25 Global_step 2090000	Train_loss: 0.2238	Eval_AUC: 0.8574
Epoch 25 Global_step 2091000	Train_loss: 0.2254	Eval_AUC: 0.8521
Epoch 25 Global_step 2092000	Train_loss: 0.2261	Eval_AUC: 0.8578
Epoch 25 Global_step 2093000	Train_loss: 0.2266	Eval_AUC: 0.8537
Epoch 25 Global_step 2094000	Train_loss: 0.2255	Eval_AUC: 0.8538
Epoch 25 Global_step 2095000	Train_loss: 0.2280	Eval_AUC: 0.8545
Epoch 25 Global_step 2096000	Train_loss: 0.2277	Eval_AUC: 0.8528
Epoch 25 Global_step 2097000	Train_loss: 0.2274	Eval_AUC: 0.8578
Epoch 25 Global_step 2098000	Train_loss: 0.2261	Eval_AUC: 0.8576
Epoch 25 Global_step 2099000	Train_loss: 0.2284	Eval_AUC: 0.8585
Epoch 25 Global_step 2100000	Train_loss: 0.2276	Eval_AUC: 0.8562
Epoch 25 Global_step 2101000	Train_loss: 0.2293	Eval_AUC: 0.8554
Epoch 25 Global_step 2102000	Train_loss: 0.2314	Eval_AUC: 0.8559
Epoch 25 Global_step 2103000	Train_loss: 0.2300	Eval_AUC: 0.8496
Epoch 25 Global_step 2104000	Train_loss: 0.2292	Eval_AUC: 0.8525
Epoch 25 Global_step 2105000	Train_loss: 0.2300	Eval_AUC: 0.8581
Epoch 25 Global_step 2106000	Train_loss: 0.2297	Eval_AUC: 0.8575
Epoch 25 Global_step 2107000	Train_loss: 0.2325	Eval_AUC: 0.8574
Epoch 25 Global_step 2108000	Train_loss: 0.2307	Eval_AUC: 0.8613
Epoch 25 Global_step 2109000	Train_loss: 0.2307	Eval_AUC: 0.8595
Epoch 25 Global_step 2110000	Train_loss: 0.2287	Eval_AUC: 0.8532
Epoch 25 Global_step 2111000	Train_loss: 0.2354	Eval_AUC: 0.8590
Epoch 25 Global_step 2112000	Train_loss: 0.2304	Eval_AUC: 0.8545
Epoch 25 Global_step 2113000	Train_loss: 0.2296	Eval_AUC: 0.8581
Epoch 25 Global_step 2114000	Train_loss: 0.2328	Eval_AUC: 0.8587
Epoch 25 Global_step 2115000	Train_loss: 0.2338	Eval_AUC: 0.8595
Epoch 25 Global_step 2116000	Train_loss: 0.2342	Eval_AUC: 0.8564
Epoch 25 Global_step 2117000	Train_loss: 0.2358	Eval_AUC: 0.8557
Epoch 25 Global_step 2118000	Train_loss: 0.2290	Eval_AUC: 0.8545
Epoch 25 Global_step 2119000	Train_loss: 0.2308	Eval_AUC: 0.8582
Epoch 25 DONE	Cost time: 205107.87
Epoch 26 Global_step 2120000	Train_loss: 0.2249	Eval_AUC: 0.8576
Epoch 26 Global_step 2121000	Train_loss: 0.2019	Eval_AUC: 0.8555
Epoch 26 Global_step 2122000	Train_loss: 0.2024	Eval_AUC: 0.8581
Epoch 26 Global_step 2123000	Train_loss: 0.2043	Eval_AUC: 0.8539
Epoch 26 Global_step 2124000	Train_loss: 0.2033	Eval_AUC: 0.8553
Epoch 26 Global_step 2125000	Train_loss: 0.2040	Eval_AUC: 0.8555
Epoch 26 Global_step 2126000	Train_loss: 0.2064	Eval_AUC: 0.8541
Epoch 26 Global_step 2127000	Train_loss: 0.2058	Eval_AUC: 0.8549
Epoch 26 Global_step 2128000	Train_loss: 0.2080	Eval_AUC: 0.8509
Epoch 26 Global_step 2129000	Train_loss: 0.2023	Eval_AUC: 0.8512
Epoch 26 Global_step 2130000	Train_loss: 0.2060	Eval_AUC: 0.8552
Epoch 26 Global_step 2131000	Train_loss: 0.2047	Eval_AUC: 0.8547
Epoch 26 Global_step 2132000	Train_loss: 0.2080	Eval_AUC: 0.8508
Epoch 26 Global_step 2133000	Train_loss: 0.2058	Eval_AUC: 0.8514
Epoch 26 Global_step 2134000	Train_loss: 0.2093	Eval_AUC: 0.8564
Epoch 26 Global_step 2135000	Train_loss: 0.2026	Eval_AUC: 0.8536
Epoch 26 Global_step 2136000	Train_loss: 0.2106	Eval_AUC: 0.8525
Epoch 26 Global_step 2137000	Train_loss: 0.2122	Eval_AUC: 0.8479
Epoch 26 Global_step 2138000	Train_loss: 0.2090	Eval_AUC: 0.8530
Epoch 26 Global_step 2139000	Train_loss: 0.2080	Eval_AUC: 0.8528
Epoch 26 Global_step 2140000	Train_loss: 0.2106	Eval_AUC: 0.8532
Epoch 26 Global_step 2141000	Train_loss: 0.2096	Eval_AUC: 0.8560
Epoch 26 Global_step 2142000	Train_loss: 0.2123	Eval_AUC: 0.8514
Epoch 26 Global_step 2143000	Train_loss: 0.2129	Eval_AUC: 0.8504
Epoch 26 Global_step 2144000	Train_loss: 0.2116	Eval_AUC: 0.8561
Epoch 26 Global_step 2145000	Train_loss: 0.2139	Eval_AUC: 0.8524
Epoch 26 Global_step 2146000	Train_loss: 0.2130	Eval_AUC: 0.8535
Epoch 26 Global_step 2147000	Train_loss: 0.2086	Eval_AUC: 0.8555
Epoch 26 Global_step 2148000	Train_loss: 0.2141	Eval_AUC: 0.8519
Epoch 26 Global_step 2149000	Train_loss: 0.2134	Eval_AUC: 0.8525
Epoch 26 Global_step 2150000	Train_loss: 0.2148	Eval_AUC: 0.8544
Epoch 26 Global_step 2151000	Train_loss: 0.2142	Eval_AUC: 0.8554
Epoch 26 Global_step 2152000	Train_loss: 0.2139	Eval_AUC: 0.8529
Epoch 26 Global_step 2153000	Train_loss: 0.2147	Eval_AUC: 0.8575
Epoch 26 Global_step 2154000	Train_loss: 0.2150	Eval_AUC: 0.8516
Epoch 26 Global_step 2155000	Train_loss: 0.2121	Eval_AUC: 0.8478
Epoch 26 Global_step 2156000	Train_loss: 0.2148	Eval_AUC: 0.8501
Epoch 26 Global_step 2157000	Train_loss: 0.2180	Eval_AUC: 0.8531
Epoch 26 Global_step 2158000	Train_loss: 0.2178	Eval_AUC: 0.8503
Epoch 26 Global_step 2159000	Train_loss: 0.2173	Eval_AUC: 0.8546
Epoch 26 Global_step 2160000	Train_loss: 0.2163	Eval_AUC: 0.8574
Epoch 26 Global_step 2161000	Train_loss: 0.2182	Eval_AUC: 0.8576
Epoch 26 Global_step 2162000	Train_loss: 0.2184	Eval_AUC: 0.8552
Epoch 26 Global_step 2163000	Train_loss: 0.2159	Eval_AUC: 0.8532
Epoch 26 Global_step 2164000	Train_loss: 0.2196	Eval_AUC: 0.8528
Epoch 26 Global_step 2165000	Train_loss: 0.2168	Eval_AUC: 0.8550
Epoch 26 Global_step 2166000	Train_loss: 0.2197	Eval_AUC: 0.8510
Epoch 26 Global_step 2167000	Train_loss: 0.2214	Eval_AUC: 0.8558
Epoch 26 Global_step 2168000	Train_loss: 0.2192	Eval_AUC: 0.8538
Epoch 26 Global_step 2169000	Train_loss: 0.2207	Eval_AUC: 0.8524
Epoch 26 Global_step 2170000	Train_loss: 0.2186	Eval_AUC: 0.8532
Epoch 26 Global_step 2171000	Train_loss: 0.2226	Eval_AUC: 0.8571
Epoch 26 Global_step 2172000	Train_loss: 0.2211	Eval_AUC: 0.8584
Epoch 26 Global_step 2173000	Train_loss: 0.2210	Eval_AUC: 0.8577
Epoch 26 Global_step 2174000	Train_loss: 0.2183	Eval_AUC: 0.8532
Epoch 26 Global_step 2175000	Train_loss: 0.2243	Eval_AUC: 0.8536
Epoch 26 Global_step 2176000	Train_loss: 0.2181	Eval_AUC: 0.8524
Epoch 26 Global_step 2177000	Train_loss: 0.2221	Eval_AUC: 0.8585
Epoch 26 Global_step 2178000	Train_loss: 0.2191	Eval_AUC: 0.8512
Epoch 26 Global_step 2179000	Train_loss: 0.2233	Eval_AUC: 0.8554
Epoch 26 Global_step 2180000	Train_loss: 0.2245	Eval_AUC: 0.8524
Epoch 26 Global_step 2181000	Train_loss: 0.2233	Eval_AUC: 0.8506
Epoch 26 Global_step 2182000	Train_loss: 0.2220	Eval_AUC: 0.8531
Epoch 26 Global_step 2183000	Train_loss: 0.2235	Eval_AUC: 0.8535
Epoch 26 Global_step 2184000	Train_loss: 0.2236	Eval_AUC: 0.8531
Epoch 26 Global_step 2185000	Train_loss: 0.2255	Eval_AUC: 0.8501
Epoch 26 Global_step 2186000	Train_loss: 0.2248	Eval_AUC: 0.8569
Epoch 26 Global_step 2187000	Train_loss: 0.2250	Eval_AUC: 0.8572
Epoch 26 Global_step 2188000	Train_loss: 0.2254	Eval_AUC: 0.8518
Epoch 26 Global_step 2189000	Train_loss: 0.2247	Eval_AUC: 0.8520
Epoch 26 Global_step 2190000	Train_loss: 0.2251	Eval_AUC: 0.8493
Epoch 26 Global_step 2191000	Train_loss: 0.2193	Eval_AUC: 0.8550
Epoch 26 Global_step 2192000	Train_loss: 0.2265	Eval_AUC: 0.8579
Epoch 26 Global_step 2193000	Train_loss: 0.2268	Eval_AUC: 0.8509
Epoch 26 Global_step 2194000	Train_loss: 0.2265	Eval_AUC: 0.8569
Epoch 26 Global_step 2195000	Train_loss: 0.2269	Eval_AUC: 0.8530
Epoch 26 Global_step 2196000	Train_loss: 0.2293	Eval_AUC: 0.8568
Epoch 26 Global_step 2197000	Train_loss: 0.2276	Eval_AUC: 0.8591
Epoch 26 Global_step 2198000	Train_loss: 0.2247	Eval_AUC: 0.8580
Epoch 26 Global_step 2199000	Train_loss: 0.2323	Eval_AUC: 0.8580
Epoch 26 Global_step 2200000	Train_loss: 0.2252	Eval_AUC: 0.8590
Epoch 26 Global_step 2201000	Train_loss: 0.2249	Eval_AUC: 0.8590
Epoch 26 DONE	Cost time: 212343.12
Epoch 27 Global_step 2202000	Train_loss: 0.2011	Eval_AUC: 0.8555
Epoch 27 Global_step 2203000	Train_loss: 0.1962	Eval_AUC: 0.8510
Epoch 27 Global_step 2204000	Train_loss: 0.1983	Eval_AUC: 0.8540
Epoch 27 Global_step 2205000	Train_loss: 0.1968	Eval_AUC: 0.8537
Epoch 27 Global_step 2206000	Train_loss: 0.1976	Eval_AUC: 0.8538
Epoch 27 Global_step 2207000	Train_loss: 0.1993	Eval_AUC: 0.8499
Epoch 27 Global_step 2208000	Train_loss: 0.1985	Eval_AUC: 0.8555
Epoch 27 Global_step 2209000	Train_loss: 0.1988	Eval_AUC: 0.8522
Epoch 27 Global_step 2210000	Train_loss: 0.1990	Eval_AUC: 0.8551
Epoch 27 Global_step 2211000	Train_loss: 0.2019	Eval_AUC: 0.8547
Epoch 27 Global_step 2212000	Train_loss: 0.1992	Eval_AUC: 0.8519
Epoch 27 Global_step 2213000	Train_loss: 0.2028	Eval_AUC: 0.8535
Epoch 27 Global_step 2214000	Train_loss: 0.2022	Eval_AUC: 0.8509
Epoch 27 Global_step 2215000	Train_loss: 0.2023	Eval_AUC: 0.8545
Epoch 27 Global_step 2216000	Train_loss: 0.2035	Eval_AUC: 0.8514
Epoch 27 Global_step 2217000	Train_loss: 0.2026	Eval_AUC: 0.8545
Epoch 27 Global_step 2218000	Train_loss: 0.2074	Eval_AUC: 0.8512
Epoch 27 Global_step 2219000	Train_loss: 0.2016	Eval_AUC: 0.8505
Epoch 27 Global_step 2220000	Train_loss: 0.2036	Eval_AUC: 0.8538
Epoch 27 Global_step 2221000	Train_loss: 0.2024	Eval_AUC: 0.8536
Epoch 27 Global_step 2222000	Train_loss: 0.2069	Eval_AUC: 0.8511
Epoch 27 Global_step 2223000	Train_loss: 0.2037	Eval_AUC: 0.8509
Epoch 27 Global_step 2224000	Train_loss: 0.2071	Eval_AUC: 0.8539
Epoch 27 Global_step 2225000	Train_loss: 0.2065	Eval_AUC: 0.8480
Epoch 27 Global_step 2226000	Train_loss: 0.2055	Eval_AUC: 0.8540
Epoch 27 Global_step 2227000	Train_loss: 0.2063	Eval_AUC: 0.8541
Epoch 27 Global_step 2228000	Train_loss: 0.2052	Eval_AUC: 0.8563
Epoch 27 Global_step 2229000	Train_loss: 0.2070	Eval_AUC: 0.8517
Epoch 27 Global_step 2230000	Train_loss: 0.2111	Eval_AUC: 0.8541
Epoch 27 Global_step 2231000	Train_loss: 0.2096	Eval_AUC: 0.8544
Epoch 27 Global_step 2232000	Train_loss: 0.2118	Eval_AUC: 0.8536
Epoch 27 Global_step 2233000	Train_loss: 0.2053	Eval_AUC: 0.8503
Epoch 27 Global_step 2234000	Train_loss: 0.2132	Eval_AUC: 0.8538
Epoch 27 Global_step 2235000	Train_loss: 0.2094	Eval_AUC: 0.8564
Epoch 27 Global_step 2236000	Train_loss: 0.2115	Eval_AUC: 0.8546
Epoch 27 Global_step 2237000	Train_loss: 0.2080	Eval_AUC: 0.8567
Epoch 27 Global_step 2238000	Train_loss: 0.2102	Eval_AUC: 0.8504
Epoch 27 Global_step 2239000	Train_loss: 0.2107	Eval_AUC: 0.8541
Epoch 27 Global_step 2240000	Train_loss: 0.2090	Eval_AUC: 0.8538
Epoch 27 Global_step 2241000	Train_loss: 0.2128	Eval_AUC: 0.8538
Epoch 27 Global_step 2242000	Train_loss: 0.2129	Eval_AUC: 0.8522
Epoch 27 Global_step 2243000	Train_loss: 0.2099	Eval_AUC: 0.8513
Epoch 27 Global_step 2244000	Train_loss: 0.2127	Eval_AUC: 0.8564
Epoch 27 Global_step 2245000	Train_loss: 0.2123	Eval_AUC: 0.8517
Epoch 27 Global_step 2246000	Train_loss: 0.2109	Eval_AUC: 0.8544
Epoch 27 Global_step 2247000	Train_loss: 0.2126	Eval_AUC: 0.8552
Epoch 27 Global_step 2248000	Train_loss: 0.2132	Eval_AUC: 0.8513
Epoch 27 Global_step 2249000	Train_loss: 0.2190	Eval_AUC: 0.8564
Epoch 27 Global_step 2250000	Train_loss: 0.2136	Eval_AUC: 0.8573
Epoch 27 Global_step 2251000	Train_loss: 0.2134	Eval_AUC: 0.8517
Epoch 27 Global_step 2252000	Train_loss: 0.2160	Eval_AUC: 0.8516
Epoch 27 Global_step 2253000	Train_loss: 0.2160	Eval_AUC: 0.8553
Epoch 27 Global_step 2254000	Train_loss: 0.2165	Eval_AUC: 0.8549
Epoch 27 Global_step 2255000	Train_loss: 0.2164	Eval_AUC: 0.8523
Epoch 27 Global_step 2256000	Train_loss: 0.2184	Eval_AUC: 0.8544
Epoch 27 Global_step 2257000	Train_loss: 0.2149	Eval_AUC: 0.8528
Epoch 27 Global_step 2258000	Train_loss: 0.2184	Eval_AUC: 0.8561
Epoch 27 Global_step 2259000	Train_loss: 0.2165	Eval_AUC: 0.8531
Epoch 27 Global_step 2260000	Train_loss: 0.2193	Eval_AUC: 0.8519
Epoch 27 Global_step 2261000	Train_loss: 0.2195	Eval_AUC: 0.8523
Epoch 27 Global_step 2262000	Train_loss: 0.2209	Eval_AUC: 0.8507
Epoch 27 Global_step 2263000	Train_loss: 0.2157	Eval_AUC: 0.8559
Epoch 27 Global_step 2264000	Train_loss: 0.2190	Eval_AUC: 0.8488
Epoch 27 Global_step 2265000	Train_loss: 0.2187	Eval_AUC: 0.8544
Epoch 27 Global_step 2266000	Train_loss: 0.2182	Eval_AUC: 0.8547
Epoch 27 Global_step 2267000	Train_loss: 0.2185	Eval_AUC: 0.8547
Epoch 27 Global_step 2268000	Train_loss: 0.2180	Eval_AUC: 0.8505
Epoch 27 Global_step 2269000	Train_loss: 0.2184	Eval_AUC: 0.8545
Epoch 27 Global_step 2270000	Train_loss: 0.2170	Eval_AUC: 0.8580
Epoch 27 Global_step 2271000	Train_loss: 0.2203	Eval_AUC: 0.8563
Epoch 27 Global_step 2272000	Train_loss: 0.2199	Eval_AUC: 0.8564
Epoch 27 Global_step 2273000	Train_loss: 0.2210	Eval_AUC: 0.8561
Epoch 27 Global_step 2274000	Train_loss: 0.2216	Eval_AUC: 0.8514
Epoch 27 Global_step 2275000	Train_loss: 0.2219	Eval_AUC: 0.8570
Epoch 27 Global_step 2276000	Train_loss: 0.2203	Eval_AUC: 0.8554
Epoch 27 Global_step 2277000	Train_loss: 0.2187	Eval_AUC: 0.8546
Epoch 27 Global_step 2278000	Train_loss: 0.2226	Eval_AUC: 0.8551
Epoch 27 Global_step 2279000	Train_loss: 0.2238	Eval_AUC: 0.8535
Epoch 27 Global_step 2280000	Train_loss: 0.2210	Eval_AUC: 0.8561
Epoch 27 Global_step 2281000	Train_loss: 0.2219	Eval_AUC: 0.8584
Epoch 27 Global_step 2282000	Train_loss: 0.2230	Eval_AUC: 0.8531
Epoch 27 DONE	Cost time: 219510.38
Epoch 28 Global_step 2283000	Train_loss: 0.2125	Eval_AUC: 0.8531
Epoch 28 Global_step 2284000	Train_loss: 0.1938	Eval_AUC: 0.8477
Epoch 28 Global_step 2285000	Train_loss: 0.1897	Eval_AUC: 0.8544
Epoch 28 Global_step 2286000	Train_loss: 0.1890	Eval_AUC: 0.8545
Epoch 28 Global_step 2287000	Train_loss: 0.1945	Eval_AUC: 0.8543
Epoch 28 Global_step 2288000	Train_loss: 0.1932	Eval_AUC: 0.8498
Epoch 28 Global_step 2289000	Train_loss: 0.1930	Eval_AUC: 0.8500
Epoch 28 Global_step 2290000	Train_loss: 0.1945	Eval_AUC: 0.8472
Epoch 28 Global_step 2291000	Train_loss: 0.1948	Eval_AUC: 0.8503
Epoch 28 Global_step 2292000	Train_loss: 0.1917	Eval_AUC: 0.8541
Epoch 28 Global_step 2293000	Train_loss: 0.1975	Eval_AUC: 0.8518
Epoch 28 Global_step 2294000	Train_loss: 0.1964	Eval_AUC: 0.8449
Epoch 28 Global_step 2295000	Train_loss: 0.1971	Eval_AUC: 0.8512
Epoch 28 Global_step 2296000	Train_loss: 0.1957	Eval_AUC: 0.8512
Epoch 28 Global_step 2297000	Train_loss: 0.1990	Eval_AUC: 0.8547
Epoch 28 Global_step 2298000	Train_loss: 0.1989	Eval_AUC: 0.8473
Epoch 28 Global_step 2299000	Train_loss: 0.1987	Eval_AUC: 0.8503
Epoch 28 Global_step 2300000	Train_loss: 0.1980	Eval_AUC: 0.8518
Epoch 28 Global_step 2301000	Train_loss: 0.1965	Eval_AUC: 0.8530
Epoch 28 Global_step 2302000	Train_loss: 0.2009	Eval_AUC: 0.8556
Epoch 28 Global_step 2303000	Train_loss: 0.1980	Eval_AUC: 0.8554
Epoch 28 Global_step 2304000	Train_loss: 0.1991	Eval_AUC: 0.8546
Epoch 28 Global_step 2305000	Train_loss: 0.2011	Eval_AUC: 0.8477
Epoch 28 Global_step 2306000	Train_loss: 0.2025	Eval_AUC: 0.8476
Epoch 28 Global_step 2307000	Train_loss: 0.2055	Eval_AUC: 0.8535
Epoch 28 Global_step 2308000	Train_loss: 0.2006	Eval_AUC: 0.8534
Epoch 28 Global_step 2309000	Train_loss: 0.2028	Eval_AUC: 0.8487
Epoch 28 Global_step 2310000	Train_loss: 0.2017	Eval_AUC: 0.8524
Epoch 28 Global_step 2311000	Train_loss: 0.2059	Eval_AUC: 0.8548
Epoch 28 Global_step 2312000	Train_loss: 0.2048	Eval_AUC: 0.8489
Epoch 28 Global_step 2313000	Train_loss: 0.2008	Eval_AUC: 0.8537
Epoch 28 Global_step 2314000	Train_loss: 0.2052	Eval_AUC: 0.8517
Epoch 28 Global_step 2315000	Train_loss: 0.2066	Eval_AUC: 0.8511
Epoch 28 Global_step 2316000	Train_loss: 0.2036	Eval_AUC: 0.8496
Epoch 28 Global_step 2317000	Train_loss: 0.2067	Eval_AUC: 0.8492
Epoch 28 Global_step 2318000	Train_loss: 0.2049	Eval_AUC: 0.8539
Epoch 28 Global_step 2319000	Train_loss: 0.2055	Eval_AUC: 0.8497
Epoch 28 Global_step 2320000	Train_loss: 0.2011	Eval_AUC: 0.8498
Epoch 28 Global_step 2321000	Train_loss: 0.2054	Eval_AUC: 0.8535
Epoch 28 Global_step 2322000	Train_loss: 0.2080	Eval_AUC: 0.8530
Epoch 28 Global_step 2323000	Train_loss: 0.2071	Eval_AUC: 0.8522
Epoch 28 Global_step 2324000	Train_loss: 0.2079	Eval_AUC: 0.8547
Epoch 28 Global_step 2325000	Train_loss: 0.2085	Eval_AUC: 0.8537
Epoch 28 Global_step 2326000	Train_loss: 0.2046	Eval_AUC: 0.8534
Epoch 28 Global_step 2327000	Train_loss: 0.2104	Eval_AUC: 0.8506
Epoch 28 Global_step 2328000	Train_loss: 0.2095	Eval_AUC: 0.8504
Epoch 28 Global_step 2329000	Train_loss: 0.2066	Eval_AUC: 0.8533
Epoch 28 Global_step 2330000	Train_loss: 0.2075	Eval_AUC: 0.8524
Epoch 28 Global_step 2331000	Train_loss: 0.2065	Eval_AUC: 0.8555
Epoch 28 Global_step 2332000	Train_loss: 0.2135	Eval_AUC: 0.8546
Epoch 28 Global_step 2333000	Train_loss: 0.2038	Eval_AUC: 0.8517
Epoch 28 Global_step 2334000	Train_loss: 0.2110	Eval_AUC: 0.8539
Epoch 28 Global_step 2335000	Train_loss: 0.2139	Eval_AUC: 0.8506
Epoch 28 Global_step 2336000	Train_loss: 0.2080	Eval_AUC: 0.8544
Epoch 28 Global_step 2337000	Train_loss: 0.2129	Eval_AUC: 0.8505
Epoch 28 Global_step 2338000	Train_loss: 0.2129	Eval_AUC: 0.8547
Epoch 28 Global_step 2339000	Train_loss: 0.2093	Eval_AUC: 0.8565
Epoch 28 Global_step 2340000	Train_loss: 0.2113	Eval_AUC: 0.8547
Epoch 28 Global_step 2341000	Train_loss: 0.2070	Eval_AUC: 0.8549
Epoch 28 Global_step 2342000	Train_loss: 0.2122	Eval_AUC: 0.8552
Epoch 28 Global_step 2343000	Train_loss: 0.2136	Eval_AUC: 0.8520
Epoch 28 Global_step 2344000	Train_loss: 0.2128	Eval_AUC: 0.8491
Epoch 28 Global_step 2345000	Train_loss: 0.2130	Eval_AUC: 0.8545
Epoch 28 Global_step 2346000	Train_loss: 0.2128	Eval_AUC: 0.8505
Epoch 28 Global_step 2347000	Train_loss: 0.2145	Eval_AUC: 0.8538
Epoch 28 Global_step 2348000	Train_loss: 0.2143	Eval_AUC: 0.8559
Epoch 28 Global_step 2349000	Train_loss: 0.2166	Eval_AUC: 0.8525
Epoch 28 Global_step 2350000	Train_loss: 0.2144	Eval_AUC: 0.8545
Epoch 28 Global_step 2351000	Train_loss: 0.2141	Eval_AUC: 0.8559
Epoch 28 Global_step 2352000	Train_loss: 0.2149	Eval_AUC: 0.8520
Epoch 28 Global_step 2353000	Train_loss: 0.2119	Eval_AUC: 0.8500
Epoch 28 Global_step 2354000	Train_loss: 0.2162	Eval_AUC: 0.8491
Epoch 28 Global_step 2355000	Train_loss: 0.2137	Eval_AUC: 0.8562
Epoch 28 Global_step 2356000	Train_loss: 0.2177	Eval_AUC: 0.8573
Epoch 28 Global_step 2357000	Train_loss: 0.2163	Eval_AUC: 0.8481
Epoch 28 Global_step 2358000	Train_loss: 0.2157	Eval_AUC: 0.8535
Epoch 28 Global_step 2359000	Train_loss: 0.2155	Eval_AUC: 0.8551
Epoch 28 Global_step 2360000	Train_loss: 0.2129	Eval_AUC: 0.8551
Epoch 28 Global_step 2361000	Train_loss: 0.2128	Eval_AUC: 0.8551
Epoch 28 Global_step 2362000	Train_loss: 0.2186	Eval_AUC: 0.8519
Epoch 28 Global_step 2363000	Train_loss: 0.2211	Eval_AUC: 0.8534
Epoch 28 Global_step 2364000	Train_loss: 0.2144	Eval_AUC: 0.8532
Epoch 28 DONE	Cost time: 226737.19
Epoch 29 Global_step 2365000	Train_loss: 0.1951	Eval_AUC: 0.8525
Epoch 29 Global_step 2366000	Train_loss: 0.1898	Eval_AUC: 0.8544
Epoch 29 Global_step 2367000	Train_loss: 0.1861	Eval_AUC: 0.8511
Epoch 29 Global_step 2368000	Train_loss: 0.1897	Eval_AUC: 0.8490
Epoch 29 Global_step 2369000	Train_loss: 0.1922	Eval_AUC: 0.8505
Epoch 29 Global_step 2370000	Train_loss: 0.1895	Eval_AUC: 0.8501
Epoch 29 Global_step 2371000	Train_loss: 0.1892	Eval_AUC: 0.8511
Epoch 29 Global_step 2372000	Train_loss: 0.1902	Eval_AUC: 0.8461
Epoch 29 Global_step 2373000	Train_loss: 0.1897	Eval_AUC: 0.8529
Epoch 29 Global_step 2374000	Train_loss: 0.1923	Eval_AUC: 0.8454
Epoch 29 Global_step 2375000	Train_loss: 0.1910	Eval_AUC: 0.8474
Epoch 29 Global_step 2376000	Train_loss: 0.1905	Eval_AUC: 0.8447
Epoch 29 Global_step 2377000	Train_loss: 0.1911	Eval_AUC: 0.8485
Epoch 29 Global_step 2378000	Train_loss: 0.1934	Eval_AUC: 0.8509
Epoch 29 Global_step 2379000	Train_loss: 0.1908	Eval_AUC: 0.8518
Epoch 29 Global_step 2380000	Train_loss: 0.1945	Eval_AUC: 0.8525
Epoch 29 Global_step 2381000	Train_loss: 0.1946	Eval_AUC: 0.8477
Epoch 29 Global_step 2382000	Train_loss: 0.1949	Eval_AUC: 0.8487
Epoch 29 Global_step 2383000	Train_loss: 0.1923	Eval_AUC: 0.8522
Epoch 29 Global_step 2384000	Train_loss: 0.1922	Eval_AUC: 0.8489
Epoch 29 Global_step 2385000	Train_loss: 0.1956	Eval_AUC: 0.8522
Epoch 29 Global_step 2386000	Train_loss: 0.1929	Eval_AUC: 0.8484
Epoch 29 Global_step 2387000	Train_loss: 0.1979	Eval_AUC: 0.8519
Epoch 29 Global_step 2388000	Train_loss: 0.1951	Eval_AUC: 0.8529
Epoch 29 Global_step 2389000	Train_loss: 0.1968	Eval_AUC: 0.8524
Epoch 29 Global_step 2390000	Train_loss: 0.1969	Eval_AUC: 0.8508
Epoch 29 Global_step 2391000	Train_loss: 0.1964	Eval_AUC: 0.8467
Epoch 29 Global_step 2392000	Train_loss: 0.1982	Eval_AUC: 0.8506
Epoch 29 Global_step 2393000	Train_loss: 0.1982	Eval_AUC: 0.8519
Epoch 29 Global_step 2394000	Train_loss: 0.1985	Eval_AUC: 0.8514
Epoch 29 Global_step 2395000	Train_loss: 0.1969	Eval_AUC: 0.8505
Epoch 29 Global_step 2396000	Train_loss: 0.1990	Eval_AUC: 0.8491
Epoch 29 Global_step 2397000	Train_loss: 0.1989	Eval_AUC: 0.8526
Epoch 29 Global_step 2398000	Train_loss: 0.1991	Eval_AUC: 0.8560
Epoch 29 Global_step 2399000	Train_loss: 0.2013	Eval_AUC: 0.8499
Epoch 29 Global_step 2400000	Train_loss: 0.2010	Eval_AUC: 0.8559
Epoch 29 Global_step 2401000	Train_loss: 0.2004	Eval_AUC: 0.8516
Epoch 29 Global_step 2402000	Train_loss: 0.2013	Eval_AUC: 0.8519
Epoch 29 Global_step 2403000	Train_loss: 0.1989	Eval_AUC: 0.8517
Epoch 29 Global_step 2404000	Train_loss: 0.2027	Eval_AUC: 0.8484
Epoch 29 Global_step 2405000	Train_loss: 0.2022	Eval_AUC: 0.8543
Epoch 29 Global_step 2406000	Train_loss: 0.2038	Eval_AUC: 0.8527
Epoch 29 Global_step 2407000	Train_loss: 0.2017	Eval_AUC: 0.8528
Epoch 29 Global_step 2408000	Train_loss: 0.2029	Eval_AUC: 0.8512
Epoch 29 Global_step 2409000	Train_loss: 0.2032	Eval_AUC: 0.8501
Epoch 29 Global_step 2410000	Train_loss: 0.2020	Eval_AUC: 0.8517
Epoch 29 Global_step 2411000	Train_loss: 0.2043	Eval_AUC: 0.8473
Epoch 29 Global_step 2412000	Train_loss: 0.2031	Eval_AUC: 0.8500
Epoch 29 Global_step 2413000	Train_loss: 0.2034	Eval_AUC: 0.8541
Epoch 29 Global_step 2414000	Train_loss: 0.2055	Eval_AUC: 0.8515
Epoch 29 Global_step 2415000	Train_loss: 0.2035	Eval_AUC: 0.8516
Epoch 29 Global_step 2416000	Train_loss: 0.2031	Eval_AUC: 0.8524
Epoch 29 Global_step 2417000	Train_loss: 0.2030	Eval_AUC: 0.8466
Epoch 29 Global_step 2418000	Train_loss: 0.2084	Eval_AUC: 0.8488
Epoch 29 Global_step 2419000	Train_loss: 0.2072	Eval_AUC: 0.8514
Epoch 29 Global_step 2420000	Train_loss: 0.2069	Eval_AUC: 0.8542
Epoch 29 Global_step 2421000	Train_loss: 0.2074	Eval_AUC: 0.8486
Epoch 29 Global_step 2422000	Train_loss: 0.2046	Eval_AUC: 0.8543
Epoch 29 Global_step 2423000	Train_loss: 0.2051	Eval_AUC: 0.8485
Epoch 29 Global_step 2424000	Train_loss: 0.2063	Eval_AUC: 0.8481
Epoch 29 Global_step 2425000	Train_loss: 0.2085	Eval_AUC: 0.8497
Epoch 29 Global_step 2426000	Train_loss: 0.2065	Eval_AUC: 0.8546
Epoch 29 Global_step 2427000	Train_loss: 0.2076	Eval_AUC: 0.8526
Epoch 29 Global_step 2428000	Train_loss: 0.2056	Eval_AUC: 0.8495
Epoch 29 Global_step 2429000	Train_loss: 0.2083	Eval_AUC: 0.8525
Epoch 29 Global_step 2430000	Train_loss: 0.2082	Eval_AUC: 0.8432
Epoch 29 Global_step 2431000	Train_loss: 0.2098	Eval_AUC: 0.8552
Epoch 29 Global_step 2432000	Train_loss: 0.2072	Eval_AUC: 0.8501
Epoch 29 Global_step 2433000	Train_loss: 0.2090	Eval_AUC: 0.8487
Epoch 29 Global_step 2434000	Train_loss: 0.2083	Eval_AUC: 0.8467
Epoch 29 Global_step 2435000	Train_loss: 0.2094	Eval_AUC: 0.8492
Epoch 29 Global_step 2436000	Train_loss: 0.2090	Eval_AUC: 0.8543
Epoch 29 Global_step 2437000	Train_loss: 0.2100	Eval_AUC: 0.8510
Epoch 29 Global_step 2438000	Train_loss: 0.2103	Eval_AUC: 0.8533
Epoch 29 Global_step 2439000	Train_loss: 0.2131	Eval_AUC: 0.8464
Epoch 29 Global_step 2440000	Train_loss: 0.2135	Eval_AUC: 0.8505
Epoch 29 Global_step 2441000	Train_loss: 0.2115	Eval_AUC: 0.8560
Epoch 29 Global_step 2442000	Train_loss: 0.2136	Eval_AUC: 0.8503
Epoch 29 Global_step 2443000	Train_loss: 0.2134	Eval_AUC: 0.8539
Epoch 29 Global_step 2444000	Train_loss: 0.2126	Eval_AUC: 0.8551
Epoch 29 Global_step 2445000	Train_loss: 0.2158	Eval_AUC: 0.8495
Epoch 29 DONE	Cost time: 233894.44
Epoch 30 Global_step 2446000	Train_loss: 0.2045	Eval_AUC: 0.8509
Epoch 30 Global_step 2447000	Train_loss: 0.1834	Eval_AUC: 0.8514
Epoch 30 Global_step 2448000	Train_loss: 0.1829	Eval_AUC: 0.8516
Epoch 30 Global_step 2449000	Train_loss: 0.1807	Eval_AUC: 0.8522
Epoch 30 Global_step 2450000	Train_loss: 0.1815	Eval_AUC: 0.8471
Epoch 30 Global_step 2451000	Train_loss: 0.1857	Eval_AUC: 0.8527
Epoch 30 Global_step 2452000	Train_loss: 0.1850	Eval_AUC: 0.8482
Epoch 30 Global_step 2453000	Train_loss: 0.1849	Eval_AUC: 0.8513
Epoch 30 Global_step 2454000	Train_loss: 0.1864	Eval_AUC: 0.8538
Epoch 30 Global_step 2455000	Train_loss: 0.1834	Eval_AUC: 0.8526
Epoch 30 Global_step 2456000	Train_loss: 0.1864	Eval_AUC: 0.8494
Epoch 30 Global_step 2457000	Train_loss: 0.1886	Eval_AUC: 0.8472
Epoch 30 Global_step 2458000	Train_loss: 0.1869	Eval_AUC: 0.8524
Epoch 30 Global_step 2459000	Train_loss: 0.1896	Eval_AUC: 0.8502
Epoch 30 Global_step 2460000	Train_loss: 0.1860	Eval_AUC: 0.8484
Epoch 30 Global_step 2461000	Train_loss: 0.1873	Eval_AUC: 0.8505
Epoch 30 Global_step 2462000	Train_loss: 0.1871	Eval_AUC: 0.8503
Epoch 30 Global_step 2463000	Train_loss: 0.1882	Eval_AUC: 0.8519
Epoch 30 Global_step 2464000	Train_loss: 0.1886	Eval_AUC: 0.8465
Epoch 30 Global_step 2465000	Train_loss: 0.1909	Eval_AUC: 0.8519
Epoch 30 Global_step 2466000	Train_loss: 0.1912	Eval_AUC: 0.8471
Epoch 30 Global_step 2467000	Train_loss: 0.1891	Eval_AUC: 0.8482
Epoch 30 Global_step 2468000	Train_loss: 0.1916	Eval_AUC: 0.8494
Epoch 30 Global_step 2469000	Train_loss: 0.1939	Eval_AUC: 0.8476
Epoch 30 Global_step 2470000	Train_loss: 0.1931	Eval_AUC: 0.8461
Epoch 30 Global_step 2471000	Train_loss: 0.1919	Eval_AUC: 0.8503
Epoch 30 Global_step 2472000	Train_loss: 0.1921	Eval_AUC: 0.8488
Epoch 30 Global_step 2473000	Train_loss: 0.1926	Eval_AUC: 0.8508
Epoch 30 Global_step 2474000	Train_loss: 0.1907	Eval_AUC: 0.8514
Epoch 30 Global_step 2475000	Train_loss: 0.1912	Eval_AUC: 0.8503
Epoch 30 Global_step 2476000	Train_loss: 0.1938	Eval_AUC: 0.8502
Epoch 30 Global_step 2477000	Train_loss: 0.1950	Eval_AUC: 0.8474
Epoch 30 Global_step 2478000	Train_loss: 0.1930	Eval_AUC: 0.8519
Epoch 30 Global_step 2479000	Train_loss: 0.1939	Eval_AUC: 0.8503
Epoch 30 Global_step 2480000	Train_loss: 0.1944	Eval_AUC: 0.8506
Epoch 30 Global_step 2481000	Train_loss: 0.1960	Eval_AUC: 0.8497
Epoch 30 Global_step 2482000	Train_loss: 0.1957	Eval_AUC: 0.8493
Epoch 30 Global_step 2483000	Train_loss: 0.1948	Eval_AUC: 0.8500
Epoch 30 Global_step 2484000	Train_loss: 0.1940	Eval_AUC: 0.8496
Epoch 30 Global_step 2485000	Train_loss: 0.1946	Eval_AUC: 0.8515
Epoch 30 Global_step 2486000	Train_loss: 0.1965	Eval_AUC: 0.8523
Epoch 30 Global_step 2487000	Train_loss: 0.1982	Eval_AUC: 0.8500
Epoch 30 Global_step 2488000	Train_loss: 0.1987	Eval_AUC: 0.8447
Epoch 30 Global_step 2489000	Train_loss: 0.1985	Eval_AUC: 0.8523
Epoch 30 Global_step 2490000	Train_loss: 0.1986	Eval_AUC: 0.8497
Epoch 30 Global_step 2491000	Train_loss: 0.1989	Eval_AUC: 0.8512
Epoch 30 Global_step 2492000	Train_loss: 0.1992	Eval_AUC: 0.8512
Epoch 30 Global_step 2493000	Train_loss: 0.2033	Eval_AUC: 0.8472
Epoch 30 Global_step 2494000	Train_loss: 0.1999	Eval_AUC: 0.8518
Epoch 30 Global_step 2495000	Train_loss: 0.2011	Eval_AUC: 0.8487
Epoch 30 Global_step 2496000	Train_loss: 0.2010	Eval_AUC: 0.8537
Epoch 30 Global_step 2497000	Train_loss: 0.2005	Eval_AUC: 0.8465
Epoch 30 Global_step 2498000	Train_loss: 0.2017	Eval_AUC: 0.8482
Epoch 30 Global_step 2499000	Train_loss: 0.2006	Eval_AUC: 0.8514
Epoch 30 Global_step 2500000	Train_loss: 0.2019	Eval_AUC: 0.8501
Epoch 30 Global_step 2501000	Train_loss: 0.2000	Eval_AUC: 0.8486
Epoch 30 Global_step 2502000	Train_loss: 0.2025	Eval_AUC: 0.8490
Epoch 30 Global_step 2503000	Train_loss: 0.2031	Eval_AUC: 0.8516
Epoch 30 Global_step 2504000	Train_loss: 0.2022	Eval_AUC: 0.8518
Epoch 30 Global_step 2505000	Train_loss: 0.2033	Eval_AUC: 0.8513
Epoch 30 Global_step 2506000	Train_loss: 0.2028	Eval_AUC: 0.8505
Epoch 30 Global_step 2507000	Train_loss: 0.2023	Eval_AUC: 0.8480
Epoch 30 Global_step 2508000	Train_loss: 0.2041	Eval_AUC: 0.8505
Epoch 30 Global_step 2509000	Train_loss: 0.1994	Eval_AUC: 0.8518
Epoch 30 Global_step 2510000	Train_loss: 0.2053	Eval_AUC: 0.8476
Epoch 30 Global_step 2511000	Train_loss: 0.2018	Eval_AUC: 0.8503
Epoch 30 Global_step 2512000	Train_loss: 0.2030	Eval_AUC: 0.8530
Epoch 30 Global_step 2513000	Train_loss: 0.2018	Eval_AUC: 0.8475
Epoch 30 Global_step 2514000	Train_loss: 0.2020	Eval_AUC: 0.8467
Epoch 30 Global_step 2515000	Train_loss: 0.2067	Eval_AUC: 0.8494
Epoch 30 Global_step 2516000	Train_loss: 0.2061	Eval_AUC: 0.8542
Epoch 30 Global_step 2517000	Train_loss: 0.2051	Eval_AUC: 0.8505
Epoch 30 Global_step 2518000	Train_loss: 0.2070	Eval_AUC: 0.8549
Epoch 30 Global_step 2519000	Train_loss: 0.2067	Eval_AUC: 0.8482
Epoch 30 Global_step 2520000	Train_loss: 0.2062	Eval_AUC: 0.8509
Epoch 30 Global_step 2521000	Train_loss: 0.2075	Eval_AUC: 0.8514
Epoch 30 Global_step 2522000	Train_loss: 0.2084	Eval_AUC: 0.8494
Epoch 30 Global_step 2523000	Train_loss: 0.2104	Eval_AUC: 0.8487
Epoch 30 Global_step 2524000	Train_loss: 0.2066	Eval_AUC: 0.8456
Epoch 30 Global_step 2525000	Train_loss: 0.2085	Eval_AUC: 0.8504
Epoch 30 Global_step 2526000	Train_loss: 0.2062	Eval_AUC: 0.8479
Epoch 30 Global_step 2527000	Train_loss: 0.2084	Eval_AUC: 0.8516
Epoch 30 DONE	Cost time: 241123.19
Epoch 31 Global_step 2528000	Train_loss: 0.1861	Eval_AUC: 0.8489
Epoch 31 Global_step 2529000	Train_loss: 0.1790	Eval_AUC: 0.8499
Epoch 31 Global_step 2530000	Train_loss: 0.1802	Eval_AUC: 0.8490
Epoch 31 Global_step 2531000	Train_loss: 0.1797	Eval_AUC: 0.8485
Epoch 31 Global_step 2532000	Train_loss: 0.1799	Eval_AUC: 0.8504
Epoch 31 Global_step 2533000	Train_loss: 0.1794	Eval_AUC: 0.8513
Epoch 31 Global_step 2534000	Train_loss: 0.1819	Eval_AUC: 0.8494
Epoch 31 Global_step 2535000	Train_loss: 0.1820	Eval_AUC: 0.8499
Epoch 31 Global_step 2536000	Train_loss: 0.1818	Eval_AUC: 0.8498
Epoch 31 Global_step 2537000	Train_loss: 0.1810	Eval_AUC: 0.8503
Epoch 31 Global_step 2538000	Train_loss: 0.1811	Eval_AUC: 0.8493
Epoch 31 Global_step 2539000	Train_loss: 0.1816	Eval_AUC: 0.8532
Epoch 31 Global_step 2540000	Train_loss: 0.1858	Eval_AUC: 0.8501
Epoch 31 Global_step 2541000	Train_loss: 0.1841	Eval_AUC: 0.8512
Epoch 31 Global_step 2542000	Train_loss: 0.1839	Eval_AUC: 0.8438
Epoch 31 Global_step 2543000	Train_loss: 0.1848	Eval_AUC: 0.8471
Epoch 31 Global_step 2544000	Train_loss: 0.1850	Eval_AUC: 0.8514
Epoch 31 Global_step 2545000	Train_loss: 0.1855	Eval_AUC: 0.8508
Epoch 31 Global_step 2546000	Train_loss: 0.1834	Eval_AUC: 0.8482
Epoch 31 Global_step 2547000	Train_loss: 0.1850	Eval_AUC: 0.8482
Epoch 31 Global_step 2548000	Train_loss: 0.1865	Eval_AUC: 0.8491
Epoch 31 Global_step 2549000	Train_loss: 0.1851	Eval_AUC: 0.8484
Epoch 31 Global_step 2550000	Train_loss: 0.1878	Eval_AUC: 0.8477
Epoch 31 Global_step 2551000	Train_loss: 0.1904	Eval_AUC: 0.8439
Epoch 31 Global_step 2552000	Train_loss: 0.1872	Eval_AUC: 0.8464
Epoch 31 Global_step 2553000	Train_loss: 0.1844	Eval_AUC: 0.8478
Epoch 31 Global_step 2554000	Train_loss: 0.1879	Eval_AUC: 0.8451
Epoch 31 Global_step 2555000	Train_loss: 0.1899	Eval_AUC: 0.8461
Epoch 31 Global_step 2556000	Train_loss: 0.1888	Eval_AUC: 0.8519
Epoch 31 Global_step 2557000	Train_loss: 0.1918	Eval_AUC: 0.8499
Epoch 31 Global_step 2558000	Train_loss: 0.1914	Eval_AUC: 0.8423
Epoch 31 Global_step 2559000	Train_loss: 0.1888	Eval_AUC: 0.8470
Epoch 31 Global_step 2560000	Train_loss: 0.1897	Eval_AUC: 0.8498
Epoch 31 Global_step 2561000	Train_loss: 0.1900	Eval_AUC: 0.8456
Epoch 31 Global_step 2562000	Train_loss: 0.1881	Eval_AUC: 0.8506
Epoch 31 Global_step 2563000	Train_loss: 0.1917	Eval_AUC: 0.8487
Epoch 31 Global_step 2564000	Train_loss: 0.1911	Eval_AUC: 0.8502
Epoch 31 Global_step 2565000	Train_loss: 0.1932	Eval_AUC: 0.8503
Epoch 31 Global_step 2566000	Train_loss: 0.1922	Eval_AUC: 0.8508
Epoch 31 Global_step 2567000	Train_loss: 0.1936	Eval_AUC: 0.8516
Epoch 31 Global_step 2568000	Train_loss: 0.1954	Eval_AUC: 0.8456
Epoch 31 Global_step 2569000	Train_loss: 0.1918	Eval_AUC: 0.8477
Epoch 31 Global_step 2570000	Train_loss: 0.1923	Eval_AUC: 0.8471
Epoch 31 Global_step 2571000	Train_loss: 0.1940	Eval_AUC: 0.8483
Epoch 31 Global_step 2572000	Train_loss: 0.1920	Eval_AUC: 0.8505
Epoch 31 Global_step 2573000	Train_loss: 0.1957	Eval_AUC: 0.8478
Epoch 31 Global_step 2574000	Train_loss: 0.1925	Eval_AUC: 0.8464
Epoch 31 Global_step 2575000	Train_loss: 0.1910	Eval_AUC: 0.8489
Epoch 31 Global_step 2576000	Train_loss: 0.1960	Eval_AUC: 0.8524
Epoch 31 Global_step 2577000	Train_loss: 0.1953	Eval_AUC: 0.8515
Epoch 31 Global_step 2578000	Train_loss: 0.1976	Eval_AUC: 0.8490
Epoch 31 Global_step 2579000	Train_loss: 0.1968	Eval_AUC: 0.8524
Epoch 31 Global_step 2580000	Train_loss: 0.1964	Eval_AUC: 0.8490
Epoch 31 Global_step 2581000	Train_loss: 0.1971	Eval_AUC: 0.8523
Epoch 31 Global_step 2582000	Train_loss: 0.1974	Eval_AUC: 0.8460
Epoch 31 Global_step 2583000	Train_loss: 0.1980	Eval_AUC: 0.8502
Epoch 31 Global_step 2584000	Train_loss: 0.1958	Eval_AUC: 0.8468
Epoch 31 Global_step 2585000	Train_loss: 0.1957	Eval_AUC: 0.8510
Epoch 31 Global_step 2586000	Train_loss: 0.1974	Eval_AUC: 0.8507
Epoch 31 Global_step 2587000	Train_loss: 0.1978	Eval_AUC: 0.8503
Epoch 31 Global_step 2588000	Train_loss: 0.1983	Eval_AUC: 0.8492
Epoch 31 Global_step 2589000	Train_loss: 0.1995	Eval_AUC: 0.8512
Epoch 31 Global_step 2590000	Train_loss: 0.1989	Eval_AUC: 0.8429
Epoch 31 Global_step 2591000	Train_loss: 0.1983	Eval_AUC: 0.8511
Epoch 31 Global_step 2592000	Train_loss: 0.2005	Eval_AUC: 0.8503
Epoch 31 Global_step 2593000	Train_loss: 0.2018	Eval_AUC: 0.8505
Epoch 31 Global_step 2594000	Train_loss: 0.1965	Eval_AUC: 0.8492
Epoch 31 Global_step 2595000	Train_loss: 0.2007	Eval_AUC: 0.8472
Epoch 31 Global_step 2596000	Train_loss: 0.1981	Eval_AUC: 0.8490
Epoch 31 Global_step 2597000	Train_loss: 0.1984	Eval_AUC: 0.8482
Epoch 31 Global_step 2598000	Train_loss: 0.1961	Eval_AUC: 0.8487
Epoch 31 Global_step 2599000	Train_loss: 0.2025	Eval_AUC: 0.8463
Epoch 31 Global_step 2600000	Train_loss: 0.1990	Eval_AUC: 0.8474
Epoch 31 Global_step 2601000	Train_loss: 0.2020	Eval_AUC: 0.8485
Epoch 31 Global_step 2602000	Train_loss: 0.1992	Eval_AUC: 0.8478
Epoch 31 Global_step 2603000	Train_loss: 0.2037	Eval_AUC: 0.8465
Epoch 31 Global_step 2604000	Train_loss: 0.2000	Eval_AUC: 0.8488
Epoch 31 Global_step 2605000	Train_loss: 0.2033	Eval_AUC: 0.8516
Epoch 31 Global_step 2606000	Train_loss: 0.2027	Eval_AUC: 0.8525
Epoch 31 Global_step 2607000	Train_loss: 0.2016	Eval_AUC: 0.8474
Epoch 31 Global_step 2608000	Train_loss: 0.2038	Eval_AUC: 0.8483
Epoch 31 DONE	Cost time: 248299.61
Epoch 32 Global_step 2609000	Train_loss: 0.1963	Eval_AUC: 0.8514
Epoch 32 Global_step 2610000	Train_loss: 0.1711	Eval_AUC: 0.8519
Epoch 32 Global_step 2611000	Train_loss: 0.1759	Eval_AUC: 0.8462
Epoch 32 Global_step 2612000	Train_loss: 0.1739	Eval_AUC: 0.8426
Epoch 32 Global_step 2613000	Train_loss: 0.1750	Eval_AUC: 0.8484
Epoch 32 Global_step 2614000	Train_loss: 0.1762	Eval_AUC: 0.8478
Epoch 32 Global_step 2615000	Train_loss: 0.1780	Eval_AUC: 0.8446
Epoch 32 Global_step 2616000	Train_loss: 0.1758	Eval_AUC: 0.8482
Epoch 32 Global_step 2617000	Train_loss: 0.1762	Eval_AUC: 0.8465
Epoch 32 Global_step 2618000	Train_loss: 0.1781	Eval_AUC: 0.8494
Epoch 32 Global_step 2619000	Train_loss: 0.1818	Eval_AUC: 0.8441
Epoch 32 Global_step 2620000	Train_loss: 0.1773	Eval_AUC: 0.8438
Epoch 32 Global_step 2621000	Train_loss: 0.1801	Eval_AUC: 0.8434
Epoch 32 Global_step 2622000	Train_loss: 0.1792	Eval_AUC: 0.8479
Epoch 32 Global_step 2623000	Train_loss: 0.1823	Eval_AUC: 0.8455
Epoch 32 Global_step 2624000	Train_loss: 0.1824	Eval_AUC: 0.8497
Epoch 32 Global_step 2625000	Train_loss: 0.1789	Eval_AUC: 0.8426
Epoch 32 Global_step 2626000	Train_loss: 0.1798	Eval_AUC: 0.8499
Epoch 32 Global_step 2627000	Train_loss: 0.1832	Eval_AUC: 0.8448
Epoch 32 Global_step 2628000	Train_loss: 0.1818	Eval_AUC: 0.8452
Epoch 32 Global_step 2629000	Train_loss: 0.1795	Eval_AUC: 0.8483
Epoch 32 Global_step 2630000	Train_loss: 0.1815	Eval_AUC: 0.8456
Epoch 32 Global_step 2631000	Train_loss: 0.1807	Eval_AUC: 0.8492
Epoch 32 Global_step 2632000	Train_loss: 0.1833	Eval_AUC: 0.8471
Epoch 32 Global_step 2633000	Train_loss: 0.1821	Eval_AUC: 0.8513
Epoch 32 Global_step 2634000	Train_loss: 0.1829	Eval_AUC: 0.8523
Epoch 32 Global_step 2635000	Train_loss: 0.1827	Eval_AUC: 0.8489
Epoch 32 Global_step 2636000	Train_loss: 0.1850	Eval_AUC: 0.8478
Epoch 32 Global_step 2637000	Train_loss: 0.1858	Eval_AUC: 0.8438
Epoch 32 Global_step 2638000	Train_loss: 0.1879	Eval_AUC: 0.8466
Epoch 32 Global_step 2639000	Train_loss: 0.1844	Eval_AUC: 0.8454
Epoch 32 Global_step 2640000	Train_loss: 0.1864	Eval_AUC: 0.8464
Epoch 32 Global_step 2641000	Train_loss: 0.1872	Eval_AUC: 0.8490
Epoch 32 Global_step 2642000	Train_loss: 0.1854	Eval_AUC: 0.8498
Epoch 32 Global_step 2643000	Train_loss: 0.1852	Eval_AUC: 0.8484
Epoch 32 Global_step 2644000	Train_loss: 0.1871	Eval_AUC: 0.8435
Epoch 32 Global_step 2645000	Train_loss: 0.1899	Eval_AUC: 0.8460
Epoch 32 Global_step 2646000	Train_loss: 0.1862	Eval_AUC: 0.8493
Epoch 32 Global_step 2647000	Train_loss: 0.1874	Eval_AUC: 0.8465
Epoch 32 Global_step 2648000	Train_loss: 0.1873	Eval_AUC: 0.8485
Epoch 32 Global_step 2649000	Train_loss: 0.1897	Eval_AUC: 0.8500
Epoch 32 Global_step 2650000	Train_loss: 0.1914	Eval_AUC: 0.8513
Epoch 32 Global_step 2651000	Train_loss: 0.1882	Eval_AUC: 0.8461
Epoch 32 Global_step 2652000	Train_loss: 0.1897	Eval_AUC: 0.8493
Epoch 32 Global_step 2653000	Train_loss: 0.1908	Eval_AUC: 0.8465
Epoch 32 Global_step 2654000	Train_loss: 0.1852	Eval_AUC: 0.8484
Epoch 32 Global_step 2655000	Train_loss: 0.1934	Eval_AUC: 0.8504
Epoch 32 Global_step 2656000	Train_loss: 0.1900	Eval_AUC: 0.8489
Epoch 32 Global_step 2657000	Train_loss: 0.1873	Eval_AUC: 0.8464
Epoch 32 Global_step 2658000	Train_loss: 0.1908	Eval_AUC: 0.8451
Epoch 32 Global_step 2659000	Train_loss: 0.1900	Eval_AUC: 0.8487
Epoch 32 Global_step 2660000	Train_loss: 0.1889	Eval_AUC: 0.8439
Epoch 32 Global_step 2661000	Train_loss: 0.1944	Eval_AUC: 0.8439
Epoch 32 Global_step 2662000	Train_loss: 0.1897	Eval_AUC: 0.8489
Epoch 32 Global_step 2663000	Train_loss: 0.1912	Eval_AUC: 0.8482
Epoch 32 Global_step 2664000	Train_loss: 0.1938	Eval_AUC: 0.8475
Epoch 32 Global_step 2665000	Train_loss: 0.1904	Eval_AUC: 0.8447
Epoch 32 Global_step 2666000	Train_loss: 0.1914	Eval_AUC: 0.8433
Epoch 32 Global_step 2667000	Train_loss: 0.1946	Eval_AUC: 0.8484
Epoch 32 Global_step 2668000	Train_loss: 0.1913	Eval_AUC: 0.8472
Epoch 32 Global_step 2669000	Train_loss: 0.1923	Eval_AUC: 0.8424
Epoch 32 Global_step 2670000	Train_loss: 0.1939	Eval_AUC: 0.8440
Epoch 32 Global_step 2671000	Train_loss: 0.1917	Eval_AUC: 0.8460
Epoch 32 Global_step 2672000	Train_loss: 0.1938	Eval_AUC: 0.8469
Epoch 32 Global_step 2673000	Train_loss: 0.1993	Eval_AUC: 0.8431
Epoch 32 Global_step 2674000	Train_loss: 0.1946	Eval_AUC: 0.8529
Epoch 32 Global_step 2675000	Train_loss: 0.1943	Eval_AUC: 0.8522
Epoch 32 Global_step 2676000	Train_loss: 0.1934	Eval_AUC: 0.8471
Epoch 32 Global_step 2677000	Train_loss: 0.1944	Eval_AUC: 0.8445
Epoch 32 Global_step 2678000	Train_loss: 0.1951	Eval_AUC: 0.8537
Epoch 32 Global_step 2679000	Train_loss: 0.1947	Eval_AUC: 0.8470
Epoch 32 Global_step 2680000	Train_loss: 0.1965	Eval_AUC: 0.8457
Epoch 32 Global_step 2681000	Train_loss: 0.1970	Eval_AUC: 0.8438
Epoch 32 Global_step 2682000	Train_loss: 0.1997	Eval_AUC: 0.8503
Epoch 32 Global_step 2683000	Train_loss: 0.1959	Eval_AUC: 0.8478
Epoch 32 Global_step 2684000	Train_loss: 0.1988	Eval_AUC: 0.8509
Epoch 32 Global_step 2685000	Train_loss: 0.1964	Eval_AUC: 0.8443
Epoch 32 Global_step 2686000	Train_loss: 0.1964	Eval_AUC: 0.8503
Epoch 32 Global_step 2687000	Train_loss: 0.1960	Eval_AUC: 0.8479
Epoch 32 Global_step 2688000	Train_loss: 0.1945	Eval_AUC: 0.8465
Epoch 32 Global_step 2689000	Train_loss: 0.1972	Eval_AUC: 0.8494
Epoch 32 Global_step 2690000	Train_loss: 0.1994	Eval_AUC: 0.8474
Epoch 32 DONE	Cost time: 255484.31
Epoch 33 Global_step 2691000	Train_loss: 0.1795	Eval_AUC: 0.8460
Epoch 33 Global_step 2692000	Train_loss: 0.1719	Eval_AUC: 0.8450
Epoch 33 Global_step 2693000	Train_loss: 0.1701	Eval_AUC: 0.8458
Epoch 33 Global_step 2694000	Train_loss: 0.1690	Eval_AUC: 0.8476
Epoch 33 Global_step 2695000	Train_loss: 0.1707	Eval_AUC: 0.8485
Epoch 33 Global_step 2696000	Train_loss: 0.1721	Eval_AUC: 0.8433
Epoch 33 Global_step 2697000	Train_loss: 0.1728	Eval_AUC: 0.8435
Epoch 33 Global_step 2698000	Train_loss: 0.1735	Eval_AUC: 0.8495
Epoch 33 Global_step 2699000	Train_loss: 0.1734	Eval_AUC: 0.8461
Epoch 33 Global_step 2700000	Train_loss: 0.1756	Eval_AUC: 0.8433
Epoch 33 Global_step 2701000	Train_loss: 0.1734	Eval_AUC: 0.8501
Epoch 33 Global_step 2702000	Train_loss: 0.1736	Eval_AUC: 0.8454
Epoch 33 Global_step 2703000	Train_loss: 0.1731	Eval_AUC: 0.8476
Epoch 33 Global_step 2704000	Train_loss: 0.1769	Eval_AUC: 0.8481
Epoch 33 Global_step 2705000	Train_loss: 0.1742	Eval_AUC: 0.8449
Epoch 33 Global_step 2706000	Train_loss: 0.1784	Eval_AUC: 0.8492
Epoch 33 Global_step 2707000	Train_loss: 0.1762	Eval_AUC: 0.8480
Epoch 33 Global_step 2708000	Train_loss: 0.1739	Eval_AUC: 0.8441
Epoch 33 Global_step 2709000	Train_loss: 0.1774	Eval_AUC: 0.8438
Epoch 33 Global_step 2710000	Train_loss: 0.1771	Eval_AUC: 0.8467
Epoch 33 Global_step 2711000	Train_loss: 0.1776	Eval_AUC: 0.8459
Epoch 33 Global_step 2712000	Train_loss: 0.1796	Eval_AUC: 0.8469
Epoch 33 Global_step 2713000	Train_loss: 0.1777	Eval_AUC: 0.8462
Epoch 33 Global_step 2714000	Train_loss: 0.1789	Eval_AUC: 0.8444
Epoch 33 Global_step 2715000	Train_loss: 0.1772	Eval_AUC: 0.8475
Epoch 33 Global_step 2716000	Train_loss: 0.1799	Eval_AUC: 0.8480
Epoch 33 Global_step 2717000	Train_loss: 0.1818	Eval_AUC: 0.8461
Epoch 33 Global_step 2718000	Train_loss: 0.1795	Eval_AUC: 0.8475
Epoch 33 Global_step 2719000	Train_loss: 0.1827	Eval_AUC: 0.8472
Epoch 33 Global_step 2720000	Train_loss: 0.1833	Eval_AUC: 0.8418
Epoch 33 Global_step 2721000	Train_loss: 0.1810	Eval_AUC: 0.8465
Epoch 33 Global_step 2722000	Train_loss: 0.1835	Eval_AUC: 0.8437
Epoch 33 Global_step 2723000	Train_loss: 0.1821	Eval_AUC: 0.8477
Epoch 33 Global_step 2724000	Train_loss: 0.1855	Eval_AUC: 0.8461
Epoch 33 Global_step 2725000	Train_loss: 0.1819	Eval_AUC: 0.8440
Epoch 33 Global_step 2726000	Train_loss: 0.1854	Eval_AUC: 0.8467
Epoch 33 Global_step 2727000	Train_loss: 0.1832	Eval_AUC: 0.8491
Epoch 33 Global_step 2728000	Train_loss: 0.1850	Eval_AUC: 0.8456
Epoch 33 Global_step 2729000	Train_loss: 0.1824	Eval_AUC: 0.8436
Epoch 33 Global_step 2730000	Train_loss: 0.1828	Eval_AUC: 0.8446
Epoch 33 Global_step 2731000	Train_loss: 0.1840	Eval_AUC: 0.8490
Epoch 33 Global_step 2732000	Train_loss: 0.1864	Eval_AUC: 0.8441
Epoch 33 Global_step 2733000	Train_loss: 0.1852	Eval_AUC: 0.8500
Epoch 33 Global_step 2734000	Train_loss: 0.1830	Eval_AUC: 0.8485
Epoch 33 Global_step 2735000	Train_loss: 0.1809	Eval_AUC: 0.8453
Epoch 33 Global_step 2736000	Train_loss: 0.1856	Eval_AUC: 0.8450
Epoch 33 Global_step 2737000	Train_loss: 0.1841	Eval_AUC: 0.8495
Epoch 33 Global_step 2738000	Train_loss: 0.1852	Eval_AUC: 0.8470
Epoch 33 Global_step 2739000	Train_loss: 0.1863	Eval_AUC: 0.8500
Epoch 33 Global_step 2740000	Train_loss: 0.1856	Eval_AUC: 0.8500
Epoch 33 Global_step 2741000	Train_loss: 0.1860	Eval_AUC: 0.8470
Epoch 33 Global_step 2742000	Train_loss: 0.1866	Eval_AUC: 0.8499
Epoch 33 Global_step 2743000	Train_loss: 0.1864	Eval_AUC: 0.8506
Epoch 33 Global_step 2744000	Train_loss: 0.1876	Eval_AUC: 0.8481
Epoch 33 Global_step 2745000	Train_loss: 0.1839	Eval_AUC: 0.8499
Epoch 33 Global_step 2746000	Train_loss: 0.1867	Eval_AUC: 0.8478
Epoch 33 Global_step 2747000	Train_loss: 0.1882	Eval_AUC: 0.8471
Epoch 33 Global_step 2748000	Train_loss: 0.1906	Eval_AUC: 0.8492
Epoch 33 Global_step 2749000	Train_loss: 0.1871	Eval_AUC: 0.8496
Epoch 33 Global_step 2750000	Train_loss: 0.1897	Eval_AUC: 0.8467
Epoch 33 Global_step 2751000	Train_loss: 0.1906	Eval_AUC: 0.8431
Epoch 33 Global_step 2752000	Train_loss: 0.1904	Eval_AUC: 0.8453
Epoch 33 Global_step 2753000	Train_loss: 0.1913	Eval_AUC: 0.8456
Epoch 33 Global_step 2754000	Train_loss: 0.1922	Eval_AUC: 0.8461
Epoch 33 Global_step 2755000	Train_loss: 0.1905	Eval_AUC: 0.8484
Epoch 33 Global_step 2756000	Train_loss: 0.1900	Eval_AUC: 0.8479
Epoch 33 Global_step 2757000	Train_loss: 0.1898	Eval_AUC: 0.8468
Epoch 33 Global_step 2758000	Train_loss: 0.1893	Eval_AUC: 0.8492
Epoch 33 Global_step 2759000	Train_loss: 0.1930	Eval_AUC: 0.8465
Epoch 33 Global_step 2760000	Train_loss: 0.1900	Eval_AUC: 0.8450
Epoch 33 Global_step 2761000	Train_loss: 0.1896	Eval_AUC: 0.8458
Epoch 33 Global_step 2762000	Train_loss: 0.1915	Eval_AUC: 0.8474
Epoch 33 Global_step 2763000	Train_loss: 0.1938	Eval_AUC: 0.8458
Epoch 33 Global_step 2764000	Train_loss: 0.1927	Eval_AUC: 0.8469
Epoch 33 Global_step 2765000	Train_loss: 0.1948	Eval_AUC: 0.8472
Epoch 33 Global_step 2766000	Train_loss: 0.1911	Eval_AUC: 0.8469
Epoch 33 Global_step 2767000	Train_loss: 0.1934	Eval_AUC: 0.8480
Epoch 33 Global_step 2768000	Train_loss: 0.1971	Eval_AUC: 0.8508
Epoch 33 Global_step 2769000	Train_loss: 0.1950	Eval_AUC: 0.8497
Epoch 33 Global_step 2770000	Train_loss: 0.1932	Eval_AUC: 0.8485
Epoch 33 Global_step 2771000	Train_loss: 0.1955	Eval_AUC: 0.8427
Epoch 33 DONE	Cost time: 262586.71
Epoch 34 Global_step 2772000	Train_loss: 0.1865	Eval_AUC: 0.8466
Epoch 34 Global_step 2773000	Train_loss: 0.1643	Eval_AUC: 0.8445
Epoch 34 Global_step 2774000	Train_loss: 0.1653	Eval_AUC: 0.8402
Epoch 34 Global_step 2775000	Train_loss: 0.1687	Eval_AUC: 0.8488
Epoch 34 Global_step 2776000	Train_loss: 0.1652	Eval_AUC: 0.8417
Epoch 34 Global_step 2777000	Train_loss: 0.1705	Eval_AUC: 0.8445
Epoch 34 Global_step 2778000	Train_loss: 0.1668	Eval_AUC: 0.8446
Epoch 34 Global_step 2779000	Train_loss: 0.1662	Eval_AUC: 0.8447
Epoch 34 Global_step 2780000	Train_loss: 0.1683	Eval_AUC: 0.8469
Epoch 34 Global_step 2781000	Train_loss: 0.1687	Eval_AUC: 0.8426
Epoch 34 Global_step 2782000	Train_loss: 0.1707	Eval_AUC: 0.8471
Epoch 34 Global_step 2783000	Train_loss: 0.1696	Eval_AUC: 0.8439
Epoch 34 Global_step 2784000	Train_loss: 0.1709	Eval_AUC: 0.8436
Epoch 34 Global_step 2785000	Train_loss: 0.1678	Eval_AUC: 0.8434
Epoch 34 Global_step 2786000	Train_loss: 0.1711	Eval_AUC: 0.8466
Epoch 34 Global_step 2787000	Train_loss: 0.1704	Eval_AUC: 0.8450
Epoch 34 Global_step 2788000	Train_loss: 0.1732	Eval_AUC: 0.8413
Epoch 34 Global_step 2789000	Train_loss: 0.1731	Eval_AUC: 0.8503
Epoch 34 Global_step 2790000	Train_loss: 0.1699	Eval_AUC: 0.8468
Epoch 34 Global_step 2791000	Train_loss: 0.1758	Eval_AUC: 0.8448
Epoch 34 Global_step 2792000	Train_loss: 0.1768	Eval_AUC: 0.8460
Epoch 34 Global_step 2793000	Train_loss: 0.1737	Eval_AUC: 0.8463
Epoch 34 Global_step 2794000	Train_loss: 0.1732	Eval_AUC: 0.8478
Epoch 34 Global_step 2795000	Train_loss: 0.1708	Eval_AUC: 0.8453
Epoch 34 Global_step 2796000	Train_loss: 0.1755	Eval_AUC: 0.8473
Epoch 34 Global_step 2797000	Train_loss: 0.1741	Eval_AUC: 0.8418
Epoch 34 Global_step 2798000	Train_loss: 0.1738	Eval_AUC: 0.8458
Epoch 34 Global_step 2799000	Train_loss: 0.1770	Eval_AUC: 0.8452
Epoch 34 Global_step 2800000	Train_loss: 0.1790	Eval_AUC: 0.8483
Epoch 34 Global_step 2801000	Train_loss: 0.1777	Eval_AUC: 0.8425
Epoch 34 Global_step 2802000	Train_loss: 0.1780	Eval_AUC: 0.8438
Epoch 34 Global_step 2803000	Train_loss: 0.1789	Eval_AUC: 0.8497
Epoch 34 Global_step 2804000	Train_loss: 0.1795	Eval_AUC: 0.8401
Epoch 34 Global_step 2805000	Train_loss: 0.1787	Eval_AUC: 0.8410
Epoch 34 Global_step 2806000	Train_loss: 0.1782	Eval_AUC: 0.8442
Epoch 34 Global_step 2807000	Train_loss: 0.1798	Eval_AUC: 0.8430
Epoch 34 Global_step 2808000	Train_loss: 0.1787	Eval_AUC: 0.8444
Epoch 34 Global_step 2809000	Train_loss: 0.1781	Eval_AUC: 0.8433
Epoch 34 Global_step 2810000	Train_loss: 0.1783	Eval_AUC: 0.8473
Epoch 34 Global_step 2811000	Train_loss: 0.1805	Eval_AUC: 0.8443
Epoch 34 Global_step 2812000	Train_loss: 0.1798	Eval_AUC: 0.8449
Epoch 34 Global_step 2813000	Train_loss: 0.1835	Eval_AUC: 0.8469
Epoch 34 Global_step 2814000	Train_loss: 0.1790	Eval_AUC: 0.8437
Epoch 34 Global_step 2815000	Train_loss: 0.1810	Eval_AUC: 0.8458
Epoch 34 Global_step 2816000	Train_loss: 0.1818	Eval_AUC: 0.8445
Epoch 34 Global_step 2817000	Train_loss: 0.1822	Eval_AUC: 0.8423
Epoch 34 Global_step 2818000	Train_loss: 0.1805	Eval_AUC: 0.8484
Epoch 34 Global_step 2819000	Train_loss: 0.1797	Eval_AUC: 0.8413
Epoch 34 Global_step 2820000	Train_loss: 0.1846	Eval_AUC: 0.8468
Epoch 34 Global_step 2821000	Train_loss: 0.1850	Eval_AUC: 0.8452
Epoch 34 Global_step 2822000	Train_loss: 0.1852	Eval_AUC: 0.8468
Epoch 34 Global_step 2823000	Train_loss: 0.1834	Eval_AUC: 0.8440
Epoch 34 Global_step 2824000	Train_loss: 0.1823	Eval_AUC: 0.8459
Epoch 34 Global_step 2825000	Train_loss: 0.1850	Eval_AUC: 0.8440
Epoch 34 Global_step 2826000	Train_loss: 0.1807	Eval_AUC: 0.8447
Epoch 34 Global_step 2827000	Train_loss: 0.1844	Eval_AUC: 0.8435
Epoch 34 Global_step 2828000	Train_loss: 0.1841	Eval_AUC: 0.8438
Epoch 34 Global_step 2829000	Train_loss: 0.1810	Eval_AUC: 0.8439
Epoch 34 Global_step 2830000	Train_loss: 0.1844	Eval_AUC: 0.8462
Epoch 34 Global_step 2831000	Train_loss: 0.1879	Eval_AUC: 0.8475
Epoch 34 Global_step 2832000	Train_loss: 0.1855	Eval_AUC: 0.8449
Epoch 34 Global_step 2833000	Train_loss: 0.1862	Eval_AUC: 0.8456
Epoch 34 Global_step 2834000	Train_loss: 0.1867	Eval_AUC: 0.8476
Epoch 34 Global_step 2835000	Train_loss: 0.1858	Eval_AUC: 0.8489
Epoch 34 Global_step 2836000	Train_loss: 0.1886	Eval_AUC: 0.8463
Epoch 34 Global_step 2837000	Train_loss: 0.1862	Eval_AUC: 0.8477
Epoch 34 Global_step 2838000	Train_loss: 0.1886	Eval_AUC: 0.8486
Epoch 34 Global_step 2839000	Train_loss: 0.1869	Eval_AUC: 0.8509
Epoch 34 Global_step 2840000	Train_loss: 0.1864	Eval_AUC: 0.8461
Epoch 34 Global_step 2841000	Train_loss: 0.1871	Eval_AUC: 0.8478
Epoch 34 Global_step 2842000	Train_loss: 0.1878	Eval_AUC: 0.8465
Epoch 34 Global_step 2843000	Train_loss: 0.1879	Eval_AUC: 0.8453
Epoch 34 Global_step 2844000	Train_loss: 0.1897	Eval_AUC: 0.8478
Epoch 34 Global_step 2845000	Train_loss: 0.1895	Eval_AUC: 0.8426
Epoch 34 Global_step 2846000	Train_loss: 0.1865	Eval_AUC: 0.8450
Epoch 34 Global_step 2847000	Train_loss: 0.1889	Eval_AUC: 0.8429
Epoch 34 Global_step 2848000	Train_loss: 0.1914	Eval_AUC: 0.8453
Epoch 34 Global_step 2849000	Train_loss: 0.1888	Eval_AUC: 0.8464
Epoch 34 Global_step 2850000	Train_loss: 0.1909	Eval_AUC: 0.8469
Epoch 34 Global_step 2851000	Train_loss: 0.1885	Eval_AUC: 0.8466
Epoch 34 Global_step 2852000	Train_loss: 0.1897	Eval_AUC: 0.8503
Epoch 34 Global_step 2853000	Train_loss: 0.1889	Eval_AUC: 0.8460
Epoch 34 DONE	Cost time: 269808.07
Epoch 35 Global_step 2854000	Train_loss: 0.1746	Eval_AUC: 0.8420
Epoch 35 Global_step 2855000	Train_loss: 0.1641	Eval_AUC: 0.8474
Epoch 35 Global_step 2856000	Train_loss: 0.1645	Eval_AUC: 0.8467
Epoch 35 Global_step 2857000	Train_loss: 0.1632	Eval_AUC: 0.8422
Epoch 35 Global_step 2858000	Train_loss: 0.1633	Eval_AUC: 0.8442
Epoch 35 Global_step 2859000	Train_loss: 0.1652	Eval_AUC: 0.8429
Epoch 35 Global_step 2860000	Train_loss: 0.1642	Eval_AUC: 0.8436
Epoch 35 Global_step 2861000	Train_loss: 0.1670	Eval_AUC: 0.8410
Epoch 35 Global_step 2862000	Train_loss: 0.1660	Eval_AUC: 0.8452
Epoch 35 Global_step 2863000	Train_loss: 0.1674	Eval_AUC: 0.8439
Epoch 35 Global_step 2864000	Train_loss: 0.1685	Eval_AUC: 0.8406
Epoch 35 Global_step 2865000	Train_loss: 0.1665	Eval_AUC: 0.8402
Epoch 35 Global_step 2866000	Train_loss: 0.1699	Eval_AUC: 0.8442
Epoch 35 Global_step 2867000	Train_loss: 0.1671	Eval_AUC: 0.8460
Epoch 35 Global_step 2868000	Train_loss: 0.1693	Eval_AUC: 0.8407
Epoch 35 Global_step 2869000	Train_loss: 0.1672	Eval_AUC: 0.8459
Epoch 35 Global_step 2870000	Train_loss: 0.1694	Eval_AUC: 0.8420
Epoch 35 Global_step 2871000	Train_loss: 0.1679	Eval_AUC: 0.8452
Epoch 35 Global_step 2872000	Train_loss: 0.1685	Eval_AUC: 0.8439
Epoch 35 Global_step 2873000	Train_loss: 0.1700	Eval_AUC: 0.8434
Epoch 35 Global_step 2874000	Train_loss: 0.1681	Eval_AUC: 0.8441
Epoch 35 Global_step 2875000	Train_loss: 0.1728	Eval_AUC: 0.8463
Epoch 35 Global_step 2876000	Train_loss: 0.1725	Eval_AUC: 0.8462
Epoch 35 Global_step 2877000	Train_loss: 0.1707	Eval_AUC: 0.8465
Epoch 35 Global_step 2878000	Train_loss: 0.1692	Eval_AUC: 0.8448
Epoch 35 Global_step 2879000	Train_loss: 0.1716	Eval_AUC: 0.8458
Epoch 35 Global_step 2880000	Train_loss: 0.1746	Eval_AUC: 0.8435
Epoch 35 Global_step 2881000	Train_loss: 0.1716	Eval_AUC: 0.8451
Epoch 35 Global_step 2882000	Train_loss: 0.1753	Eval_AUC: 0.8441
Epoch 35 Global_step 2883000	Train_loss: 0.1715	Eval_AUC: 0.8426
Epoch 35 Global_step 2884000	Train_loss: 0.1714	Eval_AUC: 0.8474
Epoch 35 Global_step 2885000	Train_loss: 0.1764	Eval_AUC: 0.8446
Epoch 35 Global_step 2886000	Train_loss: 0.1754	Eval_AUC: 0.8423
Epoch 35 Global_step 2887000	Train_loss: 0.1763	Eval_AUC: 0.8428
Epoch 35 Global_step 2888000	Train_loss: 0.1755	Eval_AUC: 0.8464
Epoch 35 Global_step 2889000	Train_loss: 0.1744	Eval_AUC: 0.8487
Epoch 35 Global_step 2890000	Train_loss: 0.1761	Eval_AUC: 0.8472
Epoch 35 Global_step 2891000	Train_loss: 0.1767	Eval_AUC: 0.8438
Epoch 35 Global_step 2892000	Train_loss: 0.1799	Eval_AUC: 0.8474
Epoch 35 Global_step 2893000	Train_loss: 0.1758	Eval_AUC: 0.8460
Epoch 35 Global_step 2894000	Train_loss: 0.1783	Eval_AUC: 0.8468
Epoch 35 Global_step 2895000	Train_loss: 0.1763	Eval_AUC: 0.8471
Epoch 35 Global_step 2896000	Train_loss: 0.1768	Eval_AUC: 0.8436
Epoch 35 Global_step 2897000	Train_loss: 0.1754	Eval_AUC: 0.8405
Epoch 35 Global_step 2898000	Train_loss: 0.1744	Eval_AUC: 0.8441
Epoch 35 Global_step 2899000	Train_loss: 0.1759	Eval_AUC: 0.8421
Epoch 35 Global_step 2900000	Train_loss: 0.1781	Eval_AUC: 0.8486
Epoch 35 Global_step 2901000	Train_loss: 0.1775	Eval_AUC: 0.8429
Epoch 35 Global_step 2902000	Train_loss: 0.1808	Eval_AUC: 0.8429
Epoch 35 Global_step 2903000	Train_loss: 0.1806	Eval_AUC: 0.8379
Epoch 35 Global_step 2904000	Train_loss: 0.1775	Eval_AUC: 0.8425
Epoch 35 Global_step 2905000	Train_loss: 0.1812	Eval_AUC: 0.8427
Epoch 35 Global_step 2906000	Train_loss: 0.1811	Eval_AUC: 0.8437
Epoch 35 Global_step 2907000	Train_loss: 0.1787	Eval_AUC: 0.8471
Epoch 35 Global_step 2908000	Train_loss: 0.1756	Eval_AUC: 0.8477
Epoch 35 Global_step 2909000	Train_loss: 0.1789	Eval_AUC: 0.8470
Epoch 35 Global_step 2910000	Train_loss: 0.1814	Eval_AUC: 0.8471
Epoch 35 Global_step 2911000	Train_loss: 0.1810	Eval_AUC: 0.8471
Epoch 35 Global_step 2912000	Train_loss: 0.1786	Eval_AUC: 0.8429
Epoch 35 Global_step 2913000	Train_loss: 0.1814	Eval_AUC: 0.8363
Epoch 35 Global_step 2914000	Train_loss: 0.1813	Eval_AUC: 0.8489
Epoch 35 Global_step 2915000	Train_loss: 0.1817	Eval_AUC: 0.8435
Epoch 35 Global_step 2916000	Train_loss: 0.1830	Eval_AUC: 0.8447
Epoch 35 Global_step 2917000	Train_loss: 0.1812	Eval_AUC: 0.8460
Epoch 35 Global_step 2918000	Train_loss: 0.1840	Eval_AUC: 0.8435
Epoch 35 Global_step 2919000	Train_loss: 0.1840	Eval_AUC: 0.8388
Epoch 35 Global_step 2920000	Train_loss: 0.1822	Eval_AUC: 0.8375
Epoch 35 Global_step 2921000	Train_loss: 0.1832	Eval_AUC: 0.8483
Epoch 35 Global_step 2922000	Train_loss: 0.1848	Eval_AUC: 0.8435
Epoch 35 Global_step 2923000	Train_loss: 0.1803	Eval_AUC: 0.8450
Epoch 35 Global_step 2924000	Train_loss: 0.1850	Eval_AUC: 0.8434
Epoch 35 Global_step 2925000	Train_loss: 0.1848	Eval_AUC: 0.8450
Epoch 35 Global_step 2926000	Train_loss: 0.1841	Eval_AUC: 0.8396
Epoch 35 Global_step 2927000	Train_loss: 0.1805	Eval_AUC: 0.8437
Epoch 35 Global_step 2928000	Train_loss: 0.1852	Eval_AUC: 0.8456
Epoch 35 Global_step 2929000	Train_loss: 0.1849	Eval_AUC: 0.8452
Epoch 35 Global_step 2930000	Train_loss: 0.1855	Eval_AUC: 0.8451
Epoch 35 Global_step 2931000	Train_loss: 0.1862	Eval_AUC: 0.8459
Epoch 35 Global_step 2932000	Train_loss: 0.1868	Eval_AUC: 0.8447
Epoch 35 Global_step 2933000	Train_loss: 0.1845	Eval_AUC: 0.8480
Epoch 35 Global_step 2934000	Train_loss: 0.1829	Eval_AUC: 0.8453
Epoch 35 DONE	Cost time: 276964.96
Epoch 36 Global_step 2935000	Train_loss: 0.1794	Eval_AUC: 0.8459
Epoch 36 Global_step 2936000	Train_loss: 0.1594	Eval_AUC: 0.8433
Epoch 36 Global_step 2937000	Train_loss: 0.1627	Eval_AUC: 0.8431
Epoch 36 Global_step 2938000	Train_loss: 0.1588	Eval_AUC: 0.8436
Epoch 36 Global_step 2939000	Train_loss: 0.1614	Eval_AUC: 0.8432
Epoch 36 Global_step 2940000	Train_loss: 0.1619	Eval_AUC: 0.8441
Epoch 36 Global_step 2941000	Train_loss: 0.1608	Eval_AUC: 0.8434
Epoch 36 Global_step 2942000	Train_loss: 0.1625	Eval_AUC: 0.8446
Epoch 36 Global_step 2943000	Train_loss: 0.1614	Eval_AUC: 0.8466
Epoch 36 Global_step 2944000	Train_loss: 0.1638	Eval_AUC: 0.8422
Epoch 36 Global_step 2945000	Train_loss: 0.1639	Eval_AUC: 0.8464
Epoch 36 Global_step 2946000	Train_loss: 0.1638	Eval_AUC: 0.8436
Epoch 36 Global_step 2947000	Train_loss: 0.1617	Eval_AUC: 0.8442
Epoch 36 Global_step 2948000	Train_loss: 0.1659	Eval_AUC: 0.8412
Epoch 36 Global_step 2949000	Train_loss: 0.1647	Eval_AUC: 0.8443
Epoch 36 Global_step 2950000	Train_loss: 0.1652	Eval_AUC: 0.8441
Epoch 36 Global_step 2951000	Train_loss: 0.1637	Eval_AUC: 0.8453
Epoch 36 Global_step 2952000	Train_loss: 0.1651	Eval_AUC: 0.8389
Epoch 36 Global_step 2953000	Train_loss: 0.1659	Eval_AUC: 0.8484
Epoch 36 Global_step 2954000	Train_loss: 0.1659	Eval_AUC: 0.8442
Epoch 36 Global_step 2955000	Train_loss: 0.1667	Eval_AUC: 0.8433
Epoch 36 Global_step 2956000	Train_loss: 0.1671	Eval_AUC: 0.8438
Epoch 36 Global_step 2957000	Train_loss: 0.1652	Eval_AUC: 0.8451
Epoch 36 Global_step 2958000	Train_loss: 0.1708	Eval_AUC: 0.8419
Epoch 36 Global_step 2959000	Train_loss: 0.1684	Eval_AUC: 0.8441
Epoch 36 Global_step 2960000	Train_loss: 0.1691	Eval_AUC: 0.8462
Epoch 36 Global_step 2961000	Train_loss: 0.1701	Eval_AUC: 0.8436
Epoch 36 Global_step 2962000	Train_loss: 0.1676	Eval_AUC: 0.8459
Epoch 36 Global_step 2963000	Train_loss: 0.1684	Eval_AUC: 0.8425
Epoch 36 Global_step 2964000	Train_loss: 0.1690	Eval_AUC: 0.8406
Epoch 36 Global_step 2965000	Train_loss: 0.1703	Eval_AUC: 0.8440
Epoch 36 Global_step 2966000	Train_loss: 0.1703	Eval_AUC: 0.8407
Epoch 36 Global_step 2967000	Train_loss: 0.1698	Eval_AUC: 0.8421
Epoch 36 Global_step 2968000	Train_loss: 0.1711	Eval_AUC: 0.8442
Epoch 36 Global_step 2969000	Train_loss: 0.1704	Eval_AUC: 0.8418
Epoch 36 Global_step 2970000	Train_loss: 0.1718	Eval_AUC: 0.8465
Epoch 36 Global_step 2971000	Train_loss: 0.1706	Eval_AUC: 0.8451
Epoch 36 Global_step 2972000	Train_loss: 0.1717	Eval_AUC: 0.8447
Epoch 36 Global_step 2973000	Train_loss: 0.1725	Eval_AUC: 0.8443
Epoch 36 Global_step 2974000	Train_loss: 0.1704	Eval_AUC: 0.8435
Epoch 36 Global_step 2975000	Train_loss: 0.1695	Eval_AUC: 0.8420
Epoch 36 Global_step 2976000	Train_loss: 0.1729	Eval_AUC: 0.8430
Epoch 36 Global_step 2977000	Train_loss: 0.1718	Eval_AUC: 0.8397
Epoch 36 Global_step 2978000	Train_loss: 0.1728	Eval_AUC: 0.8460
Epoch 36 Global_step 2979000	Train_loss: 0.1745	Eval_AUC: 0.8429
Epoch 36 Global_step 2980000	Train_loss: 0.1757	Eval_AUC: 0.8471
Epoch 36 Global_step 2981000	Train_loss: 0.1758	Eval_AUC: 0.8449
Epoch 36 Global_step 2982000	Train_loss: 0.1745	Eval_AUC: 0.8461
Epoch 36 Global_step 2983000	Train_loss: 0.1768	Eval_AUC: 0.8454
Epoch 36 Global_step 2984000	Train_loss: 0.1731	Eval_AUC: 0.8464
Epoch 36 Global_step 2985000	Train_loss: 0.1755	Eval_AUC: 0.8409
Epoch 36 Global_step 2986000	Train_loss: 0.1750	Eval_AUC: 0.8453
Epoch 36 Global_step 2987000	Train_loss: 0.1742	Eval_AUC: 0.8441
Epoch 36 Global_step 2988000	Train_loss: 0.1753	Eval_AUC: 0.8434
Epoch 36 Global_step 2989000	Train_loss: 0.1753	Eval_AUC: 0.8456
Epoch 36 Global_step 2990000	Train_loss: 0.1766	Eval_AUC: 0.8409
Epoch 36 Global_step 2991000	Train_loss: 0.1781	Eval_AUC: 0.8464
Epoch 36 Global_step 2992000	Train_loss: 0.1742	Eval_AUC: 0.8414
Epoch 36 Global_step 2993000	Train_loss: 0.1796	Eval_AUC: 0.8388
Epoch 36 Global_step 2994000	Train_loss: 0.1774	Eval_AUC: 0.8413
Epoch 36 Global_step 2995000	Train_loss: 0.1742	Eval_AUC: 0.8458
Epoch 36 Global_step 2996000	Train_loss: 0.1775	Eval_AUC: 0.8453
Epoch 36 Global_step 2997000	Train_loss: 0.1752	Eval_AUC: 0.8408
Epoch 36 Global_step 2998000	Train_loss: 0.1804	Eval_AUC: 0.8468
Epoch 36 Global_step 2999000	Train_loss: 0.1792	Eval_AUC: 0.8456
Epoch 36 Global_step 3000000	Train_loss: 0.1787	Eval_AUC: 0.8442
Epoch 36 Global_step 3001000	Train_loss: 0.1798	Eval_AUC: 0.8410
Epoch 36 Global_step 3002000	Train_loss: 0.1761	Eval_AUC: 0.8447
Epoch 36 Global_step 3003000	Train_loss: 0.1790	Eval_AUC: 0.8442
Epoch 36 Global_step 3004000	Train_loss: 0.1796	Eval_AUC: 0.8483
Epoch 36 Global_step 3005000	Train_loss: 0.1807	Eval_AUC: 0.8403
Epoch 36 Global_step 3006000	Train_loss: 0.1789	Eval_AUC: 0.8494
Epoch 36 Global_step 3007000	Train_loss: 0.1808	Eval_AUC: 0.8447
Epoch 36 Global_step 3008000	Train_loss: 0.1828	Eval_AUC: 0.8456
Epoch 36 Global_step 3009000	Train_loss: 0.1789	Eval_AUC: 0.8377
Epoch 36 Global_step 3010000	Train_loss: 0.1800	Eval_AUC: 0.8423
Epoch 36 Global_step 3011000	Train_loss: 0.1794	Eval_AUC: 0.8448
Epoch 36 Global_step 3012000	Train_loss: 0.1829	Eval_AUC: 0.8414
Epoch 36 Global_step 3013000	Train_loss: 0.1831	Eval_AUC: 0.8462
Epoch 36 Global_step 3014000	Train_loss: 0.1821	Eval_AUC: 0.8448
Epoch 36 Global_step 3015000	Train_loss: 0.1820	Eval_AUC: 0.8428
Epoch 36 Global_step 3016000	Train_loss: 0.1830	Eval_AUC: 0.8420
Epoch 36 DONE	Cost time: 284184.22
Epoch 37 Global_step 3017000	Train_loss: 0.1699	Eval_AUC: 0.8404
Epoch 37 Global_step 3018000	Train_loss: 0.1573	Eval_AUC: 0.8412
Epoch 37 Global_step 3019000	Train_loss: 0.1573	Eval_AUC: 0.8395
Epoch 37 Global_step 3020000	Train_loss: 0.1579	Eval_AUC: 0.8411
Epoch 37 Global_step 3021000	Train_loss: 0.1580	Eval_AUC: 0.8417
Epoch 37 Global_step 3022000	Train_loss: 0.1584	Eval_AUC: 0.8417
Epoch 37 Global_step 3023000	Train_loss: 0.1576	Eval_AUC: 0.8414
Epoch 37 Global_step 3024000	Train_loss: 0.1584	Eval_AUC: 0.8437
Epoch 37 Global_step 3025000	Train_loss: 0.1579	Eval_AUC: 0.8429
Epoch 37 Global_step 3026000	Train_loss: 0.1600	Eval_AUC: 0.8391
Epoch 37 Global_step 3027000	Train_loss: 0.1587	Eval_AUC: 0.8402
Epoch 37 Global_step 3028000	Train_loss: 0.1589	Eval_AUC: 0.8443
Epoch 37 Global_step 3029000	Train_loss: 0.1618	Eval_AUC: 0.8430
Epoch 37 Global_step 3030000	Train_loss: 0.1592	Eval_AUC: 0.8453
Epoch 37 Global_step 3031000	Train_loss: 0.1624	Eval_AUC: 0.8390
Epoch 37 Global_step 3032000	Train_loss: 0.1621	Eval_AUC: 0.8438
Epoch 37 Global_step 3033000	Train_loss: 0.1625	Eval_AUC: 0.8423
Epoch 37 Global_step 3034000	Train_loss: 0.1621	Eval_AUC: 0.8414
Epoch 37 Global_step 3035000	Train_loss: 0.1615	Eval_AUC: 0.8431
Epoch 37 Global_step 3036000	Train_loss: 0.1634	Eval_AUC: 0.8415
Epoch 37 Global_step 3037000	Train_loss: 0.1629	Eval_AUC: 0.8414
Epoch 37 Global_step 3038000	Train_loss: 0.1620	Eval_AUC: 0.8412
Epoch 37 Global_step 3039000	Train_loss: 0.1622	Eval_AUC: 0.8433
Epoch 37 Global_step 3040000	Train_loss: 0.1638	Eval_AUC: 0.8435
Epoch 37 Global_step 3041000	Train_loss: 0.1633	Eval_AUC: 0.8390
Epoch 37 Global_step 3042000	Train_loss: 0.1641	Eval_AUC: 0.8428
Epoch 37 Global_step 3043000	Train_loss: 0.1664	Eval_AUC: 0.8433
Epoch 37 Global_step 3044000	Train_loss: 0.1656	Eval_AUC: 0.8437
Epoch 37 Global_step 3045000	Train_loss: 0.1657	Eval_AUC: 0.8430
Epoch 37 Global_step 3046000	Train_loss: 0.1644	Eval_AUC: 0.8422
Epoch 37 Global_step 3047000	Train_loss: 0.1674	Eval_AUC: 0.8432
Epoch 37 Global_step 3048000	Train_loss: 0.1677	Eval_AUC: 0.8452
Epoch 37 Global_step 3049000	Train_loss: 0.1674	Eval_AUC: 0.8436
Epoch 37 Global_step 3050000	Train_loss: 0.1697	Eval_AUC: 0.8417
Epoch 37 Global_step 3051000	Train_loss: 0.1661	Eval_AUC: 0.8437
Epoch 37 Global_step 3052000	Train_loss: 0.1704	Eval_AUC: 0.8430
Epoch 37 Global_step 3053000	Train_loss: 0.1695	Eval_AUC: 0.8419
Epoch 37 Global_step 3054000	Train_loss: 0.1656	Eval_AUC: 0.8440
Epoch 37 Global_step 3055000	Train_loss: 0.1674	Eval_AUC: 0.8414
Epoch 37 Global_step 3056000	Train_loss: 0.1706	Eval_AUC: 0.8427
Epoch 37 Global_step 3057000	Train_loss: 0.1694	Eval_AUC: 0.8436
Epoch 37 Global_step 3058000	Train_loss: 0.1674	Eval_AUC: 0.8411
Epoch 37 Global_step 3059000	Train_loss: 0.1688	Eval_AUC: 0.8396
Epoch 37 Global_step 3060000	Train_loss: 0.1703	Eval_AUC: 0.8425
Epoch 37 Global_step 3061000	Train_loss: 0.1704	Eval_AUC: 0.8420
Epoch 37 Global_step 3062000	Train_loss: 0.1715	Eval_AUC: 0.8385
Epoch 37 Global_step 3063000	Train_loss: 0.1722	Eval_AUC: 0.8467
Epoch 37 Global_step 3064000	Train_loss: 0.1683	Eval_AUC: 0.8431
Epoch 37 Global_step 3065000	Train_loss: 0.1702	Eval_AUC: 0.8463
Epoch 37 Global_step 3066000	Train_loss: 0.1719	Eval_AUC: 0.8424
Epoch 37 Global_step 3067000	Train_loss: 0.1728	Eval_AUC: 0.8396
Epoch 37 Global_step 3068000	Train_loss: 0.1746	Eval_AUC: 0.8466
Epoch 37 Global_step 3069000	Train_loss: 0.1696	Eval_AUC: 0.8444
Epoch 37 Global_step 3070000	Train_loss: 0.1714	Eval_AUC: 0.8397
Epoch 37 Global_step 3071000	Train_loss: 0.1730	Eval_AUC: 0.8408
Epoch 37 Global_step 3072000	Train_loss: 0.1714	Eval_AUC: 0.8447
Epoch 37 Global_step 3073000	Train_loss: 0.1743	Eval_AUC: 0.8392
Epoch 37 Global_step 3074000	Train_loss: 0.1731	Eval_AUC: 0.8443
Epoch 37 Global_step 3075000	Train_loss: 0.1772	Eval_AUC: 0.8434
Epoch 37 Global_step 3076000	Train_loss: 0.1753	Eval_AUC: 0.8426
Epoch 37 Global_step 3077000	Train_loss: 0.1766	Eval_AUC: 0.8432
Epoch 37 Global_step 3078000	Train_loss: 0.1760	Eval_AUC: 0.8443
Epoch 37 Global_step 3079000	Train_loss: 0.1746	Eval_AUC: 0.8418
Epoch 37 Global_step 3080000	Train_loss: 0.1750	Eval_AUC: 0.8429
Epoch 37 Global_step 3081000	Train_loss: 0.1739	Eval_AUC: 0.8428
Epoch 37 Global_step 3082000	Train_loss: 0.1727	Eval_AUC: 0.8425
Epoch 37 Global_step 3083000	Train_loss: 0.1746	Eval_AUC: 0.8427
Epoch 37 Global_step 3084000	Train_loss: 0.1761	Eval_AUC: 0.8399
Epoch 37 Global_step 3085000	Train_loss: 0.1751	Eval_AUC: 0.8460
Epoch 37 Global_step 3086000	Train_loss: 0.1766	Eval_AUC: 0.8440
Epoch 37 Global_step 3087000	Train_loss: 0.1754	Eval_AUC: 0.8378
Epoch 37 Global_step 3088000	Train_loss: 0.1735	Eval_AUC: 0.8399
Epoch 37 Global_step 3089000	Train_loss: 0.1755	Eval_AUC: 0.8461
Epoch 37 Global_step 3090000	Train_loss: 0.1757	Eval_AUC: 0.8394
Epoch 37 Global_step 3091000	Train_loss: 0.1795	Eval_AUC: 0.8448
Epoch 37 Global_step 3092000	Train_loss: 0.1783	Eval_AUC: 0.8438
Epoch 37 Global_step 3093000	Train_loss: 0.1762	Eval_AUC: 0.8387
Epoch 37 Global_step 3094000	Train_loss: 0.1796	Eval_AUC: 0.8437
Epoch 37 Global_step 3095000	Train_loss: 0.1789	Eval_AUC: 0.8396
Epoch 37 Global_step 3096000	Train_loss: 0.1780	Eval_AUC: 0.8404
Epoch 37 Global_step 3097000	Train_loss: 0.1781	Eval_AUC: 0.8461
Epoch 37 DONE	Cost time: 291353.50
Epoch 38 Global_step 3098000	Train_loss: 0.1755	Eval_AUC: 0.8451
Epoch 38 Global_step 3099000	Train_loss: 0.1551	Eval_AUC: 0.8392
Epoch 38 Global_step 3100000	Train_loss: 0.1567	Eval_AUC: 0.8410
Epoch 38 Global_step 3101000	Train_loss: 0.1523	Eval_AUC: 0.8440
Epoch 38 Global_step 3102000	Train_loss: 0.1542	Eval_AUC: 0.8397
Epoch 38 Global_step 3103000	Train_loss: 0.1537	Eval_AUC: 0.8398
Epoch 38 Global_step 3104000	Train_loss: 0.1544	Eval_AUC: 0.8424
Epoch 38 Global_step 3105000	Train_loss: 0.1548	Eval_AUC: 0.8426
Epoch 38 Global_step 3106000	Train_loss: 0.1545	Eval_AUC: 0.8410
Epoch 38 Global_step 3107000	Train_loss: 0.1519	Eval_AUC: 0.8396
Epoch 38 Global_step 3108000	Train_loss: 0.1543	Eval_AUC: 0.8433
Epoch 38 Global_step 3109000	Train_loss: 0.1546	Eval_AUC: 0.8407
Epoch 38 Global_step 3110000	Train_loss: 0.1588	Eval_AUC: 0.8377
Epoch 38 Global_step 3111000	Train_loss: 0.1572	Eval_AUC: 0.8421
Epoch 38 Global_step 3112000	Train_loss: 0.1586	Eval_AUC: 0.8420
Epoch 38 Global_step 3113000	Train_loss: 0.1586	Eval_AUC: 0.8424
Epoch 38 Global_step 3114000	Train_loss: 0.1593	Eval_AUC: 0.8402
Epoch 38 Global_step 3115000	Train_loss: 0.1587	Eval_AUC: 0.8406
Epoch 38 Global_step 3116000	Train_loss: 0.1611	Eval_AUC: 0.8400
Epoch 38 Global_step 3117000	Train_loss: 0.1591	Eval_AUC: 0.8415
Epoch 38 Global_step 3118000	Train_loss: 0.1618	Eval_AUC: 0.8427
Epoch 38 Global_step 3119000	Train_loss: 0.1600	Eval_AUC: 0.8421
Epoch 38 Global_step 3120000	Train_loss: 0.1609	Eval_AUC: 0.8386
Epoch 38 Global_step 3121000	Train_loss: 0.1593	Eval_AUC: 0.8412
Epoch 38 Global_step 3122000	Train_loss: 0.1614	Eval_AUC: 0.8418
Epoch 38 Global_step 3123000	Train_loss: 0.1623	Eval_AUC: 0.8401
Epoch 38 Global_step 3124000	Train_loss: 0.1616	Eval_AUC: 0.8436
Epoch 38 Global_step 3125000	Train_loss: 0.1628	Eval_AUC: 0.8443
Epoch 38 Global_step 3126000	Train_loss: 0.1656	Eval_AUC: 0.8426
Epoch 38 Global_step 3127000	Train_loss: 0.1620	Eval_AUC: 0.8423
Epoch 38 Global_step 3128000	Train_loss: 0.1637	Eval_AUC: 0.8404
Epoch 38 Global_step 3129000	Train_loss: 0.1633	Eval_AUC: 0.8400
Epoch 38 Global_step 3130000	Train_loss: 0.1638	Eval_AUC: 0.8402
Epoch 38 Global_step 3131000	Train_loss: 0.1639	Eval_AUC: 0.8387
Epoch 38 Global_step 3132000	Train_loss: 0.1633	Eval_AUC: 0.8384
Epoch 38 Global_step 3133000	Train_loss: 0.1651	Eval_AUC: 0.8401
Epoch 38 Global_step 3134000	Train_loss: 0.1638	Eval_AUC: 0.8438
Epoch 38 Global_step 3135000	Train_loss: 0.1666	Eval_AUC: 0.8418
Epoch 38 Global_step 3136000	Train_loss: 0.1619	Eval_AUC: 0.8437
Epoch 38 Global_step 3137000	Train_loss: 0.1668	Eval_AUC: 0.8387
Epoch 38 Global_step 3138000	Train_loss: 0.1672	Eval_AUC: 0.8434
Epoch 38 Global_step 3139000	Train_loss: 0.1662	Eval_AUC: 0.8436
Epoch 38 Global_step 3140000	Train_loss: 0.1640	Eval_AUC: 0.8378
Epoch 38 Global_step 3141000	Train_loss: 0.1641	Eval_AUC: 0.8427
Epoch 38 Global_step 3142000	Train_loss: 0.1647	Eval_AUC: 0.8400
Epoch 38 Global_step 3143000	Train_loss: 0.1676	Eval_AUC: 0.8435
Epoch 38 Global_step 3144000	Train_loss: 0.1659	Eval_AUC: 0.8417
Epoch 38 Global_step 3145000	Train_loss: 0.1658	Eval_AUC: 0.8419
Epoch 38 Global_step 3146000	Train_loss: 0.1656	Eval_AUC: 0.8438
Epoch 38 Global_step 3147000	Train_loss: 0.1679	Eval_AUC: 0.8381
Epoch 38 Global_step 3148000	Train_loss: 0.1697	Eval_AUC: 0.8424
Epoch 38 Global_step 3149000	Train_loss: 0.1683	Eval_AUC: 0.8466
Epoch 38 Global_step 3150000	Train_loss: 0.1667	Eval_AUC: 0.8381
Epoch 38 Global_step 3151000	Train_loss: 0.1688	Eval_AUC: 0.8447
Epoch 38 Global_step 3152000	Train_loss: 0.1690	Eval_AUC: 0.8464
Epoch 38 Global_step 3153000	Train_loss: 0.1687	Eval_AUC: 0.8429
Epoch 38 Global_step 3154000	Train_loss: 0.1703	Eval_AUC: 0.8420
Epoch 38 Global_step 3155000	Train_loss: 0.1675	Eval_AUC: 0.8399
Epoch 38 Global_step 3156000	Train_loss: 0.1702	Eval_AUC: 0.8471
Epoch 38 Global_step 3157000	Train_loss: 0.1699	Eval_AUC: 0.8416
Epoch 38 Global_step 3158000	Train_loss: 0.1710	Eval_AUC: 0.8422
Epoch 38 Global_step 3159000	Train_loss: 0.1696	Eval_AUC: 0.8428
Epoch 38 Global_step 3160000	Train_loss: 0.1740	Eval_AUC: 0.8392
Epoch 38 Global_step 3161000	Train_loss: 0.1701	Eval_AUC: 0.8400
Epoch 38 Global_step 3162000	Train_loss: 0.1687	Eval_AUC: 0.8378
Epoch 38 Global_step 3163000	Train_loss: 0.1717	Eval_AUC: 0.8428
Epoch 38 Global_step 3164000	Train_loss: 0.1710	Eval_AUC: 0.8396
Epoch 38 Global_step 3165000	Train_loss: 0.1686	Eval_AUC: 0.8462
Epoch 38 Global_step 3166000	Train_loss: 0.1734	Eval_AUC: 0.8397
Epoch 38 Global_step 3167000	Train_loss: 0.1715	Eval_AUC: 0.8404
Epoch 38 Global_step 3168000	Train_loss: 0.1737	Eval_AUC: 0.8437
Epoch 38 Global_step 3169000	Train_loss: 0.1738	Eval_AUC: 0.8433
Epoch 38 Global_step 3170000	Train_loss: 0.1777	Eval_AUC: 0.8431
Epoch 38 Global_step 3171000	Train_loss: 0.1743	Eval_AUC: 0.8415
Epoch 38 Global_step 3172000	Train_loss: 0.1751	Eval_AUC: 0.8444
Epoch 38 Global_step 3173000	Train_loss: 0.1744	Eval_AUC: 0.8397
Epoch 38 Global_step 3174000	Train_loss: 0.1728	Eval_AUC: 0.8460
Epoch 38 Global_step 3175000	Train_loss: 0.1734	Eval_AUC: 0.8372
Epoch 38 Global_step 3176000	Train_loss: 0.1720	Eval_AUC: 0.8420
Epoch 38 Global_step 3177000	Train_loss: 0.1749	Eval_AUC: 0.8367
Epoch 38 Global_step 3178000	Train_loss: 0.1764	Eval_AUC: 0.8409
Epoch 38 Global_step 3179000	Train_loss: 0.1751	Eval_AUC: 0.8420
Epoch 38 DONE	Cost time: 298590.48
Epoch 39 Global_step 3180000	Train_loss: 0.1627	Eval_AUC: 0.8410
Epoch 39 Global_step 3181000	Train_loss: 0.1519	Eval_AUC: 0.8360
Epoch 39 Global_step 3182000	Train_loss: 0.1503	Eval_AUC: 0.8408
Epoch 39 Global_step 3183000	Train_loss: 0.1489	Eval_AUC: 0.8425
Epoch 39 Global_step 3184000	Train_loss: 0.1497	Eval_AUC: 0.8405
Epoch 39 Global_step 3185000	Train_loss: 0.1515	Eval_AUC: 0.8418
Epoch 39 Global_step 3186000	Train_loss: 0.1520	Eval_AUC: 0.8393
Epoch 39 Global_step 3187000	Train_loss: 0.1529	Eval_AUC: 0.8406
Epoch 39 Global_step 3188000	Train_loss: 0.1524	Eval_AUC: 0.8438
Epoch 39 Global_step 3189000	Train_loss: 0.1540	Eval_AUC: 0.8403
Epoch 39 Global_step 3190000	Train_loss: 0.1546	Eval_AUC: 0.8427
Epoch 39 Global_step 3191000	Train_loss: 0.1564	Eval_AUC: 0.8430
Epoch 39 Global_step 3192000	Train_loss: 0.1545	Eval_AUC: 0.8356
Epoch 39 Global_step 3193000	Train_loss: 0.1542	Eval_AUC: 0.8407
Epoch 39 Global_step 3194000	Train_loss: 0.1560	Eval_AUC: 0.8392
Epoch 39 Global_step 3195000	Train_loss: 0.1541	Eval_AUC: 0.8407
Epoch 39 Global_step 3196000	Train_loss: 0.1582	Eval_AUC: 0.8370
Epoch 39 Global_step 3197000	Train_loss: 0.1562	Eval_AUC: 0.8440
Epoch 39 Global_step 3198000	Train_loss: 0.1586	Eval_AUC: 0.8392
Epoch 39 Global_step 3199000	Train_loss: 0.1605	Eval_AUC: 0.8390
Epoch 39 Global_step 3200000	Train_loss: 0.1556	Eval_AUC: 0.8428
Epoch 39 Global_step 3201000	Train_loss: 0.1543	Eval_AUC: 0.8378
Epoch 39 Global_step 3202000	Train_loss: 0.1595	Eval_AUC: 0.8346
Epoch 39 Global_step 3203000	Train_loss: 0.1600	Eval_AUC: 0.8416
Epoch 39 Global_step 3204000	Train_loss: 0.1608	Eval_AUC: 0.8412
Epoch 39 Global_step 3205000	Train_loss: 0.1579	Eval_AUC: 0.8427
Epoch 39 Global_step 3206000	Train_loss: 0.1549	Eval_AUC: 0.8387
Epoch 39 Global_step 3207000	Train_loss: 0.1573	Eval_AUC: 0.8416
Epoch 39 Global_step 3208000	Train_loss: 0.1619	Eval_AUC: 0.8408
Epoch 39 Global_step 3209000	Train_loss: 0.1601	Eval_AUC: 0.8408
Epoch 39 Global_step 3210000	Train_loss: 0.1598	Eval_AUC: 0.8407
Epoch 39 Global_step 3211000	Train_loss: 0.1594	Eval_AUC: 0.8385
Epoch 39 Global_step 3212000	Train_loss: 0.1583	Eval_AUC: 0.8403
Epoch 39 Global_step 3213000	Train_loss: 0.1600	Eval_AUC: 0.8431
Epoch 39 Global_step 3214000	Train_loss: 0.1600	Eval_AUC: 0.8430
Epoch 39 Global_step 3215000	Train_loss: 0.1616	Eval_AUC: 0.8380
Epoch 39 Global_step 3216000	Train_loss: 0.1639	Eval_AUC: 0.8383
Epoch 39 Global_step 3217000	Train_loss: 0.1616	Eval_AUC: 0.8398
Epoch 39 Global_step 3218000	Train_loss: 0.1641	Eval_AUC: 0.8361
Epoch 39 Global_step 3219000	Train_loss: 0.1629	Eval_AUC: 0.8396
Epoch 39 Global_step 3220000	Train_loss: 0.1628	Eval_AUC: 0.8374
Epoch 39 Global_step 3221000	Train_loss: 0.1606	Eval_AUC: 0.8448
Epoch 39 Global_step 3222000	Train_loss: 0.1627	Eval_AUC: 0.8427
Epoch 39 Global_step 3223000	Train_loss: 0.1636	Eval_AUC: 0.8396
Epoch 39 Global_step 3224000	Train_loss: 0.1637	Eval_AUC: 0.8434
Epoch 39 Global_step 3225000	Train_loss: 0.1641	Eval_AUC: 0.8435
Epoch 39 Global_step 3226000	Train_loss: 0.1651	Eval_AUC: 0.8434
Epoch 39 Global_step 3227000	Train_loss: 0.1663	Eval_AUC: 0.8349
Epoch 39 Global_step 3228000	Train_loss: 0.1651	Eval_AUC: 0.8396
Epoch 39 Global_step 3229000	Train_loss: 0.1659	Eval_AUC: 0.8419
Epoch 39 Global_step 3230000	Train_loss: 0.1670	Eval_AUC: 0.8358
Epoch 39 Global_step 3231000	Train_loss: 0.1637	Eval_AUC: 0.8397
Epoch 39 Global_step 3232000	Train_loss: 0.1642	Eval_AUC: 0.8438
Epoch 39 Global_step 3233000	Train_loss: 0.1654	Eval_AUC: 0.8396
Epoch 39 Global_step 3234000	Train_loss: 0.1631	Eval_AUC: 0.8392
Epoch 39 Global_step 3235000	Train_loss: 0.1647	Eval_AUC: 0.8428
Epoch 39 Global_step 3236000	Train_loss: 0.1664	Eval_AUC: 0.8417
Epoch 39 Global_step 3237000	Train_loss: 0.1652	Eval_AUC: 0.8404
Epoch 39 Global_step 3238000	Train_loss: 0.1683	Eval_AUC: 0.8402
Epoch 39 Global_step 3239000	Train_loss: 0.1664	Eval_AUC: 0.8414
Epoch 39 Global_step 3240000	Train_loss: 0.1677	Eval_AUC: 0.8438
Epoch 39 Global_step 3241000	Train_loss: 0.1682	Eval_AUC: 0.8443
Epoch 39 Global_step 3242000	Train_loss: 0.1676	Eval_AUC: 0.8399
Epoch 39 Global_step 3243000	Train_loss: 0.1701	Eval_AUC: 0.8404
Epoch 39 Global_step 3244000	Train_loss: 0.1698	Eval_AUC: 0.8388
Epoch 39 Global_step 3245000	Train_loss: 0.1667	Eval_AUC: 0.8438
Epoch 39 Global_step 3246000	Train_loss: 0.1663	Eval_AUC: 0.8473
Epoch 39 Global_step 3247000	Train_loss: 0.1673	Eval_AUC: 0.8446
Epoch 39 Global_step 3248000	Train_loss: 0.1686	Eval_AUC: 0.8373
Epoch 39 Global_step 3249000	Train_loss: 0.1697	Eval_AUC: 0.8423
Epoch 39 Global_step 3250000	Train_loss: 0.1696	Eval_AUC: 0.8421
Epoch 39 Global_step 3251000	Train_loss: 0.1695	Eval_AUC: 0.8433
Epoch 39 Global_step 3252000	Train_loss: 0.1706	Eval_AUC: 0.8426
Epoch 39 Global_step 3253000	Train_loss: 0.1710	Eval_AUC: 0.8391
Epoch 39 Global_step 3254000	Train_loss: 0.1697	Eval_AUC: 0.8430
Epoch 39 Global_step 3255000	Train_loss: 0.1710	Eval_AUC: 0.8440
Epoch 39 Global_step 3256000	Train_loss: 0.1715	Eval_AUC: 0.8396
Epoch 39 Global_step 3257000	Train_loss: 0.1694	Eval_AUC: 0.8409
Epoch 39 Global_step 3258000	Train_loss: 0.1686	Eval_AUC: 0.8440
Epoch 39 Global_step 3259000	Train_loss: 0.1687	Eval_AUC: 0.8392
Epoch 39 Global_step 3260000	Train_loss: 0.1708	Eval_AUC: 0.8443
Epoch 39 DONE	Cost time: 305755.44
Epoch 40 Global_step 3261000	Train_loss: 0.1698	Eval_AUC: 0.8424
Epoch 40 Global_step 3262000	Train_loss: 0.1487	Eval_AUC: 0.8378
Epoch 40 Global_step 3263000	Train_loss: 0.1472	Eval_AUC: 0.8355
Epoch 40 Global_step 3264000	Train_loss: 0.1494	Eval_AUC: 0.8369
Epoch 40 Global_step 3265000	Train_loss: 0.1481	Eval_AUC: 0.8375
Epoch 40 Global_step 3266000	Train_loss: 0.1486	Eval_AUC: 0.8400
Epoch 40 Global_step 3267000	Train_loss: 0.1487	Eval_AUC: 0.8415
Epoch 40 Global_step 3268000	Train_loss: 0.1510	Eval_AUC: 0.8417
Epoch 40 Global_step 3269000	Train_loss: 0.1503	Eval_AUC: 0.8366
Epoch 40 Global_step 3270000	Train_loss: 0.1522	Eval_AUC: 0.8391
Epoch 40 Global_step 3271000	Train_loss: 0.1509	Eval_AUC: 0.8370
Epoch 40 Global_step 3272000	Train_loss: 0.1494	Eval_AUC: 0.8386
Epoch 40 Global_step 3273000	Train_loss: 0.1522	Eval_AUC: 0.8373
Epoch 40 Global_step 3274000	Train_loss: 0.1525	Eval_AUC: 0.8405
Epoch 40 Global_step 3275000	Train_loss: 0.1544	Eval_AUC: 0.8367
Epoch 40 Global_step 3276000	Train_loss: 0.1520	Eval_AUC: 0.8361
Epoch 40 Global_step 3277000	Train_loss: 0.1516	Eval_AUC: 0.8402
Epoch 40 Global_step 3278000	Train_loss: 0.1525	Eval_AUC: 0.8412
Epoch 40 Global_step 3279000	Train_loss: 0.1536	Eval_AUC: 0.8404
Epoch 40 Global_step 3280000	Train_loss: 0.1529	Eval_AUC: 0.8371
Epoch 40 Global_step 3281000	Train_loss: 0.1542	Eval_AUC: 0.8339
Epoch 40 Global_step 3282000	Train_loss: 0.1556	Eval_AUC: 0.8415
Epoch 40 Global_step 3283000	Train_loss: 0.1540	Eval_AUC: 0.8429
Epoch 40 Global_step 3284000	Train_loss: 0.1551	Eval_AUC: 0.8390
Epoch 40 Global_step 3285000	Train_loss: 0.1527	Eval_AUC: 0.8361
Epoch 40 Global_step 3286000	Train_loss: 0.1553	Eval_AUC: 0.8399
Epoch 40 Global_step 3287000	Train_loss: 0.1552	Eval_AUC: 0.8351
Epoch 40 Global_step 3288000	Train_loss: 0.1563	Eval_AUC: 0.8357
Epoch 40 Global_step 3289000	Train_loss: 0.1559	Eval_AUC: 0.8397
Epoch 40 Global_step 3290000	Train_loss: 0.1568	Eval_AUC: 0.8396
Epoch 40 Global_step 3291000	Train_loss: 0.1535	Eval_AUC: 0.8403
Epoch 40 Global_step 3292000	Train_loss: 0.1569	Eval_AUC: 0.8409
Epoch 40 Global_step 3293000	Train_loss: 0.1586	Eval_AUC: 0.8371
Epoch 40 Global_step 3294000	Train_loss: 0.1599	Eval_AUC: 0.8392
Epoch 40 Global_step 3295000	Train_loss: 0.1560	Eval_AUC: 0.8436
Epoch 40 Global_step 3296000	Train_loss: 0.1571	Eval_AUC: 0.8341
Epoch 40 Global_step 3297000	Train_loss: 0.1578	Eval_AUC: 0.8349
Epoch 40 Global_step 3298000	Train_loss: 0.1585	Eval_AUC: 0.8393
Epoch 40 Global_step 3299000	Train_loss: 0.1573	Eval_AUC: 0.8386
Epoch 40 Global_step 3300000	Train_loss: 0.1569	Eval_AUC: 0.8391
Epoch 40 Global_step 3301000	Train_loss: 0.1605	Eval_AUC: 0.8403
Epoch 40 Global_step 3302000	Train_loss: 0.1581	Eval_AUC: 0.8414
Epoch 40 Global_step 3303000	Train_loss: 0.1628	Eval_AUC: 0.8327
Epoch 40 Global_step 3304000	Train_loss: 0.1588	Eval_AUC: 0.8398
Epoch 40 Global_step 3305000	Train_loss: 0.1631	Eval_AUC: 0.8353
Epoch 40 Global_step 3306000	Train_loss: 0.1609	Eval_AUC: 0.8389
Epoch 40 Global_step 3307000	Train_loss: 0.1604	Eval_AUC: 0.8373
Epoch 40 Global_step 3308000	Train_loss: 0.1608	Eval_AUC: 0.8398
Epoch 40 Global_step 3309000	Train_loss: 0.1597	Eval_AUC: 0.8433
Epoch 40 Global_step 3310000	Train_loss: 0.1617	Eval_AUC: 0.8403
Epoch 40 Global_step 3311000	Train_loss: 0.1621	Eval_AUC: 0.8399
Epoch 40 Global_step 3312000	Train_loss: 0.1595	Eval_AUC: 0.8399
Epoch 40 Global_step 3313000	Train_loss: 0.1620	Eval_AUC: 0.8427
Epoch 40 Global_step 3314000	Train_loss: 0.1612	Eval_AUC: 0.8349
Epoch 40 Global_step 3315000	Train_loss: 0.1613	Eval_AUC: 0.8415
Epoch 40 Global_step 3316000	Train_loss: 0.1624	Eval_AUC: 0.8344
Epoch 40 Global_step 3317000	Train_loss: 0.1621	Eval_AUC: 0.8373
Epoch 40 Global_step 3318000	Train_loss: 0.1645	Eval_AUC: 0.8399
Epoch 40 Global_step 3319000	Train_loss: 0.1643	Eval_AUC: 0.8405
Epoch 40 Global_step 3320000	Train_loss: 0.1643	Eval_AUC: 0.8417
Epoch 40 Global_step 3321000	Train_loss: 0.1624	Eval_AUC: 0.8398
Epoch 40 Global_step 3322000	Train_loss: 0.1624	Eval_AUC: 0.8404
Epoch 40 Global_step 3323000	Train_loss: 0.1636	Eval_AUC: 0.8432
Epoch 40 Global_step 3324000	Train_loss: 0.1650	Eval_AUC: 0.8414
Epoch 40 Global_step 3325000	Train_loss: 0.1650	Eval_AUC: 0.8397
Epoch 40 Global_step 3326000	Train_loss: 0.1665	Eval_AUC: 0.8442
Epoch 40 Global_step 3327000	Train_loss: 0.1631	Eval_AUC: 0.8388
Epoch 40 Global_step 3328000	Train_loss: 0.1651	Eval_AUC: 0.8387
Epoch 40 Global_step 3329000	Train_loss: 0.1661	Eval_AUC: 0.8362
Epoch 40 Global_step 3330000	Train_loss: 0.1650	Eval_AUC: 0.8428
Epoch 40 Global_step 3331000	Train_loss: 0.1679	Eval_AUC: 0.8401
Epoch 40 Global_step 3332000	Train_loss: 0.1650	Eval_AUC: 0.8395
Epoch 40 Global_step 3333000	Train_loss: 0.1633	Eval_AUC: 0.8388
Epoch 40 Global_step 3334000	Train_loss: 0.1679	Eval_AUC: 0.8367
Epoch 40 Global_step 3335000	Train_loss: 0.1668	Eval_AUC: 0.8373
Epoch 40 Global_step 3336000	Train_loss: 0.1685	Eval_AUC: 0.8398
Epoch 40 Global_step 3337000	Train_loss: 0.1685	Eval_AUC: 0.8368
Epoch 40 Global_step 3338000	Train_loss: 0.1658	Eval_AUC: 0.8426
Epoch 40 Global_step 3339000	Train_loss: 0.1697	Eval_AUC: 0.8391
Epoch 40 Global_step 3340000	Train_loss: 0.1679	Eval_AUC: 0.8380
Epoch 40 Global_step 3341000	Train_loss: 0.1703	Eval_AUC: 0.8412
Epoch 40 Global_step 3342000	Train_loss: 0.1720	Eval_AUC: 0.8383
Epoch 40 DONE	Cost time: 312972.71
Epoch 41 Global_step 3343000	Train_loss: 0.1566	Eval_AUC: 0.8442
Epoch 41 Global_step 3344000	Train_loss: 0.1464	Eval_AUC: 0.8390
Epoch 41 Global_step 3345000	Train_loss: 0.1467	Eval_AUC: 0.8421
Epoch 41 Global_step 3346000	Train_loss: 0.1448	Eval_AUC: 0.8392
Epoch 41 Global_step 3347000	Train_loss: 0.1452	Eval_AUC: 0.8435
Epoch 41 Global_step 3348000	Train_loss: 0.1459	Eval_AUC: 0.8380
Epoch 41 Global_step 3349000	Train_loss: 0.1473	Eval_AUC: 0.8413
Epoch 41 Global_step 3350000	Train_loss: 0.1459	Eval_AUC: 0.8384
Epoch 41 Global_step 3351000	Train_loss: 0.1477	Eval_AUC: 0.8345
Epoch 41 Global_step 3352000	Train_loss: 0.1456	Eval_AUC: 0.8362
Epoch 41 Global_step 3353000	Train_loss: 0.1477	Eval_AUC: 0.8397
Epoch 41 Global_step 3354000	Train_loss: 0.1484	Eval_AUC: 0.8379
Epoch 41 Global_step 3355000	Train_loss: 0.1487	Eval_AUC: 0.8374
Epoch 41 Global_step 3356000	Train_loss: 0.1490	Eval_AUC: 0.8384
Epoch 41 Global_step 3357000	Train_loss: 0.1494	Eval_AUC: 0.8390
Epoch 41 Global_step 3358000	Train_loss: 0.1498	Eval_AUC: 0.8377
Epoch 41 Global_step 3359000	Train_loss: 0.1513	Eval_AUC: 0.8366
Epoch 41 Global_step 3360000	Train_loss: 0.1496	Eval_AUC: 0.8417
Epoch 41 Global_step 3361000	Train_loss: 0.1505	Eval_AUC: 0.8360
Epoch 41 Global_step 3362000	Train_loss: 0.1499	Eval_AUC: 0.8408
Epoch 41 Global_step 3363000	Train_loss: 0.1497	Eval_AUC: 0.8369
Epoch 41 Global_step 3364000	Train_loss: 0.1507	Eval_AUC: 0.8356
Epoch 41 Global_step 3365000	Train_loss: 0.1526	Eval_AUC: 0.8351
Epoch 41 Global_step 3366000	Train_loss: 0.1500	Eval_AUC: 0.8373
Epoch 41 Global_step 3367000	Train_loss: 0.1533	Eval_AUC: 0.8433
Epoch 41 Global_step 3368000	Train_loss: 0.1507	Eval_AUC: 0.8372
Epoch 41 Global_step 3369000	Train_loss: 0.1521	Eval_AUC: 0.8386
Epoch 41 Global_step 3370000	Train_loss: 0.1508	Eval_AUC: 0.8396
Epoch 41 Global_step 3371000	Train_loss: 0.1519	Eval_AUC: 0.8374
Epoch 41 Global_step 3372000	Train_loss: 0.1536	Eval_AUC: 0.8340
Epoch 41 Global_step 3373000	Train_loss: 0.1567	Eval_AUC: 0.8383
Epoch 41 Global_step 3374000	Train_loss: 0.1563	Eval_AUC: 0.8378
Epoch 41 Global_step 3375000	Train_loss: 0.1561	Eval_AUC: 0.8413
Epoch 41 Global_step 3376000	Train_loss: 0.1521	Eval_AUC: 0.8372
Epoch 41 Global_step 3377000	Train_loss: 0.1537	Eval_AUC: 0.8394
Epoch 41 Global_step 3378000	Train_loss: 0.1550	Eval_AUC: 0.8402
Epoch 41 Global_step 3379000	Train_loss: 0.1550	Eval_AUC: 0.8372
Epoch 41 Global_step 3380000	Train_loss: 0.1546	Eval_AUC: 0.8407
Epoch 41 Global_step 3381000	Train_loss: 0.1538	Eval_AUC: 0.8377
Epoch 41 Global_step 3382000	Train_loss: 0.1568	Eval_AUC: 0.8348
Epoch 41 Global_step 3383000	Train_loss: 0.1561	Eval_AUC: 0.8418
Epoch 41 Global_step 3384000	Train_loss: 0.1559	Eval_AUC: 0.8388
Epoch 41 Global_step 3385000	Train_loss: 0.1599	Eval_AUC: 0.8392
Epoch 41 Global_step 3386000	Train_loss: 0.1580	Eval_AUC: 0.8340
Epoch 41 Global_step 3387000	Train_loss: 0.1554	Eval_AUC: 0.8389
Epoch 41 Global_step 3388000	Train_loss: 0.1595	Eval_AUC: 0.8390
Epoch 41 Global_step 3389000	Train_loss: 0.1585	Eval_AUC: 0.8382
Epoch 41 Global_step 3390000	Train_loss: 0.1610	Eval_AUC: 0.8367
Epoch 41 Global_step 3391000	Train_loss: 0.1596	Eval_AUC: 0.8334
Epoch 41 Global_step 3392000	Train_loss: 0.1586	Eval_AUC: 0.8359
Epoch 41 Global_step 3393000	Train_loss: 0.1595	Eval_AUC: 0.8396
Epoch 41 Global_step 3394000	Train_loss: 0.1592	Eval_AUC: 0.8377
Epoch 41 Global_step 3395000	Train_loss: 0.1610	Eval_AUC: 0.8350
Epoch 41 Global_step 3396000	Train_loss: 0.1580	Eval_AUC: 0.8422
Epoch 41 Global_step 3397000	Train_loss: 0.1589	Eval_AUC: 0.8371
Epoch 41 Global_step 3398000	Train_loss: 0.1600	Eval_AUC: 0.8387
Epoch 41 Global_step 3399000	Train_loss: 0.1595	Eval_AUC: 0.8402
Epoch 41 Global_step 3400000	Train_loss: 0.1577	Eval_AUC: 0.8409
Epoch 41 Global_step 3401000	Train_loss: 0.1590	Eval_AUC: 0.8382
Epoch 41 Global_step 3402000	Train_loss: 0.1591	Eval_AUC: 0.8411
Epoch 41 Global_step 3403000	Train_loss: 0.1621	Eval_AUC: 0.8380
Epoch 41 Global_step 3404000	Train_loss: 0.1635	Eval_AUC: 0.8414
Epoch 41 Global_step 3405000	Train_loss: 0.1625	Eval_AUC: 0.8314
Epoch 41 Global_step 3406000	Train_loss: 0.1615	Eval_AUC: 0.8375
Epoch 41 Global_step 3407000	Train_loss: 0.1609	Eval_AUC: 0.8366
Epoch 41 Global_step 3408000	Train_loss: 0.1606	Eval_AUC: 0.8376
Epoch 41 Global_step 3409000	Train_loss: 0.1609	Eval_AUC: 0.8391
Epoch 41 Global_step 3410000	Train_loss: 0.1618	Eval_AUC: 0.8358
Epoch 41 Global_step 3411000	Train_loss: 0.1640	Eval_AUC: 0.8383
Epoch 41 Global_step 3412000	Train_loss: 0.1610	Eval_AUC: 0.8381
Epoch 41 Global_step 3413000	Train_loss: 0.1631	Eval_AUC: 0.8436
Epoch 41 Global_step 3414000	Train_loss: 0.1619	Eval_AUC: 0.8419
Epoch 41 Global_step 3415000	Train_loss: 0.1618	Eval_AUC: 0.8371
Epoch 41 Global_step 3416000	Train_loss: 0.1654	Eval_AUC: 0.8431
Epoch 41 Global_step 3417000	Train_loss: 0.1650	Eval_AUC: 0.8384
Epoch 41 Global_step 3418000	Train_loss: 0.1634	Eval_AUC: 0.8408
Epoch 41 Global_step 3419000	Train_loss: 0.1641	Eval_AUC: 0.8401
Epoch 41 Global_step 3420000	Train_loss: 0.1656	Eval_AUC: 0.8418
Epoch 41 Global_step 3421000	Train_loss: 0.1669	Eval_AUC: 0.8395
Epoch 41 Global_step 3422000	Train_loss: 0.1668	Eval_AUC: 0.8420
Epoch 41 Global_step 3423000	Train_loss: 0.1635	Eval_AUC: 0.8420
Epoch 41 Global_step 3424000	Train_loss: 0.1639	Eval_AUC: 0.8397
Epoch 41 DONE	Cost time: 320198.68
Epoch 42 Global_step 3425000	Train_loss: 0.1425	Eval_AUC: 0.8409
Epoch 42 Global_step 3426000	Train_loss: 0.1423	Eval_AUC: 0.8348
Epoch 42 Global_step 3427000	Train_loss: 0.1436	Eval_AUC: 0.8360
Epoch 42 Global_step 3428000	Train_loss: 0.1437	Eval_AUC: 0.8355
Epoch 42 Global_step 3429000	Train_loss: 0.1455	Eval_AUC: 0.8384
Epoch 42 Global_step 3430000	Train_loss: 0.1460	Eval_AUC: 0.8381
Epoch 42 Global_step 3431000	Train_loss: 0.1442	Eval_AUC: 0.8375
Epoch 42 Global_step 3432000	Train_loss: 0.1452	Eval_AUC: 0.8359
Epoch 42 Global_step 3433000	Train_loss: 0.1452	Eval_AUC: 0.8367
Epoch 42 Global_step 3434000	Train_loss: 0.1453	Eval_AUC: 0.8377
Epoch 42 Global_step 3435000	Train_loss: 0.1445	Eval_AUC: 0.8373
Epoch 42 Global_step 3436000	Train_loss: 0.1484	Eval_AUC: 0.8376
Epoch 42 Global_step 3437000	Train_loss: 0.1458	Eval_AUC: 0.8344
Epoch 42 Global_step 3438000	Train_loss: 0.1470	Eval_AUC: 0.8373
Epoch 42 Global_step 3439000	Train_loss: 0.1461	Eval_AUC: 0.8357
Epoch 42 Global_step 3440000	Train_loss: 0.1460	Eval_AUC: 0.8354
Epoch 42 Global_step 3441000	Train_loss: 0.1487	Eval_AUC: 0.8388
Epoch 42 Global_step 3442000	Train_loss: 0.1484	Eval_AUC: 0.8371
Epoch 42 Global_step 3443000	Train_loss: 0.1489	Eval_AUC: 0.8372
Epoch 42 Global_step 3444000	Train_loss: 0.1476	Eval_AUC: 0.8345
Epoch 42 Global_step 3445000	Train_loss: 0.1472	Eval_AUC: 0.8371
Epoch 42 Global_step 3446000	Train_loss: 0.1492	Eval_AUC: 0.8377
Epoch 42 Global_step 3447000	Train_loss: 0.1502	Eval_AUC: 0.8387
Epoch 42 Global_step 3448000	Train_loss: 0.1484	Eval_AUC: 0.8365
Epoch 42 Global_step 3449000	Train_loss: 0.1506	Eval_AUC: 0.8371
Epoch 42 Global_step 3450000	Train_loss: 0.1491	Eval_AUC: 0.8365
Epoch 42 Global_step 3451000	Train_loss: 0.1504	Eval_AUC: 0.8338
Epoch 42 Global_step 3452000	Train_loss: 0.1489	Eval_AUC: 0.8382
Epoch 42 Global_step 3453000	Train_loss: 0.1518	Eval_AUC: 0.8372
Epoch 42 Global_step 3454000	Train_loss: 0.1504	Eval_AUC: 0.8358
Epoch 42 Global_step 3455000	Train_loss: 0.1536	Eval_AUC: 0.8378
Epoch 42 Global_step 3456000	Train_loss: 0.1532	Eval_AUC: 0.8420
Epoch 42 Global_step 3457000	Train_loss: 0.1506	Eval_AUC: 0.8355
Epoch 42 Global_step 3458000	Train_loss: 0.1532	Eval_AUC: 0.8413
Epoch 42 Global_step 3459000	Train_loss: 0.1489	Eval_AUC: 0.8332
Epoch 42 Global_step 3460000	Train_loss: 0.1523	Eval_AUC: 0.8367
Epoch 42 Global_step 3461000	Train_loss: 0.1537	Eval_AUC: 0.8381
Epoch 42 Global_step 3462000	Train_loss: 0.1528	Eval_AUC: 0.8395
Epoch 42 Global_step 3463000	Train_loss: 0.1504	Eval_AUC: 0.8364
Epoch 42 Global_step 3464000	Train_loss: 0.1532	Eval_AUC: 0.8373
Epoch 42 Global_step 3465000	Train_loss: 0.1533	Eval_AUC: 0.8412
Epoch 42 Global_step 3466000	Train_loss: 0.1549	Eval_AUC: 0.8381
Epoch 42 Global_step 3467000	Train_loss: 0.1546	Eval_AUC: 0.8377
Epoch 42 Global_step 3468000	Train_loss: 0.1553	Eval_AUC: 0.8369
Epoch 42 Global_step 3469000	Train_loss: 0.1552	Eval_AUC: 0.8391
Epoch 42 Global_step 3470000	Train_loss: 0.1532	Eval_AUC: 0.8326
Epoch 42 Global_step 3471000	Train_loss: 0.1546	Eval_AUC: 0.8375
Epoch 42 Global_step 3472000	Train_loss: 0.1571	Eval_AUC: 0.8372
Epoch 42 Global_step 3473000	Train_loss: 0.1546	Eval_AUC: 0.8345
Epoch 42 Global_step 3474000	Train_loss: 0.1555	Eval_AUC: 0.8396
Epoch 42 Global_step 3475000	Train_loss: 0.1560	Eval_AUC: 0.8410
Epoch 42 Global_step 3476000	Train_loss: 0.1562	Eval_AUC: 0.8349
Epoch 42 Global_step 3477000	Train_loss: 0.1538	Eval_AUC: 0.8411
Epoch 42 Global_step 3478000	Train_loss: 0.1535	Eval_AUC: 0.8388
Epoch 42 Global_step 3479000	Train_loss: 0.1561	Eval_AUC: 0.8388
Epoch 42 Global_step 3480000	Train_loss: 0.1586	Eval_AUC: 0.8345
Epoch 42 Global_step 3481000	Train_loss: 0.1579	Eval_AUC: 0.8324
Epoch 42 Global_step 3482000	Train_loss: 0.1556	Eval_AUC: 0.8342
Epoch 42 Global_step 3483000	Train_loss: 0.1569	Eval_AUC: 0.8371
Epoch 42 Global_step 3484000	Train_loss: 0.1580	Eval_AUC: 0.8363
Epoch 42 Global_step 3485000	Train_loss: 0.1550	Eval_AUC: 0.8346
Epoch 42 Global_step 3486000	Train_loss: 0.1593	Eval_AUC: 0.8327
Epoch 42 Global_step 3487000	Train_loss: 0.1558	Eval_AUC: 0.8399
Epoch 42 Global_step 3488000	Train_loss: 0.1596	Eval_AUC: 0.8385
Epoch 42 Global_step 3489000	Train_loss: 0.1622	Eval_AUC: 0.8397
Epoch 42 Global_step 3490000	Train_loss: 0.1583	Eval_AUC: 0.8348
Epoch 42 Global_step 3491000	Train_loss: 0.1590	Eval_AUC: 0.8380
Epoch 42 Global_step 3492000	Train_loss: 0.1609	Eval_AUC: 0.8361
Epoch 42 Global_step 3493000	Train_loss: 0.1590	Eval_AUC: 0.8334
Epoch 42 Global_step 3494000	Train_loss: 0.1612	Eval_AUC: 0.8347
Epoch 42 Global_step 3495000	Train_loss: 0.1607	Eval_AUC: 0.8361
Epoch 42 Global_step 3496000	Train_loss: 0.1594	Eval_AUC: 0.8342
Epoch 42 Global_step 3497000	Train_loss: 0.1593	Eval_AUC: 0.8317
Epoch 42 Global_step 3498000	Train_loss: 0.1613	Eval_AUC: 0.8380
Epoch 42 Global_step 3499000	Train_loss: 0.1620	Eval_AUC: 0.8380
Epoch 42 Global_step 3500000	Train_loss: 0.1616	Eval_AUC: 0.8328
Epoch 42 Global_step 3501000	Train_loss: 0.1632	Eval_AUC: 0.8347
Epoch 42 Global_step 3502000	Train_loss: 0.1608	Eval_AUC: 0.8363
Epoch 42 Global_step 3503000	Train_loss: 0.1626	Eval_AUC: 0.8378
Epoch 42 Global_step 3504000	Train_loss: 0.1623	Eval_AUC: 0.8374
Epoch 42 Global_step 3505000	Train_loss: 0.1625	Eval_AUC: 0.8395
Epoch 42 DONE	Cost time: 327374.52
Epoch 43 Global_step 3506000	Train_loss: 0.1532	Eval_AUC: 0.8368
Epoch 43 Global_step 3507000	Train_loss: 0.1400	Eval_AUC: 0.8363
Epoch 43 Global_step 3508000	Train_loss: 0.1414	Eval_AUC: 0.8380
Epoch 43 Global_step 3509000	Train_loss: 0.1414	Eval_AUC: 0.8366
Epoch 43 Global_step 3510000	Train_loss: 0.1400	Eval_AUC: 0.8356
Epoch 43 Global_step 3511000	Train_loss: 0.1404	Eval_AUC: 0.8390
Epoch 43 Global_step 3512000	Train_loss: 0.1441	Eval_AUC: 0.8368
Epoch 43 Global_step 3513000	Train_loss: 0.1432	Eval_AUC: 0.8382
Epoch 43 Global_step 3514000	Train_loss: 0.1432	Eval_AUC: 0.8317
Epoch 43 Global_step 3515000	Train_loss: 0.1422	Eval_AUC: 0.8348
Epoch 43 Global_step 3516000	Train_loss: 0.1431	Eval_AUC: 0.8382
Epoch 43 Global_step 3517000	Train_loss: 0.1394	Eval_AUC: 0.8387
Epoch 43 Global_step 3518000	Train_loss: 0.1432	Eval_AUC: 0.8350
Epoch 43 Global_step 3519000	Train_loss: 0.1427	Eval_AUC: 0.8351
Epoch 43 Global_step 3520000	Train_loss: 0.1435	Eval_AUC: 0.8378
Epoch 43 Global_step 3521000	Train_loss: 0.1422	Eval_AUC: 0.8389
Epoch 43 Global_step 3522000	Train_loss: 0.1451	Eval_AUC: 0.8340
Epoch 43 Global_step 3523000	Train_loss: 0.1452	Eval_AUC: 0.8347
Epoch 43 Global_step 3524000	Train_loss: 0.1454	Eval_AUC: 0.8399
Epoch 43 Global_step 3525000	Train_loss: 0.1454	Eval_AUC: 0.8354
Epoch 43 Global_step 3526000	Train_loss: 0.1446	Eval_AUC: 0.8364
Epoch 43 Global_step 3527000	Train_loss: 0.1472	Eval_AUC: 0.8384
Epoch 43 Global_step 3528000	Train_loss: 0.1482	Eval_AUC: 0.8338
Epoch 43 Global_step 3529000	Train_loss: 0.1451	Eval_AUC: 0.8372
Epoch 43 Global_step 3530000	Train_loss: 0.1472	Eval_AUC: 0.8358
Epoch 43 Global_step 3531000	Train_loss: 0.1459	Eval_AUC: 0.8386
Epoch 43 Global_step 3532000	Train_loss: 0.1478	Eval_AUC: 0.8417
Epoch 43 Global_step 3533000	Train_loss: 0.1484	Eval_AUC: 0.8369
Epoch 43 Global_step 3534000	Train_loss: 0.1485	Eval_AUC: 0.8367
Epoch 43 Global_step 3535000	Train_loss: 0.1471	Eval_AUC: 0.8389
Epoch 43 Global_step 3536000	Train_loss: 0.1492	Eval_AUC: 0.8368
Epoch 43 Global_step 3537000	Train_loss: 0.1481	Eval_AUC: 0.8361
Epoch 43 Global_step 3538000	Train_loss: 0.1478	Eval_AUC: 0.8380
Epoch 43 Global_step 3539000	Train_loss: 0.1487	Eval_AUC: 0.8335
Epoch 43 Global_step 3540000	Train_loss: 0.1480	Eval_AUC: 0.8401
Epoch 43 Global_step 3541000	Train_loss: 0.1513	Eval_AUC: 0.8339
Epoch 43 Global_step 3542000	Train_loss: 0.1481	Eval_AUC: 0.8342
Epoch 43 Global_step 3543000	Train_loss: 0.1518	Eval_AUC: 0.8367
Epoch 43 Global_step 3544000	Train_loss: 0.1527	Eval_AUC: 0.8363
Epoch 43 Global_step 3545000	Train_loss: 0.1506	Eval_AUC: 0.8354
Epoch 43 Global_step 3546000	Train_loss: 0.1517	Eval_AUC: 0.8393
Epoch 43 Global_step 3547000	Train_loss: 0.1507	Eval_AUC: 0.8325
Epoch 43 Global_step 3548000	Train_loss: 0.1514	Eval_AUC: 0.8362
Epoch 43 Global_step 3549000	Train_loss: 0.1513	Eval_AUC: 0.8393
Epoch 43 Global_step 3550000	Train_loss: 0.1509	Eval_AUC: 0.8386
Epoch 43 Global_step 3551000	Train_loss: 0.1530	Eval_AUC: 0.8396
Epoch 43 Global_step 3552000	Train_loss: 0.1516	Eval_AUC: 0.8390
Epoch 43 Global_step 3553000	Train_loss: 0.1505	Eval_AUC: 0.8404
Epoch 43 Global_step 3554000	Train_loss: 0.1519	Eval_AUC: 0.8373
Epoch 43 Global_step 3555000	Train_loss: 0.1534	Eval_AUC: 0.8377
Epoch 43 Global_step 3556000	Train_loss: 0.1521	Eval_AUC: 0.8390
Epoch 43 Global_step 3557000	Train_loss: 0.1530	Eval_AUC: 0.8390
Epoch 43 Global_step 3558000	Train_loss: 0.1539	Eval_AUC: 0.8367
Epoch 43 Global_step 3559000	Train_loss: 0.1530	Eval_AUC: 0.8383
Epoch 43 Global_step 3560000	Train_loss: 0.1517	Eval_AUC: 0.8374
Epoch 43 Global_step 3561000	Train_loss: 0.1520	Eval_AUC: 0.8370
Epoch 43 Global_step 3562000	Train_loss: 0.1550	Eval_AUC: 0.8369
Epoch 43 Global_step 3563000	Train_loss: 0.1529	Eval_AUC: 0.8339
Epoch 43 Global_step 3564000	Train_loss: 0.1541	Eval_AUC: 0.8356
Epoch 43 Global_step 3565000	Train_loss: 0.1549	Eval_AUC: 0.8332
Epoch 43 Global_step 3566000	Train_loss: 0.1554	Eval_AUC: 0.8389
Epoch 43 Global_step 3567000	Train_loss: 0.1552	Eval_AUC: 0.8373
Epoch 43 Global_step 3568000	Train_loss: 0.1557	Eval_AUC: 0.8406
Epoch 43 Global_step 3569000	Train_loss: 0.1564	Eval_AUC: 0.8409
Epoch 43 Global_step 3570000	Train_loss: 0.1561	Eval_AUC: 0.8362
Epoch 43 Global_step 3571000	Train_loss: 0.1552	Eval_AUC: 0.8331
Epoch 43 Global_step 3572000	Train_loss: 0.1556	Eval_AUC: 0.8381
Epoch 43 Global_step 3573000	Train_loss: 0.1607	Eval_AUC: 0.8346
Epoch 43 Global_step 3574000	Train_loss: 0.1556	Eval_AUC: 0.8379
Epoch 43 Global_step 3575000	Train_loss: 0.1566	Eval_AUC: 0.8321
Epoch 43 Global_step 3576000	Train_loss: 0.1579	Eval_AUC: 0.8394
Epoch 43 Global_step 3577000	Train_loss: 0.1586	Eval_AUC: 0.8410
Epoch 43 Global_step 3578000	Train_loss: 0.1565	Eval_AUC: 0.8390
Epoch 43 Global_step 3579000	Train_loss: 0.1561	Eval_AUC: 0.8405
Epoch 43 Global_step 3580000	Train_loss: 0.1551	Eval_AUC: 0.8379
Epoch 43 Global_step 3581000	Train_loss: 0.1601	Eval_AUC: 0.8383
Epoch 43 Global_step 3582000	Train_loss: 0.1603	Eval_AUC: 0.8399
Epoch 43 Global_step 3583000	Train_loss: 0.1573	Eval_AUC: 0.8387
Epoch 43 Global_step 3584000	Train_loss: 0.1610	Eval_AUC: 0.8378
Epoch 43 Global_step 3585000	Train_loss: 0.1577	Eval_AUC: 0.8365
Epoch 43 Global_step 3586000	Train_loss: 0.1621	Eval_AUC: 0.8357
Epoch 43 Global_step 3587000	Train_loss: 0.1597	Eval_AUC: 0.8344
Epoch 43 DONE	Cost time: 334607.08
Epoch 44 Global_step 3588000	Train_loss: 0.1409	Eval_AUC: 0.8348
Epoch 44 Global_step 3589000	Train_loss: 0.1369	Eval_AUC: 0.8406
Epoch 44 Global_step 3590000	Train_loss: 0.1411	Eval_AUC: 0.8338
Epoch 44 Global_step 3591000	Train_loss: 0.1386	Eval_AUC: 0.8369
Epoch 44 Global_step 3592000	Train_loss: 0.1362	Eval_AUC: 0.8378
Epoch 44 Global_step 3593000	Train_loss: 0.1400	Eval_AUC: 0.8327
Epoch 44 Global_step 3594000	Train_loss: 0.1383	Eval_AUC: 0.8381
Epoch 44 Global_step 3595000	Train_loss: 0.1382	Eval_AUC: 0.8330
Epoch 44 Global_step 3596000	Train_loss: 0.1394	Eval_AUC: 0.8340
Epoch 44 Global_step 3597000	Train_loss: 0.1411	Eval_AUC: 0.8333
Epoch 44 Global_step 3598000	Train_loss: 0.1403	Eval_AUC: 0.8359
Epoch 44 Global_step 3599000	Train_loss: 0.1434	Eval_AUC: 0.8381
Epoch 44 Global_step 3600000	Train_loss: 0.1410	Eval_AUC: 0.8355
Epoch 44 Global_step 3601000	Train_loss: 0.1416	Eval_AUC: 0.8376
Epoch 44 Global_step 3602000	Train_loss: 0.1400	Eval_AUC: 0.8345
Epoch 44 Global_step 3603000	Train_loss: 0.1406	Eval_AUC: 0.8360
Epoch 44 Global_step 3604000	Train_loss: 0.1433	Eval_AUC: 0.8319
Epoch 44 Global_step 3605000	Train_loss: 0.1420	Eval_AUC: 0.8320
Epoch 44 Global_step 3606000	Train_loss: 0.1418	Eval_AUC: 0.8386
Epoch 44 Global_step 3607000	Train_loss: 0.1419	Eval_AUC: 0.8398
Epoch 44 Global_step 3608000	Train_loss: 0.1433	Eval_AUC: 0.8359
Epoch 44 Global_step 3609000	Train_loss: 0.1429	Eval_AUC: 0.8326
Epoch 44 Global_step 3610000	Train_loss: 0.1447	Eval_AUC: 0.8359
Epoch 44 Global_step 3611000	Train_loss: 0.1458	Eval_AUC: 0.8342
Epoch 44 Global_step 3612000	Train_loss: 0.1463	Eval_AUC: 0.8402
Epoch 44 Global_step 3613000	Train_loss: 0.1437	Eval_AUC: 0.8376
Epoch 44 Global_step 3614000	Train_loss: 0.1449	Eval_AUC: 0.8410
Epoch 44 Global_step 3615000	Train_loss: 0.1435	Eval_AUC: 0.8365
Epoch 44 Global_step 3616000	Train_loss: 0.1447	Eval_AUC: 0.8358
Epoch 44 Global_step 3617000	Train_loss: 0.1454	Eval_AUC: 0.8347
Epoch 44 Global_step 3618000	Train_loss: 0.1451	Eval_AUC: 0.8389
Epoch 44 Global_step 3619000	Train_loss: 0.1463	Eval_AUC: 0.8367
Epoch 44 Global_step 3620000	Train_loss: 0.1464	Eval_AUC: 0.8356
Epoch 44 Global_step 3621000	Train_loss: 0.1447	Eval_AUC: 0.8381
Epoch 44 Global_step 3622000	Train_loss: 0.1472	Eval_AUC: 0.8316
Epoch 44 Global_step 3623000	Train_loss: 0.1477	Eval_AUC: 0.8323
Epoch 44 Global_step 3624000	Train_loss: 0.1507	Eval_AUC: 0.8376
Epoch 44 Global_step 3625000	Train_loss: 0.1467	Eval_AUC: 0.8343
Epoch 44 Global_step 3626000	Train_loss: 0.1477	Eval_AUC: 0.8354
Epoch 44 Global_step 3627000	Train_loss: 0.1483	Eval_AUC: 0.8363
Epoch 44 Global_step 3628000	Train_loss: 0.1489	Eval_AUC: 0.8378
Epoch 44 Global_step 3629000	Train_loss: 0.1489	Eval_AUC: 0.8399
Epoch 44 Global_step 3630000	Train_loss: 0.1469	Eval_AUC: 0.8370
Epoch 44 Global_step 3631000	Train_loss: 0.1518	Eval_AUC: 0.8408
Epoch 44 Global_step 3632000	Train_loss: 0.1499	Eval_AUC: 0.8378
Epoch 44 Global_step 3633000	Train_loss: 0.1524	Eval_AUC: 0.8369
Epoch 44 Global_step 3634000	Train_loss: 0.1507	Eval_AUC: 0.8357
Epoch 44 Global_step 3635000	Train_loss: 0.1484	Eval_AUC: 0.8335
Epoch 44 Global_step 3636000	Train_loss: 0.1507	Eval_AUC: 0.8316
Epoch 44 Global_step 3637000	Train_loss: 0.1501	Eval_AUC: 0.8414
Epoch 44 Global_step 3638000	Train_loss: 0.1507	Eval_AUC: 0.8356
Epoch 44 Global_step 3639000	Train_loss: 0.1497	Eval_AUC: 0.8372
Epoch 44 Global_step 3640000	Train_loss: 0.1511	Eval_AUC: 0.8363
Epoch 44 Global_step 3641000	Train_loss: 0.1504	Eval_AUC: 0.8308
Epoch 44 Global_step 3642000	Train_loss: 0.1522	Eval_AUC: 0.8382
Epoch 44 Global_step 3643000	Train_loss: 0.1513	Eval_AUC: 0.8298
Epoch 44 Global_step 3644000	Train_loss: 0.1517	Eval_AUC: 0.8303
Epoch 44 Global_step 3645000	Train_loss: 0.1510	Eval_AUC: 0.8371
Epoch 44 Global_step 3646000	Train_loss: 0.1556	Eval_AUC: 0.8365
Epoch 44 Global_step 3647000	Train_loss: 0.1522	Eval_AUC: 0.8415
Epoch 44 Global_step 3648000	Train_loss: 0.1534	Eval_AUC: 0.8332
Epoch 44 Global_step 3649000	Train_loss: 0.1522	Eval_AUC: 0.8378
Epoch 44 Global_step 3650000	Train_loss: 0.1535	Eval_AUC: 0.8370
Epoch 44 Global_step 3651000	Train_loss: 0.1534	Eval_AUC: 0.8356
Epoch 44 Global_step 3652000	Train_loss: 0.1516	Eval_AUC: 0.8389
Epoch 44 Global_step 3653000	Train_loss: 0.1525	Eval_AUC: 0.8327
Epoch 44 Global_step 3654000	Train_loss: 0.1531	Eval_AUC: 0.8343
Epoch 44 Global_step 3655000	Train_loss: 0.1543	Eval_AUC: 0.8371
Epoch 44 Global_step 3656000	Train_loss: 0.1522	Eval_AUC: 0.8347
Epoch 44 Global_step 3657000	Train_loss: 0.1543	Eval_AUC: 0.8360
Epoch 44 Global_step 3658000	Train_loss: 0.1547	Eval_AUC: 0.8338
Epoch 44 Global_step 3659000	Train_loss: 0.1533	Eval_AUC: 0.8300
Epoch 44 Global_step 3660000	Train_loss: 0.1531	Eval_AUC: 0.8337
Epoch 44 Global_step 3661000	Train_loss: 0.1555	Eval_AUC: 0.8416
Epoch 44 Global_step 3662000	Train_loss: 0.1529	Eval_AUC: 0.8393
Epoch 44 Global_step 3663000	Train_loss: 0.1542	Eval_AUC: 0.8369
Epoch 44 Global_step 3664000	Train_loss: 0.1569	Eval_AUC: 0.8343
Epoch 44 Global_step 3665000	Train_loss: 0.1555	Eval_AUC: 0.8396
Epoch 44 Global_step 3666000	Train_loss: 0.1577	Eval_AUC: 0.8367
Epoch 44 Global_step 3667000	Train_loss: 0.1562	Eval_AUC: 0.8389
Epoch 44 Global_step 3668000	Train_loss: 0.1575	Eval_AUC: 0.8365
Epoch 44 DONE	Cost time: 341783.20
Epoch 45 Global_step 3669000	Train_loss: 0.1478	Eval_AUC: 0.8377
Epoch 45 Global_step 3670000	Train_loss: 0.1389	Eval_AUC: 0.8342
Epoch 45 Global_step 3671000	Train_loss: 0.1363	Eval_AUC: 0.8353
Epoch 45 Global_step 3672000	Train_loss: 0.1377	Eval_AUC: 0.8346
Epoch 45 Global_step 3673000	Train_loss: 0.1361	Eval_AUC: 0.8315
Epoch 45 Global_step 3674000	Train_loss: 0.1349	Eval_AUC: 0.8359
Epoch 45 Global_step 3675000	Train_loss: 0.1349	Eval_AUC: 0.8353
Epoch 45 Global_step 3676000	Train_loss: 0.1363	Eval_AUC: 0.8359
Epoch 45 Global_step 3677000	Train_loss: 0.1373	Eval_AUC: 0.8380
Epoch 45 Global_step 3678000	Train_loss: 0.1383	Eval_AUC: 0.8368
Epoch 45 Global_step 3679000	Train_loss: 0.1384	Eval_AUC: 0.8353
Epoch 45 Global_step 3680000	Train_loss: 0.1383	Eval_AUC: 0.8388
Epoch 45 Global_step 3681000	Train_loss: 0.1391	Eval_AUC: 0.8333
Epoch 45 Global_step 3682000	Train_loss: 0.1394	Eval_AUC: 0.8339
Epoch 45 Global_step 3683000	Train_loss: 0.1394	Eval_AUC: 0.8338
Epoch 45 Global_step 3684000	Train_loss: 0.1379	Eval_AUC: 0.8342
Epoch 45 Global_step 3685000	Train_loss: 0.1409	Eval_AUC: 0.8322
Epoch 45 Global_step 3686000	Train_loss: 0.1379	Eval_AUC: 0.8376
Epoch 45 Global_step 3687000	Train_loss: 0.1398	Eval_AUC: 0.8295
Epoch 45 Global_step 3688000	Train_loss: 0.1418	Eval_AUC: 0.8352
Epoch 45 Global_step 3689000	Train_loss: 0.1396	Eval_AUC: 0.8389
Epoch 45 Global_step 3690000	Train_loss: 0.1415	Eval_AUC: 0.8351
Epoch 45 Global_step 3691000	Train_loss: 0.1418	Eval_AUC: 0.8327
Epoch 45 Global_step 3692000	Train_loss: 0.1415	Eval_AUC: 0.8379
Epoch 45 Global_step 3693000	Train_loss: 0.1431	Eval_AUC: 0.8332
Epoch 45 Global_step 3694000	Train_loss: 0.1409	Eval_AUC: 0.8335
Epoch 45 Global_step 3695000	Train_loss: 0.1419	Eval_AUC: 0.8350
Epoch 45 Global_step 3696000	Train_loss: 0.1413	Eval_AUC: 0.8359
Epoch 45 Global_step 3697000	Train_loss: 0.1438	Eval_AUC: 0.8339
Epoch 45 Global_step 3698000	Train_loss: 0.1412	Eval_AUC: 0.8331
Epoch 45 Global_step 3699000	Train_loss: 0.1441	Eval_AUC: 0.8388
Epoch 45 Global_step 3700000	Train_loss: 0.1426	Eval_AUC: 0.8382
Epoch 45 Global_step 3701000	Train_loss: 0.1440	Eval_AUC: 0.8309
Epoch 45 Global_step 3702000	Train_loss: 0.1441	Eval_AUC: 0.8374
Epoch 45 Global_step 3703000	Train_loss: 0.1442	Eval_AUC: 0.8369
Epoch 45 Global_step 3704000	Train_loss: 0.1445	Eval_AUC: 0.8394
Epoch 45 Global_step 3705000	Train_loss: 0.1451	Eval_AUC: 0.8337
Epoch 45 Global_step 3706000	Train_loss: 0.1443	Eval_AUC: 0.8344
Epoch 45 Global_step 3707000	Train_loss: 0.1435	Eval_AUC: 0.8390
Epoch 45 Global_step 3708000	Train_loss: 0.1448	Eval_AUC: 0.8333
Epoch 45 Global_step 3709000	Train_loss: 0.1470	Eval_AUC: 0.8365
Epoch 45 Global_step 3710000	Train_loss: 0.1475	Eval_AUC: 0.8342
Epoch 45 Global_step 3711000	Train_loss: 0.1466	Eval_AUC: 0.8375
Epoch 45 Global_step 3712000	Train_loss: 0.1444	Eval_AUC: 0.8377
Epoch 45 Global_step 3713000	Train_loss: 0.1468	Eval_AUC: 0.8368
Epoch 45 Global_step 3714000	Train_loss: 0.1476	Eval_AUC: 0.8330
Epoch 45 Global_step 3715000	Train_loss: 0.1462	Eval_AUC: 0.8354
Epoch 45 Global_step 3716000	Train_loss: 0.1470	Eval_AUC: 0.8360
Epoch 45 Global_step 3717000	Train_loss: 0.1454	Eval_AUC: 0.8378
Epoch 45 Global_step 3718000	Train_loss: 0.1479	Eval_AUC: 0.8356
Epoch 45 Global_step 3719000	Train_loss: 0.1474	Eval_AUC: 0.8379
Epoch 45 Global_step 3720000	Train_loss: 0.1474	Eval_AUC: 0.8338
Epoch 45 Global_step 3721000	Train_loss: 0.1479	Eval_AUC: 0.8377
Epoch 45 Global_step 3722000	Train_loss: 0.1469	Eval_AUC: 0.8297
Epoch 45 Global_step 3723000	Train_loss: 0.1494	Eval_AUC: 0.8386
Epoch 45 Global_step 3724000	Train_loss: 0.1505	Eval_AUC: 0.8309
Epoch 45 Global_step 3725000	Train_loss: 0.1487	Eval_AUC: 0.8303
Epoch 45 Global_step 3726000	Train_loss: 0.1475	Eval_AUC: 0.8381
Epoch 45 Global_step 3727000	Train_loss: 0.1481	Eval_AUC: 0.8368
Epoch 45 Global_step 3728000	Train_loss: 0.1502	Eval_AUC: 0.8326
Epoch 45 Global_step 3729000	Train_loss: 0.1506	Eval_AUC: 0.8347
Epoch 45 Global_step 3730000	Train_loss: 0.1489	Eval_AUC: 0.8355
Epoch 45 Global_step 3731000	Train_loss: 0.1508	Eval_AUC: 0.8275
Epoch 45 Global_step 3732000	Train_loss: 0.1509	Eval_AUC: 0.8364
Epoch 45 Global_step 3733000	Train_loss: 0.1539	Eval_AUC: 0.8402
Epoch 45 Global_step 3734000	Train_loss: 0.1500	Eval_AUC: 0.8414
Epoch 45 Global_step 3735000	Train_loss: 0.1513	Eval_AUC: 0.8384
Epoch 45 Global_step 3736000	Train_loss: 0.1503	Eval_AUC: 0.8340
Epoch 45 Global_step 3737000	Train_loss: 0.1517	Eval_AUC: 0.8389
Epoch 45 Global_step 3738000	Train_loss: 0.1485	Eval_AUC: 0.8422
Epoch 45 Global_step 3739000	Train_loss: 0.1517	Eval_AUC: 0.8383
Epoch 45 Global_step 3740000	Train_loss: 0.1530	Eval_AUC: 0.8370
Epoch 45 Global_step 3741000	Train_loss: 0.1525	Eval_AUC: 0.8378
Epoch 45 Global_step 3742000	Train_loss: 0.1528	Eval_AUC: 0.8334
Epoch 45 Global_step 3743000	Train_loss: 0.1506	Eval_AUC: 0.8325
Epoch 45 Global_step 3744000	Train_loss: 0.1525	Eval_AUC: 0.8355
Epoch 45 Global_step 3745000	Train_loss: 0.1533	Eval_AUC: 0.8397
Epoch 45 Global_step 3746000	Train_loss: 0.1532	Eval_AUC: 0.8369
Epoch 45 Global_step 3747000	Train_loss: 0.1532	Eval_AUC: 0.8397
Epoch 45 Global_step 3748000	Train_loss: 0.1536	Eval_AUC: 0.8344
Epoch 45 Global_step 3749000	Train_loss: 0.1523	Eval_AUC: 0.8337
Epoch 45 Global_step 3750000	Train_loss: 0.1544	Eval_AUC: 0.8365
Epoch 45 DONE	Cost time: 349017.83
Epoch 46 Global_step 3751000	Train_loss: 0.1353	Eval_AUC: 0.8356
Epoch 46 Global_step 3752000	Train_loss: 0.1352	Eval_AUC: 0.8370
Epoch 46 Global_step 3753000	Train_loss: 0.1341	Eval_AUC: 0.8339
Epoch 46 Global_step 3754000	Train_loss: 0.1324	Eval_AUC: 0.8348
Epoch 46 Global_step 3755000	Train_loss: 0.1335	Eval_AUC: 0.8324
Epoch 46 Global_step 3756000	Train_loss: 0.1323	Eval_AUC: 0.8326
Epoch 46 Global_step 3757000	Train_loss: 0.1337	Eval_AUC: 0.8347
Epoch 46 Global_step 3758000	Train_loss: 0.1323	Eval_AUC: 0.8352
Epoch 46 Global_step 3759000	Train_loss: 0.1350	Eval_AUC: 0.8328
Epoch 46 Global_step 3760000	Train_loss: 0.1383	Eval_AUC: 0.8340
Epoch 46 Global_step 3761000	Train_loss: 0.1346	Eval_AUC: 0.8320
Epoch 46 Global_step 3762000	Train_loss: 0.1362	Eval_AUC: 0.8339
Epoch 46 Global_step 3763000	Train_loss: 0.1366	Eval_AUC: 0.8325
Epoch 46 Global_step 3764000	Train_loss: 0.1373	Eval_AUC: 0.8317
Epoch 46 Global_step 3765000	Train_loss: 0.1375	Eval_AUC: 0.8353
Epoch 46 Global_step 3766000	Train_loss: 0.1368	Eval_AUC: 0.8327
Epoch 46 Global_step 3767000	Train_loss: 0.1382	Eval_AUC: 0.8338
Epoch 46 Global_step 3768000	Train_loss: 0.1373	Eval_AUC: 0.8326
Epoch 46 Global_step 3769000	Train_loss: 0.1377	Eval_AUC: 0.8344
Epoch 46 Global_step 3770000	Train_loss: 0.1394	Eval_AUC: 0.8296
Epoch 46 Global_step 3771000	Train_loss: 0.1372	Eval_AUC: 0.8345
Epoch 46 Global_step 3772000	Train_loss: 0.1379	Eval_AUC: 0.8354
Epoch 46 Global_step 3773000	Train_loss: 0.1395	Eval_AUC: 0.8366
Epoch 46 Global_step 3774000	Train_loss: 0.1407	Eval_AUC: 0.8355
Epoch 46 Global_step 3775000	Train_loss: 0.1388	Eval_AUC: 0.8306
Epoch 46 Global_step 3776000	Train_loss: 0.1414	Eval_AUC: 0.8298
Epoch 46 Global_step 3777000	Train_loss: 0.1417	Eval_AUC: 0.8327
Epoch 46 Global_step 3778000	Train_loss: 0.1415	Eval_AUC: 0.8323
Epoch 46 Global_step 3779000	Train_loss: 0.1420	Eval_AUC: 0.8298
Epoch 46 Global_step 3780000	Train_loss: 0.1387	Eval_AUC: 0.8335
Epoch 46 Global_step 3781000	Train_loss: 0.1384	Eval_AUC: 0.8367
Epoch 46 Global_step 3782000	Train_loss: 0.1424	Eval_AUC: 0.8328
Epoch 46 Global_step 3783000	Train_loss: 0.1443	Eval_AUC: 0.8386
Epoch 46 Global_step 3784000	Train_loss: 0.1428	Eval_AUC: 0.8350
Epoch 46 Global_step 3785000	Train_loss: 0.1401	Eval_AUC: 0.8394
Epoch 46 Global_step 3786000	Train_loss: 0.1435	Eval_AUC: 0.8327
Epoch 46 Global_step 3787000	Train_loss: 0.1424	Eval_AUC: 0.8323
Epoch 46 Global_step 3788000	Train_loss: 0.1429	Eval_AUC: 0.8295
Epoch 46 Global_step 3789000	Train_loss: 0.1438	Eval_AUC: 0.8347
Epoch 46 Global_step 3790000	Train_loss: 0.1410	Eval_AUC: 0.8308
Epoch 46 Global_step 3791000	Train_loss: 0.1439	Eval_AUC: 0.8378
Epoch 46 Global_step 3792000	Train_loss: 0.1420	Eval_AUC: 0.8350
Epoch 46 Global_step 3793000	Train_loss: 0.1423	Eval_AUC: 0.8336
Epoch 46 Global_step 3794000	Train_loss: 0.1449	Eval_AUC: 0.8323
Epoch 46 Global_step 3795000	Train_loss: 0.1433	Eval_AUC: 0.8348
Epoch 46 Global_step 3796000	Train_loss: 0.1444	Eval_AUC: 0.8358
Epoch 46 Global_step 3797000	Train_loss: 0.1451	Eval_AUC: 0.8291
Epoch 46 Global_step 3798000	Train_loss: 0.1456	Eval_AUC: 0.8369
Epoch 46 Global_step 3799000	Train_loss: 0.1459	Eval_AUC: 0.8323
Epoch 46 Global_step 3800000	Train_loss: 0.1459	Eval_AUC: 0.8314
Epoch 46 Global_step 3801000	Train_loss: 0.1451	Eval_AUC: 0.8289
Epoch 46 Global_step 3802000	Train_loss: 0.1451	Eval_AUC: 0.8349
Epoch 46 Global_step 3803000	Train_loss: 0.1467	Eval_AUC: 0.8350
Epoch 46 Global_step 3804000	Train_loss: 0.1452	Eval_AUC: 0.8341
Epoch 46 Global_step 3805000	Train_loss: 0.1476	Eval_AUC: 0.8336
Epoch 46 Global_step 3806000	Train_loss: 0.1480	Eval_AUC: 0.8303
Epoch 46 Global_step 3807000	Train_loss: 0.1464	Eval_AUC: 0.8356
Epoch 46 Global_step 3808000	Train_loss: 0.1476	Eval_AUC: 0.8296
Epoch 46 Global_step 3809000	Train_loss: 0.1476	Eval_AUC: 0.8371
Epoch 46 Global_step 3810000	Train_loss: 0.1468	Eval_AUC: 0.8353
Epoch 46 Global_step 3811000	Train_loss: 0.1484	Eval_AUC: 0.8321
Epoch 46 Global_step 3812000	Train_loss: 0.1461	Eval_AUC: 0.8311
Epoch 46 Global_step 3813000	Train_loss: 0.1467	Eval_AUC: 0.8357
Epoch 46 Global_step 3814000	Train_loss: 0.1483	Eval_AUC: 0.8367
Epoch 46 Global_step 3815000	Train_loss: 0.1472	Eval_AUC: 0.8342
Epoch 46 Global_step 3816000	Train_loss: 0.1497	Eval_AUC: 0.8292
Epoch 46 Global_step 3817000	Train_loss: 0.1483	Eval_AUC: 0.8330
Epoch 46 Global_step 3818000	Train_loss: 0.1477	Eval_AUC: 0.8301
Epoch 46 Global_step 3819000	Train_loss: 0.1489	Eval_AUC: 0.8330
Epoch 46 Global_step 3820000	Train_loss: 0.1484	Eval_AUC: 0.8391
Epoch 46 Global_step 3821000	Train_loss: 0.1489	Eval_AUC: 0.8372
Epoch 46 Global_step 3822000	Train_loss: 0.1475	Eval_AUC: 0.8340
Epoch 46 Global_step 3823000	Train_loss: 0.1495	Eval_AUC: 0.8276
Epoch 46 Global_step 3824000	Train_loss: 0.1489	Eval_AUC: 0.8372
Epoch 46 Global_step 3825000	Train_loss: 0.1519	Eval_AUC: 0.8336
Epoch 46 Global_step 3826000	Train_loss: 0.1490	Eval_AUC: 0.8334
Epoch 46 Global_step 3827000	Train_loss: 0.1488	Eval_AUC: 0.8334
Epoch 46 Global_step 3828000	Train_loss: 0.1501	Eval_AUC: 0.8378
Epoch 46 Global_step 3829000	Train_loss: 0.1523	Eval_AUC: 0.8387
Epoch 46 Global_step 3830000	Train_loss: 0.1498	Eval_AUC: 0.8372
Epoch 46 Global_step 3831000	Train_loss: 0.1508	Eval_AUC: 0.8347
Epoch 46 DONE	Cost time: 356188.37
Epoch 47 Global_step 3832000	Train_loss: 0.1426	Eval_AUC: 0.8331
Epoch 47 Global_step 3833000	Train_loss: 0.1325	Eval_AUC: 0.8362
Epoch 47 Global_step 3834000	Train_loss: 0.1298	Eval_AUC: 0.8357
Epoch 47 Global_step 3835000	Train_loss: 0.1317	Eval_AUC: 0.8311
Epoch 47 Global_step 3836000	Train_loss: 0.1340	Eval_AUC: 0.8351
Epoch 47 Global_step 3837000	Train_loss: 0.1316	Eval_AUC: 0.8343
Epoch 47 Global_step 3838000	Train_loss: 0.1321	Eval_AUC: 0.8311
Epoch 47 Global_step 3839000	Train_loss: 0.1316	Eval_AUC: 0.8344
Epoch 47 Global_step 3840000	Train_loss: 0.1331	Eval_AUC: 0.8336
Epoch 47 Global_step 3841000	Train_loss: 0.1315	Eval_AUC: 0.8341
Epoch 47 Global_step 3842000	Train_loss: 0.1342	Eval_AUC: 0.8315
Epoch 47 Global_step 3843000	Train_loss: 0.1346	Eval_AUC: 0.8340
Epoch 47 Global_step 3844000	Train_loss: 0.1352	Eval_AUC: 0.8323
Epoch 47 Global_step 3845000	Train_loss: 0.1345	Eval_AUC: 0.8331
Epoch 47 Global_step 3846000	Train_loss: 0.1333	Eval_AUC: 0.8365
Epoch 47 Global_step 3847000	Train_loss: 0.1342	Eval_AUC: 0.8316
Epoch 47 Global_step 3848000	Train_loss: 0.1335	Eval_AUC: 0.8306
Epoch 47 Global_step 3849000	Train_loss: 0.1359	Eval_AUC: 0.8337
Epoch 47 Global_step 3850000	Train_loss: 0.1350	Eval_AUC: 0.8311
Epoch 47 Global_step 3851000	Train_loss: 0.1335	Eval_AUC: 0.8349
Epoch 47 Global_step 3852000	Train_loss: 0.1343	Eval_AUC: 0.8380
Epoch 47 Global_step 3853000	Train_loss: 0.1376	Eval_AUC: 0.8309
Epoch 47 Global_step 3854000	Train_loss: 0.1352	Eval_AUC: 0.8324
Epoch 47 Global_step 3855000	Train_loss: 0.1360	Eval_AUC: 0.8374
Epoch 47 Global_step 3856000	Train_loss: 0.1382	Eval_AUC: 0.8330
Epoch 47 Global_step 3857000	Train_loss: 0.1364	Eval_AUC: 0.8305
Epoch 47 Global_step 3858000	Train_loss: 0.1376	Eval_AUC: 0.8326
Epoch 47 Global_step 3859000	Train_loss: 0.1352	Eval_AUC: 0.8328
Epoch 47 Global_step 3860000	Train_loss: 0.1369	Eval_AUC: 0.8368
Epoch 47 Global_step 3861000	Train_loss: 0.1411	Eval_AUC: 0.8347
Epoch 47 Global_step 3862000	Train_loss: 0.1365	Eval_AUC: 0.8349
Epoch 47 Global_step 3863000	Train_loss: 0.1395	Eval_AUC: 0.8319
Epoch 47 Global_step 3864000	Train_loss: 0.1393	Eval_AUC: 0.8313
Epoch 47 Global_step 3865000	Train_loss: 0.1408	Eval_AUC: 0.8343
Epoch 47 Global_step 3866000	Train_loss: 0.1403	Eval_AUC: 0.8356
Epoch 47 Global_step 3867000	Train_loss: 0.1394	Eval_AUC: 0.8318
Epoch 47 Global_step 3868000	Train_loss: 0.1367	Eval_AUC: 0.8312
Epoch 47 Global_step 3869000	Train_loss: 0.1384	Eval_AUC: 0.8351
Epoch 47 Global_step 3870000	Train_loss: 0.1413	Eval_AUC: 0.8371
Epoch 47 Global_step 3871000	Train_loss: 0.1405	Eval_AUC: 0.8339
Epoch 47 Global_step 3872000	Train_loss: 0.1415	Eval_AUC: 0.8367
Epoch 47 Global_step 3873000	Train_loss: 0.1406	Eval_AUC: 0.8344
Epoch 47 Global_step 3874000	Train_loss: 0.1431	Eval_AUC: 0.8345
Epoch 47 Global_step 3875000	Train_loss: 0.1411	Eval_AUC: 0.8335
Epoch 47 Global_step 3876000	Train_loss: 0.1437	Eval_AUC: 0.8337
Epoch 47 Global_step 3877000	Train_loss: 0.1412	Eval_AUC: 0.8356
Epoch 47 Global_step 3878000	Train_loss: 0.1414	Eval_AUC: 0.8367
Epoch 47 Global_step 3879000	Train_loss: 0.1429	Eval_AUC: 0.8325
Epoch 47 Global_step 3880000	Train_loss: 0.1446	Eval_AUC: 0.8317
Epoch 47 Global_step 3881000	Train_loss: 0.1400	Eval_AUC: 0.8389
Epoch 47 Global_step 3882000	Train_loss: 0.1421	Eval_AUC: 0.8342
Epoch 47 Global_step 3883000	Train_loss: 0.1444	Eval_AUC: 0.8372
Epoch 47 Global_step 3884000	Train_loss: 0.1432	Eval_AUC: 0.8334
Epoch 47 Global_step 3885000	Train_loss: 0.1433	Eval_AUC: 0.8328
Epoch 47 Global_step 3886000	Train_loss: 0.1432	Eval_AUC: 0.8311
Epoch 47 Global_step 3887000	Train_loss: 0.1451	Eval_AUC: 0.8374
Epoch 47 Global_step 3888000	Train_loss: 0.1440	Eval_AUC: 0.8285
Epoch 47 Global_step 3889000	Train_loss: 0.1438	Eval_AUC: 0.8320
Epoch 47 Global_step 3890000	Train_loss: 0.1478	Eval_AUC: 0.8314
Epoch 47 Global_step 3891000	Train_loss: 0.1482	Eval_AUC: 0.8316
Epoch 47 Global_step 3892000	Train_loss: 0.1447	Eval_AUC: 0.8339
Epoch 47 Global_step 3893000	Train_loss: 0.1457	Eval_AUC: 0.8363
Epoch 47 Global_step 3894000	Train_loss: 0.1449	Eval_AUC: 0.8366
Epoch 47 Global_step 3895000	Train_loss: 0.1466	Eval_AUC: 0.8382
Epoch 47 Global_step 3896000	Train_loss: 0.1423	Eval_AUC: 0.8368
Epoch 47 Global_step 3897000	Train_loss: 0.1458	Eval_AUC: 0.8371
Epoch 47 Global_step 3898000	Train_loss: 0.1452	Eval_AUC: 0.8369
Epoch 47 Global_step 3899000	Train_loss: 0.1451	Eval_AUC: 0.8347
Epoch 47 Global_step 3900000	Train_loss: 0.1468	Eval_AUC: 0.8331
Epoch 47 Global_step 3901000	Train_loss: 0.1479	Eval_AUC: 0.8370
Epoch 47 Global_step 3902000	Train_loss: 0.1460	Eval_AUC: 0.8343
Epoch 47 Global_step 3903000	Train_loss: 0.1466	Eval_AUC: 0.8311
Epoch 47 Global_step 3904000	Train_loss: 0.1444	Eval_AUC: 0.8325
Epoch 47 Global_step 3905000	Train_loss: 0.1478	Eval_AUC: 0.8333
Epoch 47 Global_step 3906000	Train_loss: 0.1483	Eval_AUC: 0.8350
Epoch 47 Global_step 3907000	Train_loss: 0.1465	Eval_AUC: 0.8343
Epoch 47 Global_step 3908000	Train_loss: 0.1469	Eval_AUC: 0.8318
Epoch 47 Global_step 3909000	Train_loss: 0.1504	Eval_AUC: 0.8363
Epoch 47 Global_step 3910000	Train_loss: 0.1486	Eval_AUC: 0.8379
Epoch 47 Global_step 3911000	Train_loss: 0.1472	Eval_AUC: 0.8389
Epoch 47 Global_step 3912000	Train_loss: 0.1464	Eval_AUC: 0.8353
Epoch 47 Global_step 3913000	Train_loss: 0.1508	Eval_AUC: 0.8323
Epoch 47 DONE	Cost time: 363424.18
Epoch 48 Global_step 3914000	Train_loss: 0.1326	Eval_AUC: 0.8334
Epoch 48 Global_step 3915000	Train_loss: 0.1288	Eval_AUC: 0.8325
Epoch 48 Global_step 3916000	Train_loss: 0.1304	Eval_AUC: 0.8316
Epoch 48 Global_step 3917000	Train_loss: 0.1300	Eval_AUC: 0.8354
Epoch 48 Global_step 3918000	Train_loss: 0.1297	Eval_AUC: 0.8331
Epoch 48 Global_step 3919000	Train_loss: 0.1290	Eval_AUC: 0.8343
Epoch 48 Global_step 3920000	Train_loss: 0.1303	Eval_AUC: 0.8303
Epoch 48 Global_step 3921000	Train_loss: 0.1295	Eval_AUC: 0.8331
Epoch 48 Global_step 3922000	Train_loss: 0.1312	Eval_AUC: 0.8301
Epoch 48 Global_step 3923000	Train_loss: 0.1309	Eval_AUC: 0.8341
Epoch 48 Global_step 3924000	Train_loss: 0.1304	Eval_AUC: 0.8359
Epoch 48 Global_step 3925000	Train_loss: 0.1328	Eval_AUC: 0.8325
Epoch 48 Global_step 3926000	Train_loss: 0.1302	Eval_AUC: 0.8323
Epoch 48 Global_step 3927000	Train_loss: 0.1312	Eval_AUC: 0.8308
Epoch 48 Global_step 3928000	Train_loss: 0.1317	Eval_AUC: 0.8317
Epoch 48 Global_step 3929000	Train_loss: 0.1303	Eval_AUC: 0.8328
Epoch 48 Global_step 3930000	Train_loss: 0.1363	Eval_AUC: 0.8339
Epoch 48 Global_step 3931000	Train_loss: 0.1335	Eval_AUC: 0.8347
Epoch 48 Global_step 3932000	Train_loss: 0.1334	Eval_AUC: 0.8360
Epoch 48 Global_step 3933000	Train_loss: 0.1324	Eval_AUC: 0.8285
Epoch 48 Global_step 3934000	Train_loss: 0.1330	Eval_AUC: 0.8328
Epoch 48 Global_step 3935000	Train_loss: 0.1333	Eval_AUC: 0.8300
Epoch 48 Global_step 3936000	Train_loss: 0.1343	Eval_AUC: 0.8309
Epoch 48 Global_step 3937000	Train_loss: 0.1341	Eval_AUC: 0.8286
Epoch 48 Global_step 3938000	Train_loss: 0.1332	Eval_AUC: 0.8330
Epoch 48 Global_step 3939000	Train_loss: 0.1368	Eval_AUC: 0.8320
Epoch 48 Global_step 3940000	Train_loss: 0.1348	Eval_AUC: 0.8320
Epoch 48 Global_step 3941000	Train_loss: 0.1346	Eval_AUC: 0.8330
Epoch 48 Global_step 3942000	Train_loss: 0.1367	Eval_AUC: 0.8300
Epoch 48 Global_step 3943000	Train_loss: 0.1327	Eval_AUC: 0.8369
Epoch 48 Global_step 3944000	Train_loss: 0.1364	Eval_AUC: 0.8345
Epoch 48 Global_step 3945000	Train_loss: 0.1364	Eval_AUC: 0.8333
Epoch 48 Global_step 3946000	Train_loss: 0.1349	Eval_AUC: 0.8375
Epoch 48 Global_step 3947000	Train_loss: 0.1396	Eval_AUC: 0.8313
Epoch 48 Global_step 3948000	Train_loss: 0.1371	Eval_AUC: 0.8316
Epoch 48 Global_step 3949000	Train_loss: 0.1385	Eval_AUC: 0.8327
Epoch 48 Global_step 3950000	Train_loss: 0.1375	Eval_AUC: 0.8296
Epoch 48 Global_step 3951000	Train_loss: 0.1394	Eval_AUC: 0.8344
Epoch 48 Global_step 3952000	Train_loss: 0.1391	Eval_AUC: 0.8338
Epoch 48 Global_step 3953000	Train_loss: 0.1374	Eval_AUC: 0.8315
Epoch 48 Global_step 3954000	Train_loss: 0.1381	Eval_AUC: 0.8266
Epoch 48 Global_step 3955000	Train_loss: 0.1379	Eval_AUC: 0.8312
Epoch 48 Global_step 3956000	Train_loss: 0.1378	Eval_AUC: 0.8343
Epoch 48 Global_step 3957000	Train_loss: 0.1390	Eval_AUC: 0.8325
Epoch 48 Global_step 3958000	Train_loss: 0.1393	Eval_AUC: 0.8331
Epoch 48 Global_step 3959000	Train_loss: 0.1389	Eval_AUC: 0.8323
Epoch 48 Global_step 3960000	Train_loss: 0.1390	Eval_AUC: 0.8343
Epoch 48 Global_step 3961000	Train_loss: 0.1407	Eval_AUC: 0.8326
Epoch 48 Global_step 3962000	Train_loss: 0.1390	Eval_AUC: 0.8360
Epoch 48 Global_step 3963000	Train_loss: 0.1402	Eval_AUC: 0.8319
Epoch 48 Global_step 3964000	Train_loss: 0.1384	Eval_AUC: 0.8322
Epoch 48 Global_step 3965000	Train_loss: 0.1429	Eval_AUC: 0.8318
Epoch 48 Global_step 3966000	Train_loss: 0.1395	Eval_AUC: 0.8308
Epoch 48 Global_step 3967000	Train_loss: 0.1395	Eval_AUC: 0.8333
Epoch 48 Global_step 3968000	Train_loss: 0.1422	Eval_AUC: 0.8331
Epoch 48 Global_step 3969000	Train_loss: 0.1418	Eval_AUC: 0.8297
Epoch 48 Global_step 3970000	Train_loss: 0.1429	Eval_AUC: 0.8376
Epoch 48 Global_step 3971000	Train_loss: 0.1412	Eval_AUC: 0.8335
Epoch 48 Global_step 3972000	Train_loss: 0.1426	Eval_AUC: 0.8361
Epoch 48 Global_step 3973000	Train_loss: 0.1408	Eval_AUC: 0.8303
Epoch 48 Global_step 3974000	Train_loss: 0.1406	Eval_AUC: 0.8347
Epoch 48 Global_step 3975000	Train_loss: 0.1408	Eval_AUC: 0.8355
Epoch 48 Global_step 3976000	Train_loss: 0.1440	Eval_AUC: 0.8340
Epoch 48 Global_step 3977000	Train_loss: 0.1442	Eval_AUC: 0.8318
Epoch 48 Global_step 3978000	Train_loss: 0.1442	Eval_AUC: 0.8296
Epoch 48 Global_step 3979000	Train_loss: 0.1439	Eval_AUC: 0.8289
Epoch 48 Global_step 3980000	Train_loss: 0.1460	Eval_AUC: 0.8321
Epoch 48 Global_step 3981000	Train_loss: 0.1426	Eval_AUC: 0.8368
Epoch 48 Global_step 3982000	Train_loss: 0.1456	Eval_AUC: 0.8323
Epoch 48 Global_step 3983000	Train_loss: 0.1431	Eval_AUC: 0.8321
Epoch 48 Global_step 3984000	Train_loss: 0.1453	Eval_AUC: 0.8352
Epoch 48 Global_step 3985000	Train_loss: 0.1482	Eval_AUC: 0.8291
Epoch 48 Global_step 3986000	Train_loss: 0.1470	Eval_AUC: 0.8289
Epoch 48 Global_step 3987000	Train_loss: 0.1468	Eval_AUC: 0.8351
Epoch 48 Global_step 3988000	Train_loss: 0.1438	Eval_AUC: 0.8356
Epoch 48 Global_step 3989000	Train_loss: 0.1466	Eval_AUC: 0.8315
Epoch 48 Global_step 3990000	Train_loss: 0.1464	Eval_AUC: 0.8381
Epoch 48 Global_step 3991000	Train_loss: 0.1465	Eval_AUC: 0.8351
Epoch 48 Global_step 3992000	Train_loss: 0.1451	Eval_AUC: 0.8293
Epoch 48 Global_step 3993000	Train_loss: 0.1464	Eval_AUC: 0.8328
Epoch 48 Global_step 3994000	Train_loss: 0.1442	Eval_AUC: 0.8376
Epoch 48 DONE	Cost time: 370601.44
Epoch 49 Global_step 3995000	Train_loss: 0.1386	Eval_AUC: 0.8312
Epoch 49 Global_step 3996000	Train_loss: 0.1282	Eval_AUC: 0.8326
Epoch 49 Global_step 3997000	Train_loss: 0.1269	Eval_AUC: 0.8316
Epoch 49 Global_step 3998000	Train_loss: 0.1271	Eval_AUC: 0.8345
Epoch 49 Global_step 3999000	Train_loss: 0.1273	Eval_AUC: 0.8341
Epoch 49 Global_step 4000000	Train_loss: 0.1284	Eval_AUC: 0.8302
Epoch 49 Global_step 4001000	Train_loss: 0.1303	Eval_AUC: 0.8306
Epoch 49 Global_step 4002000	Train_loss: 0.1283	Eval_AUC: 0.8322
Epoch 49 Global_step 4003000	Train_loss: 0.1292	Eval_AUC: 0.8343
Epoch 49 Global_step 4004000	Train_loss: 0.1291	Eval_AUC: 0.8361
Epoch 49 Global_step 4005000	Train_loss: 0.1281	Eval_AUC: 0.8310
Epoch 49 Global_step 4006000	Train_loss: 0.1286	Eval_AUC: 0.8288
Epoch 49 Global_step 4007000	Train_loss: 0.1310	Eval_AUC: 0.8308
Epoch 49 Global_step 4008000	Train_loss: 0.1293	Eval_AUC: 0.8351
Epoch 49 Global_step 4009000	Train_loss: 0.1305	Eval_AUC: 0.8344
Epoch 49 Global_step 4010000	Train_loss: 0.1306	Eval_AUC: 0.8344
Epoch 49 Global_step 4011000	Train_loss: 0.1309	Eval_AUC: 0.8290
Epoch 49 Global_step 4012000	Train_loss: 0.1306	Eval_AUC: 0.8348
Epoch 49 Global_step 4013000	Train_loss: 0.1351	Eval_AUC: 0.8322
Epoch 49 Global_step 4014000	Train_loss: 0.1313	Eval_AUC: 0.8300
Epoch 49 Global_step 4015000	Train_loss: 0.1324	Eval_AUC: 0.8267
Epoch 49 Global_step 4016000	Train_loss: 0.1324	Eval_AUC: 0.8308
Epoch 49 Global_step 4017000	Train_loss: 0.1310	Eval_AUC: 0.8362
Epoch 49 Global_step 4018000	Train_loss: 0.1311	Eval_AUC: 0.8326
Epoch 49 Global_step 4019000	Train_loss: 0.1337	Eval_AUC: 0.8337
Epoch 49 Global_step 4020000	Train_loss: 0.1327	Eval_AUC: 0.8316
Epoch 49 Global_step 4021000	Train_loss: 0.1331	Eval_AUC: 0.8309
Epoch 49 Global_step 4022000	Train_loss: 0.1330	Eval_AUC: 0.8284
Epoch 49 Global_step 4023000	Train_loss: 0.1314	Eval_AUC: 0.8323
Epoch 49 Global_step 4024000	Train_loss: 0.1314	Eval_AUC: 0.8319
Epoch 49 Global_step 4025000	Train_loss: 0.1315	Eval_AUC: 0.8292
Epoch 49 Global_step 4026000	Train_loss: 0.1344	Eval_AUC: 0.8330
Epoch 49 Global_step 4027000	Train_loss: 0.1338	Eval_AUC: 0.8292
Epoch 49 Global_step 4028000	Train_loss: 0.1376	Eval_AUC: 0.8327
Epoch 49 Global_step 4029000	Train_loss: 0.1334	Eval_AUC: 0.8292
Epoch 49 Global_step 4030000	Train_loss: 0.1363	Eval_AUC: 0.8349
Epoch 49 Global_step 4031000	Train_loss: 0.1370	Eval_AUC: 0.8333
Epoch 49 Global_step 4032000	Train_loss: 0.1366	Eval_AUC: 0.8307
Epoch 49 Global_step 4033000	Train_loss: 0.1354	Eval_AUC: 0.8310
Epoch 49 Global_step 4034000	Train_loss: 0.1370	Eval_AUC: 0.8337
Epoch 49 Global_step 4035000	Train_loss: 0.1349	Eval_AUC: 0.8339
Epoch 49 Global_step 4036000	Train_loss: 0.1363	Eval_AUC: 0.8362
Epoch 49 Global_step 4037000	Train_loss: 0.1387	Eval_AUC: 0.8313
Epoch 49 Global_step 4038000	Train_loss: 0.1377	Eval_AUC: 0.8315
Epoch 49 Global_step 4039000	Train_loss: 0.1391	Eval_AUC: 0.8343
Epoch 49 Global_step 4040000	Train_loss: 0.1358	Eval_AUC: 0.8348
Epoch 49 Global_step 4041000	Train_loss: 0.1375	Eval_AUC: 0.8305
Epoch 49 Global_step 4042000	Train_loss: 0.1380	Eval_AUC: 0.8373
Epoch 49 Global_step 4043000	Train_loss: 0.1384	Eval_AUC: 0.8332
Epoch 49 Global_step 4044000	Train_loss: 0.1370	Eval_AUC: 0.8279
Epoch 49 Global_step 4045000	Train_loss: 0.1366	Eval_AUC: 0.8332
Epoch 49 Global_step 4046000	Train_loss: 0.1374	Eval_AUC: 0.8341
Epoch 49 Global_step 4047000	Train_loss: 0.1386	Eval_AUC: 0.8353
Epoch 49 Global_step 4048000	Train_loss: 0.1406	Eval_AUC: 0.8333
Epoch 49 Global_step 4049000	Train_loss: 0.1392	Eval_AUC: 0.8288
Epoch 49 Global_step 4050000	Train_loss: 0.1395	Eval_AUC: 0.8301
Epoch 49 Global_step 4051000	Train_loss: 0.1392	Eval_AUC: 0.8316
Epoch 49 Global_step 4052000	Train_loss: 0.1380	Eval_AUC: 0.8349
Epoch 49 Global_step 4053000	Train_loss: 0.1399	Eval_AUC: 0.8254
Epoch 49 Global_step 4054000	Train_loss: 0.1400	Eval_AUC: 0.8332
Epoch 49 Global_step 4055000	Train_loss: 0.1424	Eval_AUC: 0.8335
Epoch 49 Global_step 4056000	Train_loss: 0.1398	Eval_AUC: 0.8295
Epoch 49 Global_step 4057000	Train_loss: 0.1410	Eval_AUC: 0.8347
Epoch 49 Global_step 4058000	Train_loss: 0.1407	Eval_AUC: 0.8315
Epoch 49 Global_step 4059000	Train_loss: 0.1411	Eval_AUC: 0.8310
Epoch 49 Global_step 4060000	Train_loss: 0.1395	Eval_AUC: 0.8280
Epoch 49 Global_step 4061000	Train_loss: 0.1417	Eval_AUC: 0.8309
Epoch 49 Global_step 4062000	Train_loss: 0.1398	Eval_AUC: 0.8303
Epoch 49 Global_step 4063000	Train_loss: 0.1415	Eval_AUC: 0.8321
Epoch 49 Global_step 4064000	Train_loss: 0.1398	Eval_AUC: 0.8283
Epoch 49 Global_step 4065000	Train_loss: 0.1394	Eval_AUC: 0.8305
Epoch 49 Global_step 4066000	Train_loss: 0.1446	Eval_AUC: 0.8369
Epoch 49 Global_step 4067000	Train_loss: 0.1441	Eval_AUC: 0.8284
Epoch 49 Global_step 4068000	Train_loss: 0.1410	Eval_AUC: 0.8336
Epoch 49 Global_step 4069000	Train_loss: 0.1425	Eval_AUC: 0.8349
Epoch 49 Global_step 4070000	Train_loss: 0.1426	Eval_AUC: 0.8341
Epoch 49 Global_step 4071000	Train_loss: 0.1422	Eval_AUC: 0.8321
Epoch 49 Global_step 4072000	Train_loss: 0.1436	Eval_AUC: 0.8341
Epoch 49 Global_step 4073000	Train_loss: 0.1418	Eval_AUC: 0.8277
Epoch 49 Global_step 4074000	Train_loss: 0.1458	Eval_AUC: 0.8320
Epoch 49 Global_step 4075000	Train_loss: 0.1438	Eval_AUC: 0.8294
Epoch 49 Global_step 4076000	Train_loss: 0.1453	Eval_AUC: 0.8324
Epoch 49 DONE	Cost time: 377836.28
model saved at save_path/atrank-4076200
('best test_auc:', 0.88181577210334561)
Finished

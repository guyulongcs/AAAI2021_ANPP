RuntimeError: module compiled against API version 0xc but this version of numpy is 0xb
RuntimeError: module compiled against API version 0xc but this version of numpy is 0xb
2018-06-12 22:11:22.064055: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-06-12 22:11:24.957728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: Tesla P40 major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:02:00.0
totalMemory: 22.38GiB freeMemory: 16.38GiB
2018-06-12 22:11:24.957787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-06-12 22:11:25.314408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-12 22:11:25.314468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-06-12 22:11:25.314477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-06-12 22:11:25.314904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15880 MB memory) -> physical GPU (device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1)
test_auc: 0.4973
Epoch 0 Global_step 1000	Train_loss: 0.6788	Eval_AUC: 0.6240
Epoch 0 Global_step 2000	Train_loss: 0.6691	Eval_AUC: 0.6592
Epoch 0 Global_step 3000	Train_loss: 0.6463	Eval_AUC: 0.7121
Epoch 0 Global_step 4000	Train_loss: 0.6151	Eval_AUC: 0.7427
Epoch 0 Global_step 5000	Train_loss: 0.5965	Eval_AUC: 0.7690
Epoch 0 Global_step 6000	Train_loss: 0.5813	Eval_AUC: 0.7728
Epoch 0 Global_step 7000	Train_loss: 0.5687	Eval_AUC: 0.7784
Epoch 0 Global_step 8000	Train_loss: 0.5640	Eval_AUC: 0.7929
Epoch 0 Global_step 9000	Train_loss: 0.5587	Eval_AUC: 0.7914
Epoch 0 Global_step 10000	Train_loss: 0.5513	Eval_AUC: 0.7991
Epoch 0 Global_step 11000	Train_loss: 0.5418	Eval_AUC: 0.8027
Epoch 0 Global_step 12000	Train_loss: 0.5445	Eval_AUC: 0.8019
Epoch 0 Global_step 13000	Train_loss: 0.5394	Eval_AUC: 0.8069
Epoch 0 Global_step 14000	Train_loss: 0.5365	Eval_AUC: 0.8092
Epoch 0 Global_step 15000	Train_loss: 0.5294	Eval_AUC: 0.8071
Epoch 0 Global_step 16000	Train_loss: 0.5308	Eval_AUC: 0.8137
Epoch 0 Global_step 17000	Train_loss: 0.5275	Eval_AUC: 0.8158
Epoch 0 Global_step 18000	Train_loss: 0.5295	Eval_AUC: 0.8113
Epoch 0 Global_step 19000	Train_loss: 0.5240	Eval_AUC: 0.8192
Epoch 0 Global_step 20000	Train_loss: 0.5179	Eval_AUC: 0.8182
Epoch 0 Global_step 21000	Train_loss: 0.5225	Eval_AUC: 0.8137
Epoch 0 Global_step 22000	Train_loss: 0.5214	Eval_AUC: 0.8177
Epoch 0 Global_step 23000	Train_loss: 0.5167	Eval_AUC: 0.8203
Epoch 0 Global_step 24000	Train_loss: 0.5221	Eval_AUC: 0.8206
Epoch 0 Global_step 25000	Train_loss: 0.5161	Eval_AUC: 0.8215
Epoch 0 Global_step 26000	Train_loss: 0.5173	Eval_AUC: 0.8188
Epoch 0 Global_step 27000	Train_loss: 0.5108	Eval_AUC: 0.8215
Epoch 0 Global_step 28000	Train_loss: 0.5158	Eval_AUC: 0.8184
Epoch 0 Global_step 29000	Train_loss: 0.5118	Eval_AUC: 0.8237
Epoch 0 Global_step 30000	Train_loss: 0.5117	Eval_AUC: 0.8225
Epoch 0 Global_step 31000	Train_loss: 0.5141	Eval_AUC: 0.8238
Epoch 0 Global_step 32000	Train_loss: 0.5133	Eval_AUC: 0.8250
Epoch 0 Global_step 33000	Train_loss: 0.5111	Eval_AUC: 0.8237
Epoch 0 Global_step 34000	Train_loss: 0.5053	Eval_AUC: 0.8285
Epoch 0 Global_step 35000	Train_loss: 0.5086	Eval_AUC: 0.8276
Epoch 0 Global_step 36000	Train_loss: 0.5084	Eval_AUC: 0.8240
Epoch 0 Global_step 37000	Train_loss: 0.5109	Eval_AUC: 0.8267
Epoch 0 Global_step 38000	Train_loss: 0.5045	Eval_AUC: 0.8266
Epoch 0 Global_step 39000	Train_loss: 0.5080	Eval_AUC: 0.8288
Epoch 0 Global_step 40000	Train_loss: 0.5046	Eval_AUC: 0.8304
Epoch 0 Global_step 41000	Train_loss: 0.5002	Eval_AUC: 0.8292
Epoch 0 Global_step 42000	Train_loss: 0.5034	Eval_AUC: 0.8286
Epoch 0 Global_step 43000	Train_loss: 0.5022	Eval_AUC: 0.8244
Epoch 0 Global_step 44000	Train_loss: 0.5029	Eval_AUC: 0.8314
Epoch 0 Global_step 45000	Train_loss: 0.4994	Eval_AUC: 0.8253
Epoch 0 Global_step 46000	Train_loss: 0.5055	Eval_AUC: 0.8262
Epoch 0 Global_step 47000	Train_loss: 0.4979	Eval_AUC: 0.8336
Epoch 0 Global_step 48000	Train_loss: 0.4994	Eval_AUC: 0.8325
Epoch 0 Global_step 49000	Train_loss: 0.4982	Eval_AUC: 0.8310
Epoch 0 Global_step 50000	Train_loss: 0.4990	Eval_AUC: 0.8324
Epoch 0 Global_step 51000	Train_loss: 0.4972	Eval_AUC: 0.8341
Epoch 0 Global_step 52000	Train_loss: 0.4973	Eval_AUC: 0.8335
Epoch 0 Global_step 53000	Train_loss: 0.4946	Eval_AUC: 0.8306
Epoch 0 Global_step 54000	Train_loss: 0.4914	Eval_AUC: 0.8370
Epoch 0 Global_step 55000	Train_loss: 0.4947	Eval_AUC: 0.8339
Epoch 0 Global_step 56000	Train_loss: 0.4886	Eval_AUC: 0.8345
Epoch 0 Global_step 57000	Train_loss: 0.4944	Eval_AUC: 0.8290
Epoch 0 Global_step 58000	Train_loss: 0.4921	Eval_AUC: 0.8368
Epoch 0 Global_step 59000	Train_loss: 0.4921	Eval_AUC: 0.8350
Epoch 0 Global_step 60000	Train_loss: 0.4912	Eval_AUC: 0.8368
Epoch 0 Global_step 61000	Train_loss: 0.4902	Eval_AUC: 0.8363
Epoch 0 Global_step 62000	Train_loss: 0.4903	Eval_AUC: 0.8392
Epoch 0 Global_step 63000	Train_loss: 0.4897	Eval_AUC: 0.8366
Epoch 0 Global_step 64000	Train_loss: 0.4895	Eval_AUC: 0.8379
Epoch 0 Global_step 65000	Train_loss: 0.4876	Eval_AUC: 0.8399
Epoch 0 Global_step 66000	Train_loss: 0.4894	Eval_AUC: 0.8383
Epoch 0 Global_step 67000	Train_loss: 0.4868	Eval_AUC: 0.8412
Epoch 0 Global_step 68000	Train_loss: 0.4864	Eval_AUC: 0.8371
Epoch 0 Global_step 69000	Train_loss: 0.4841	Eval_AUC: 0.8403
Epoch 0 Global_step 70000	Train_loss: 0.4834	Eval_AUC: 0.8419
Epoch 0 Global_step 71000	Train_loss: 0.4852	Eval_AUC: 0.8428
Epoch 0 Global_step 72000	Train_loss: 0.4833	Eval_AUC: 0.8439
Epoch 0 Global_step 73000	Train_loss: 0.4807	Eval_AUC: 0.8433
Epoch 0 Global_step 74000	Train_loss: 0.4792	Eval_AUC: 0.8444
Epoch 0 Global_step 75000	Train_loss: 0.4847	Eval_AUC: 0.8447
Epoch 0 Global_step 76000	Train_loss: 0.4815	Eval_AUC: 0.8468
Epoch 0 Global_step 77000	Train_loss: 0.4793	Eval_AUC: 0.8425
Epoch 0 Global_step 78000	Train_loss: 0.4756	Eval_AUC: 0.8480
Epoch 0 Global_step 79000	Train_loss: 0.4759	Eval_AUC: 0.8448
Epoch 0 Global_step 80000	Train_loss: 0.4738	Eval_AUC: 0.8466
Epoch 0 Global_step 81000	Train_loss: 0.4781	Eval_AUC: 0.8429
Epoch 0 DONE	Cost time: 14991.94
Epoch 1 Global_step 82000	Train_loss: 0.2142	Eval_AUC: 0.8514
Epoch 1 Global_step 83000	Train_loss: 0.4479	Eval_AUC: 0.8443
Epoch 1 Global_step 84000	Train_loss: 0.4509	Eval_AUC: 0.8466
Epoch 1 Global_step 85000	Train_loss: 0.4532	Eval_AUC: 0.8472
Epoch 1 Global_step 86000	Train_loss: 0.4511	Eval_AUC: 0.8471
Epoch 1 Global_step 87000	Train_loss: 0.4488	Eval_AUC: 0.8462
Epoch 1 Global_step 88000	Train_loss: 0.4532	Eval_AUC: 0.8500
Epoch 1 Global_step 89000	Train_loss: 0.4522	Eval_AUC: 0.8491
Epoch 1 Global_step 90000	Train_loss: 0.4503	Eval_AUC: 0.8448
Epoch 1 Global_step 91000	Train_loss: 0.4546	Eval_AUC: 0.8501
Epoch 1 Global_step 92000	Train_loss: 0.4522	Eval_AUC: 0.8519
Epoch 1 Global_step 93000	Train_loss: 0.4498	Eval_AUC: 0.8504
Epoch 1 Global_step 94000	Train_loss: 0.4489	Eval_AUC: 0.8515
Epoch 1 Global_step 95000	Train_loss: 0.4560	Eval_AUC: 0.8484
Epoch 1 Global_step 96000	Train_loss: 0.4482	Eval_AUC: 0.8495
Epoch 1 Global_step 97000	Train_loss: 0.4542	Eval_AUC: 0.8489
Epoch 1 Global_step 98000	Train_loss: 0.4507	Eval_AUC: 0.8493
Epoch 1 Global_step 99000	Train_loss: 0.4526	Eval_AUC: 0.8472
Epoch 1 Global_step 100000	Train_loss: 0.4532	Eval_AUC: 0.8518
Epoch 1 Global_step 101000	Train_loss: 0.4559	Eval_AUC: 0.8539
Epoch 1 Global_step 102000	Train_loss: 0.4523	Eval_AUC: 0.8524
Epoch 1 Global_step 103000	Train_loss: 0.4496	Eval_AUC: 0.8535
Epoch 1 Global_step 104000	Train_loss: 0.4496	Eval_AUC: 0.8539
Epoch 1 Global_step 105000	Train_loss: 0.4489	Eval_AUC: 0.8539
Epoch 1 Global_step 106000	Train_loss: 0.4538	Eval_AUC: 0.8544
Epoch 1 Global_step 107000	Train_loss: 0.4507	Eval_AUC: 0.8563
Epoch 1 Global_step 108000	Train_loss: 0.4516	Eval_AUC: 0.8505
Epoch 1 Global_step 109000	Train_loss: 0.4515	Eval_AUC: 0.8535
Epoch 1 Global_step 110000	Train_loss: 0.4536	Eval_AUC: 0.8567
Epoch 1 Global_step 111000	Train_loss: 0.4551	Eval_AUC: 0.8557
Epoch 1 Global_step 112000	Train_loss: 0.4513	Eval_AUC: 0.8551
Epoch 1 Global_step 113000	Train_loss: 0.4516	Eval_AUC: 0.8571
Epoch 1 Global_step 114000	Train_loss: 0.4552	Eval_AUC: 0.8550
Epoch 1 Global_step 115000	Train_loss: 0.4528	Eval_AUC: 0.8548
Epoch 1 Global_step 116000	Train_loss: 0.4488	Eval_AUC: 0.8529
Epoch 1 Global_step 117000	Train_loss: 0.4462	Eval_AUC: 0.8558
Epoch 1 Global_step 118000	Train_loss: 0.4570	Eval_AUC: 0.8540
Epoch 1 Global_step 119000	Train_loss: 0.4561	Eval_AUC: 0.8509
Epoch 1 Global_step 120000	Train_loss: 0.4487	Eval_AUC: 0.8587
Epoch 1 Global_step 121000	Train_loss: 0.4480	Eval_AUC: 0.8607
Epoch 1 Global_step 122000	Train_loss: 0.4537	Eval_AUC: 0.8585
Epoch 1 Global_step 123000	Train_loss: 0.4477	Eval_AUC: 0.8604
Epoch 1 Global_step 124000	Train_loss: 0.4516	Eval_AUC: 0.8588
Epoch 1 Global_step 125000	Train_loss: 0.4493	Eval_AUC: 0.8575
Epoch 1 Global_step 126000	Train_loss: 0.4494	Eval_AUC: 0.8578
Epoch 1 Global_step 127000	Train_loss: 0.4530	Eval_AUC: 0.8587
Epoch 1 Global_step 128000	Train_loss: 0.4466	Eval_AUC: 0.8560
Epoch 1 Global_step 129000	Train_loss: 0.4477	Eval_AUC: 0.8576
Epoch 1 Global_step 130000	Train_loss: 0.4465	Eval_AUC: 0.8579
Epoch 1 Global_step 131000	Train_loss: 0.4463	Eval_AUC: 0.8605
Epoch 1 Global_step 132000	Train_loss: 0.4531	Eval_AUC: 0.8639
Epoch 1 Global_step 133000	Train_loss: 0.4449	Eval_AUC: 0.8573
Epoch 1 Global_step 134000	Train_loss: 0.4454	Eval_AUC: 0.8569
Epoch 1 Global_step 135000	Train_loss: 0.4438	Eval_AUC: 0.8580
Epoch 1 Global_step 136000	Train_loss: 0.4485	Eval_AUC: 0.8605
Epoch 1 Global_step 137000	Train_loss: 0.4493	Eval_AUC: 0.8637
Epoch 1 Global_step 138000	Train_loss: 0.4432	Eval_AUC: 0.8616
Epoch 1 Global_step 139000	Train_loss: 0.4431	Eval_AUC: 0.8631
Epoch 1 Global_step 140000	Train_loss: 0.4508	Eval_AUC: 0.8605
Epoch 1 Global_step 141000	Train_loss: 0.4442	Eval_AUC: 0.8607
Epoch 1 Global_step 142000	Train_loss: 0.4469	Eval_AUC: 0.8591
Epoch 1 Global_step 143000	Train_loss: 0.4447	Eval_AUC: 0.8586
Epoch 1 Global_step 144000	Train_loss: 0.4413	Eval_AUC: 0.8604
Epoch 1 Global_step 145000	Train_loss: 0.4424	Eval_AUC: 0.8627
Epoch 1 Global_step 146000	Train_loss: 0.4459	Eval_AUC: 0.8573
Epoch 1 Global_step 147000	Train_loss: 0.4386	Eval_AUC: 0.8571
Epoch 1 Global_step 148000	Train_loss: 0.4514	Eval_AUC: 0.8590
Epoch 1 Global_step 149000	Train_loss: 0.4416	Eval_AUC: 0.8617
Epoch 1 Global_step 150000	Train_loss: 0.4432	Eval_AUC: 0.8613
Epoch 1 Global_step 151000	Train_loss: 0.4424	Eval_AUC: 0.8620
Epoch 1 Global_step 152000	Train_loss: 0.4431	Eval_AUC: 0.8669
Epoch 1 Global_step 153000	Train_loss: 0.4424	Eval_AUC: 0.8646
Epoch 1 Global_step 154000	Train_loss: 0.4483	Eval_AUC: 0.8651
Epoch 1 Global_step 155000	Train_loss: 0.4432	Eval_AUC: 0.8646
Epoch 1 Global_step 156000	Train_loss: 0.4420	Eval_AUC: 0.8633
Epoch 1 Global_step 157000	Train_loss: 0.4429	Eval_AUC: 0.8615
Epoch 1 Global_step 158000	Train_loss: 0.4427	Eval_AUC: 0.8609
Epoch 1 Global_step 159000	Train_loss: 0.4369	Eval_AUC: 0.8624
Epoch 1 Global_step 160000	Train_loss: 0.4433	Eval_AUC: 0.8629
Epoch 1 Global_step 161000	Train_loss: 0.4415	Eval_AUC: 0.8627
Epoch 1 Global_step 162000	Train_loss: 0.4471	Eval_AUC: 0.8611
Epoch 1 Global_step 163000	Train_loss: 0.4417	Eval_AUC: 0.8674
Epoch 1 DONE	Cost time: 29617.26
Epoch 2 Global_step 164000	Train_loss: 0.3888	Eval_AUC: 0.8620
Epoch 2 Global_step 165000	Train_loss: 0.4073	Eval_AUC: 0.8650
Epoch 2 Global_step 166000	Train_loss: 0.4056	Eval_AUC: 0.8667
Epoch 2 Global_step 167000	Train_loss: 0.4117	Eval_AUC: 0.8633
Epoch 2 Global_step 168000	Train_loss: 0.4061	Eval_AUC: 0.8642
Epoch 2 Global_step 169000	Train_loss: 0.4094	Eval_AUC: 0.8682
Epoch 2 Global_step 170000	Train_loss: 0.4105	Eval_AUC: 0.8618
Epoch 2 Global_step 171000	Train_loss: 0.4054	Eval_AUC: 0.8667
Epoch 2 Global_step 172000	Train_loss: 0.4105	Eval_AUC: 0.8653
Epoch 2 Global_step 173000	Train_loss: 0.4090	Eval_AUC: 0.8625
Epoch 2 Global_step 174000	Train_loss: 0.4084	Eval_AUC: 0.8637
Epoch 2 Global_step 175000	Train_loss: 0.4155	Eval_AUC: 0.8623
Epoch 2 Global_step 176000	Train_loss: 0.4112	Eval_AUC: 0.8638
Epoch 2 Global_step 177000	Train_loss: 0.4100	Eval_AUC: 0.8664
Epoch 2 Global_step 178000	Train_loss: 0.4127	Eval_AUC: 0.8598
Epoch 2 Global_step 179000	Train_loss: 0.4092	Eval_AUC: 0.8641
Epoch 2 Global_step 180000	Train_loss: 0.4116	Eval_AUC: 0.8595
Epoch 2 Global_step 181000	Train_loss: 0.4170	Eval_AUC: 0.8632
Epoch 2 Global_step 182000	Train_loss: 0.4129	Eval_AUC: 0.8647
Epoch 2 Global_step 183000	Train_loss: 0.4154	Eval_AUC: 0.8662
Epoch 2 Global_step 184000	Train_loss: 0.4139	Eval_AUC: 0.8674
Epoch 2 Global_step 185000	Train_loss: 0.4197	Eval_AUC: 0.8650
Epoch 2 Global_step 186000	Train_loss: 0.4164	Eval_AUC: 0.8650
Epoch 2 Global_step 187000	Train_loss: 0.4148	Eval_AUC: 0.8627
Epoch 2 Global_step 188000	Train_loss: 0.4160	Eval_AUC: 0.8623
Epoch 2 Global_step 189000	Train_loss: 0.4156	Eval_AUC: 0.8625
Epoch 2 Global_step 190000	Train_loss: 0.4222	Eval_AUC: 0.8679
Epoch 2 Global_step 191000	Train_loss: 0.4208	Eval_AUC: 0.8656
Epoch 2 Global_step 192000	Train_loss: 0.4210	Eval_AUC: 0.8654
Epoch 2 Global_step 193000	Train_loss: 0.4155	Eval_AUC: 0.8678
Epoch 2 Global_step 194000	Train_loss: 0.4226	Eval_AUC: 0.8636
Epoch 2 Global_step 195000	Train_loss: 0.4160	Eval_AUC: 0.8659
Epoch 2 Global_step 196000	Train_loss: 0.4185	Eval_AUC: 0.8615
Epoch 2 Global_step 197000	Train_loss: 0.4160	Eval_AUC: 0.8630
Epoch 2 Global_step 198000	Train_loss: 0.4236	Eval_AUC: 0.8632
Epoch 2 Global_step 199000	Train_loss: 0.4149	Eval_AUC: 0.8676
Epoch 2 Global_step 200000	Train_loss: 0.4152	Eval_AUC: 0.8625
Epoch 2 Global_step 201000	Train_loss: 0.4191	Eval_AUC: 0.8617
Epoch 2 Global_step 202000	Train_loss: 0.4255	Eval_AUC: 0.8678
Epoch 2 Global_step 203000	Train_loss: 0.4204	Eval_AUC: 0.8642
Epoch 2 Global_step 204000	Train_loss: 0.4189	Eval_AUC: 0.8673
Epoch 2 Global_step 205000	Train_loss: 0.4219	Eval_AUC: 0.8647
Epoch 2 Global_step 206000	Train_loss: 0.4133	Eval_AUC: 0.8626
Epoch 2 Global_step 207000	Train_loss: 0.4211	Eval_AUC: 0.8676
Epoch 2 Global_step 208000	Train_loss: 0.4215	Eval_AUC: 0.8635
Epoch 2 Global_step 209000	Train_loss: 0.4143	Eval_AUC: 0.8671
Epoch 2 Global_step 210000	Train_loss: 0.4210	Eval_AUC: 0.8618
Epoch 2 Global_step 211000	Train_loss: 0.4179	Eval_AUC: 0.8654
Epoch 2 Global_step 212000	Train_loss: 0.4144	Eval_AUC: 0.8688
Epoch 2 Global_step 213000	Train_loss: 0.4147	Eval_AUC: 0.8649
Epoch 2 Global_step 214000	Train_loss: 0.4254	Eval_AUC: 0.8698
Epoch 2 Global_step 215000	Train_loss: 0.4178	Eval_AUC: 0.8685
Epoch 2 Global_step 216000	Train_loss: 0.4197	Eval_AUC: 0.8681
Epoch 2 Global_step 217000	Train_loss: 0.4189	Eval_AUC: 0.8698
Epoch 2 Global_step 218000	Train_loss: 0.4220	Eval_AUC: 0.8700
Epoch 2 Global_step 219000	Train_loss: 0.4225	Eval_AUC: 0.8718
Epoch 2 Global_step 220000	Train_loss: 0.4157	Eval_AUC: 0.8680
Epoch 2 Global_step 221000	Train_loss: 0.4203	Eval_AUC: 0.8677
Epoch 2 Global_step 222000	Train_loss: 0.4245	Eval_AUC: 0.8705
Epoch 2 Global_step 223000	Train_loss: 0.4201	Eval_AUC: 0.8703
Epoch 2 Global_step 224000	Train_loss: 0.4199	Eval_AUC: 0.8686
Epoch 2 Global_step 225000	Train_loss: 0.4230	Eval_AUC: 0.8679
Epoch 2 Global_step 226000	Train_loss: 0.4204	Eval_AUC: 0.8657
Epoch 2 Global_step 227000	Train_loss: 0.4210	Eval_AUC: 0.8683
Epoch 2 Global_step 228000	Train_loss: 0.4202	Eval_AUC: 0.8677
Epoch 2 Global_step 229000	Train_loss: 0.4246	Eval_AUC: 0.8704
Epoch 2 Global_step 230000	Train_loss: 0.4197	Eval_AUC: 0.8708
Epoch 2 Global_step 231000	Train_loss: 0.4172	Eval_AUC: 0.8611
Epoch 2 Global_step 232000	Train_loss: 0.4254	Eval_AUC: 0.8721
Epoch 2 Global_step 233000	Train_loss: 0.4158	Eval_AUC: 0.8658
Epoch 2 Global_step 234000	Train_loss: 0.4216	Eval_AUC: 0.8674
Epoch 2 Global_step 235000	Train_loss: 0.4163	Eval_AUC: 0.8669
Epoch 2 Global_step 236000	Train_loss: 0.4179	Eval_AUC: 0.8709
Epoch 2 Global_step 237000	Train_loss: 0.4209	Eval_AUC: 0.8690
Epoch 2 Global_step 238000	Train_loss: 0.4162	Eval_AUC: 0.8685
Epoch 2 Global_step 239000	Train_loss: 0.4208	Eval_AUC: 0.8694
Epoch 2 Global_step 240000	Train_loss: 0.4236	Eval_AUC: 0.8704
Epoch 2 Global_step 241000	Train_loss: 0.4189	Eval_AUC: 0.8732
Epoch 2 Global_step 242000	Train_loss: 0.4246	Eval_AUC: 0.8754
Epoch 2 Global_step 243000	Train_loss: 0.4134	Eval_AUC: 0.8695
Epoch 2 Global_step 244000	Train_loss: 0.4177	Eval_AUC: 0.8709
Epoch 2 DONE	Cost time: 40605.67
Epoch 3 Global_step 245000	Train_loss: 0.1587	Eval_AUC: 0.8718
Epoch 3 Global_step 246000	Train_loss: 0.3752	Eval_AUC: 0.8722
Epoch 3 Global_step 247000	Train_loss: 0.3699	Eval_AUC: 0.8684
Epoch 3 Global_step 248000	Train_loss: 0.3775	Eval_AUC: 0.8691
Epoch 3 Global_step 249000	Train_loss: 0.3725	Eval_AUC: 0.8634
Epoch 3 Global_step 250000	Train_loss: 0.3803	Eval_AUC: 0.8713
Epoch 3 Global_step 251000	Train_loss: 0.3774	Eval_AUC: 0.8687
Epoch 3 Global_step 252000	Train_loss: 0.3780	Eval_AUC: 0.8696
Epoch 3 Global_step 253000	Train_loss: 0.3757	Eval_AUC: 0.8698
Epoch 3 Global_step 254000	Train_loss: 0.3812	Eval_AUC: 0.8686
Epoch 3 Global_step 255000	Train_loss: 0.3774	Eval_AUC: 0.8661
Epoch 3 Global_step 256000	Train_loss: 0.3842	Eval_AUC: 0.8671
Epoch 3 Global_step 257000	Train_loss: 0.3842	Eval_AUC: 0.8688
Epoch 3 Global_step 258000	Train_loss: 0.3806	Eval_AUC: 0.8702
Epoch 3 Global_step 259000	Train_loss: 0.3840	Eval_AUC: 0.8693
Epoch 3 Global_step 260000	Train_loss: 0.3785	Eval_AUC: 0.8623
Epoch 3 Global_step 261000	Train_loss: 0.3816	Eval_AUC: 0.8685
Epoch 3 Global_step 262000	Train_loss: 0.3848	Eval_AUC: 0.8718
Epoch 3 Global_step 263000	Train_loss: 0.3829	Eval_AUC: 0.8634
Epoch 3 Global_step 264000	Train_loss: 0.3845	Eval_AUC: 0.8697
Epoch 3 Global_step 265000	Train_loss: 0.3858	Eval_AUC: 0.8645
Epoch 3 Global_step 266000	Train_loss: 0.3859	Eval_AUC: 0.8714
Epoch 3 Global_step 267000	Train_loss: 0.3899	Eval_AUC: 0.8700
Epoch 3 Global_step 268000	Train_loss: 0.3867	Eval_AUC: 0.8700
Epoch 3 Global_step 269000	Train_loss: 0.3938	Eval_AUC: 0.8683
Epoch 3 Global_step 270000	Train_loss: 0.3893	Eval_AUC: 0.8681
Epoch 3 Global_step 271000	Train_loss: 0.3871	Eval_AUC: 0.8667
Epoch 3 Global_step 272000	Train_loss: 0.3860	Eval_AUC: 0.8684
Epoch 3 Global_step 273000	Train_loss: 0.3897	Eval_AUC: 0.8690
Epoch 3 Global_step 274000	Train_loss: 0.3904	Eval_AUC: 0.8691
Epoch 3 Global_step 275000	Train_loss: 0.3939	Eval_AUC: 0.8671
Epoch 3 Global_step 276000	Train_loss: 0.3898	Eval_AUC: 0.8680
Epoch 3 Global_step 277000	Train_loss: 0.3900	Eval_AUC: 0.8678
Epoch 3 Global_step 278000	Train_loss: 0.3950	Eval_AUC: 0.8695
Epoch 3 Global_step 279000	Train_loss: 0.3875	Eval_AUC: 0.8684
Epoch 3 Global_step 280000	Train_loss: 0.3911	Eval_AUC: 0.8716
Epoch 3 Global_step 281000	Train_loss: 0.3880	Eval_AUC: 0.8712
Epoch 3 Global_step 282000	Train_loss: 0.3954	Eval_AUC: 0.8666
Epoch 3 Global_step 283000	Train_loss: 0.3944	Eval_AUC: 0.8696
Epoch 3 Global_step 284000	Train_loss: 0.3927	Eval_AUC: 0.8664
Epoch 3 Global_step 285000	Train_loss: 0.3939	Eval_AUC: 0.8715
Epoch 3 Global_step 286000	Train_loss: 0.3948	Eval_AUC: 0.8694
Epoch 3 Global_step 287000	Train_loss: 0.3905	Eval_AUC: 0.8685
Epoch 3 Global_step 288000	Train_loss: 0.3975	Eval_AUC: 0.8686
Epoch 3 Global_step 289000	Train_loss: 0.3976	Eval_AUC: 0.8715
Epoch 3 Global_step 290000	Train_loss: 0.3916	Eval_AUC: 0.8709
Epoch 3 Global_step 291000	Train_loss: 0.3936	Eval_AUC: 0.8707
Epoch 3 Global_step 292000	Train_loss: 0.3892	Eval_AUC: 0.8699
Epoch 3 Global_step 293000	Train_loss: 0.3914	Eval_AUC: 0.8689
Epoch 3 Global_step 294000	Train_loss: 0.3992	Eval_AUC: 0.8731
Epoch 3 Global_step 295000	Train_loss: 0.3994	Eval_AUC: 0.8697
Epoch 3 Global_step 296000	Train_loss: 0.3980	Eval_AUC: 0.8714
Epoch 3 Global_step 297000	Train_loss: 0.3915	Eval_AUC: 0.8708
Epoch 3 Global_step 298000	Train_loss: 0.3943	Eval_AUC: 0.8681
Epoch 3 Global_step 299000	Train_loss: 0.3939	Eval_AUC: 0.8673
Epoch 3 Global_step 300000	Train_loss: 0.3933	Eval_AUC: 0.8708
Epoch 3 Global_step 301000	Train_loss: 0.3935	Eval_AUC: 0.8679
Epoch 3 Global_step 302000	Train_loss: 0.3916	Eval_AUC: 0.8703
Epoch 3 Global_step 303000	Train_loss: 0.3984	Eval_AUC: 0.8700
Epoch 3 Global_step 304000	Train_loss: 0.4001	Eval_AUC: 0.8689
Epoch 3 Global_step 305000	Train_loss: 0.4000	Eval_AUC: 0.8681
Epoch 3 Global_step 306000	Train_loss: 0.3931	Eval_AUC: 0.8689
Epoch 3 Global_step 307000	Train_loss: 0.4021	Eval_AUC: 0.8689
Epoch 3 Global_step 308000	Train_loss: 0.3984	Eval_AUC: 0.8688
Epoch 3 Global_step 309000	Train_loss: 0.3984	Eval_AUC: 0.8726
Epoch 3 Global_step 310000	Train_loss: 0.4012	Eval_AUC: 0.8709
Epoch 3 Global_step 311000	Train_loss: 0.4016	Eval_AUC: 0.8697
Epoch 3 Global_step 312000	Train_loss: 0.4038	Eval_AUC: 0.8735
Epoch 3 Global_step 313000	Train_loss: 0.3945	Eval_AUC: 0.8723
Epoch 3 Global_step 314000	Train_loss: 0.4025	Eval_AUC: 0.8690
Epoch 3 Global_step 315000	Train_loss: 0.3978	Eval_AUC: 0.8736
Epoch 3 Global_step 316000	Train_loss: 0.3993	Eval_AUC: 0.8710
Epoch 3 Global_step 317000	Train_loss: 0.3961	Eval_AUC: 0.8694
Epoch 3 Global_step 318000	Train_loss: 0.3972	Eval_AUC: 0.8732
Epoch 3 Global_step 319000	Train_loss: 0.3998	Eval_AUC: 0.8723
Epoch 3 Global_step 320000	Train_loss: 0.3976	Eval_AUC: 0.8701
Epoch 3 Global_step 321000	Train_loss: 0.4048	Eval_AUC: 0.8708
Epoch 3 Global_step 322000	Train_loss: 0.4035	Eval_AUC: 0.8714
Epoch 3 Global_step 323000	Train_loss: 0.4016	Eval_AUC: 0.8709
Epoch 3 Global_step 324000	Train_loss: 0.4038	Eval_AUC: 0.8759
Epoch 3 Global_step 325000	Train_loss: 0.4034	Eval_AUC: 0.8717
Epoch 3 Global_step 326000	Train_loss: 0.4030	Eval_AUC: 0.8725
Epoch 3 DONE	Cost time: 54190.78
Epoch 4 Global_step 327000	Train_loss: 0.3042	Eval_AUC: 0.8741
Epoch 4 Global_step 328000	Train_loss: 0.3327	Eval_AUC: 0.8669
Epoch 4 Global_step 329000	Train_loss: 0.3322	Eval_AUC: 0.8691
Epoch 4 Global_step 330000	Train_loss: 0.3383	Eval_AUC: 0.8661
Epoch 4 Global_step 331000	Train_loss: 0.3331	Eval_AUC: 0.8689
Epoch 4 Global_step 332000	Train_loss: 0.3364	Eval_AUC: 0.8677
Epoch 4 Global_step 333000	Train_loss: 0.3357	Eval_AUC: 0.8665
Epoch 4 Global_step 334000	Train_loss: 0.3427	Eval_AUC: 0.8651
Epoch 4 Global_step 335000	Train_loss: 0.3386	Eval_AUC: 0.8650
Epoch 4 Global_step 336000	Train_loss: 0.3430	Eval_AUC: 0.8687
Epoch 4 Global_step 337000	Train_loss: 0.3384	Eval_AUC: 0.8676
Epoch 4 Global_step 338000	Train_loss: 0.3409	Eval_AUC: 0.8692
Epoch 4 Global_step 339000	Train_loss: 0.3379	Eval_AUC: 0.8688
Epoch 4 Global_step 340000	Train_loss: 0.3340	Eval_AUC: 0.8699
Epoch 4 Global_step 341000	Train_loss: 0.3349	Eval_AUC: 0.8686
Epoch 4 Global_step 342000	Train_loss: 0.3337	Eval_AUC: 0.8687
Epoch 4 Global_step 343000	Train_loss: 0.3347	Eval_AUC: 0.8701
Epoch 4 Global_step 344000	Train_loss: 0.3343	Eval_AUC: 0.8705
Epoch 4 Global_step 345000	Train_loss: 0.3340	Eval_AUC: 0.8695
Epoch 4 Global_step 346000	Train_loss: 0.3363	Eval_AUC: 0.8697
Epoch 4 Global_step 347000	Train_loss: 0.3329	Eval_AUC: 0.8686
Epoch 4 Global_step 348000	Train_loss: 0.3366	Eval_AUC: 0.8695
Epoch 4 Global_step 349000	Train_loss: 0.3298	Eval_AUC: 0.8705
Epoch 4 Global_step 350000	Train_loss: 0.3263	Eval_AUC: 0.8698
Epoch 4 Global_step 351000	Train_loss: 0.3306	Eval_AUC: 0.8701
Epoch 4 Global_step 352000	Train_loss: 0.3323	Eval_AUC: 0.8703
Epoch 4 Global_step 353000	Train_loss: 0.3294	Eval_AUC: 0.8699
Epoch 4 Global_step 354000	Train_loss: 0.3311	Eval_AUC: 0.8689
Epoch 4 Global_step 355000	Train_loss: 0.3322	Eval_AUC: 0.8696
Epoch 4 Global_step 356000	Train_loss: 0.3341	Eval_AUC: 0.8687
Epoch 4 Global_step 357000	Train_loss: 0.3352	Eval_AUC: 0.8700
Epoch 4 Global_step 358000	Train_loss: 0.3328	Eval_AUC: 0.8697
Epoch 4 Global_step 359000	Train_loss: 0.3279	Eval_AUC: 0.8697
Epoch 4 Global_step 360000	Train_loss: 0.3313	Eval_AUC: 0.8692
Epoch 4 Global_step 361000	Train_loss: 0.3327	Eval_AUC: 0.8707
Epoch 4 Global_step 362000	Train_loss: 0.3351	Eval_AUC: 0.8702
Epoch 4 Global_step 363000	Train_loss: 0.3295	Eval_AUC: 0.8705
Epoch 4 Global_step 364000	Train_loss: 0.3337	Eval_AUC: 0.8698
Epoch 4 Global_step 365000	Train_loss: 0.3319	Eval_AUC: 0.8699
Epoch 4 Global_step 366000	Train_loss: 0.3316	Eval_AUC: 0.8708
Epoch 4 Global_step 367000	Train_loss: 0.3272	Eval_AUC: 0.8706
Epoch 4 Global_step 368000	Train_loss: 0.3326	Eval_AUC: 0.8709
Epoch 4 Global_step 369000	Train_loss: 0.3318	Eval_AUC: 0.8695
Epoch 4 Global_step 370000	Train_loss: 0.3309	Eval_AUC: 0.8715
Epoch 4 Global_step 371000	Train_loss: 0.3318	Eval_AUC: 0.8700
Epoch 4 Global_step 372000	Train_loss: 0.3285	Eval_AUC: 0.8701
Epoch 4 Global_step 373000	Train_loss: 0.3289	Eval_AUC: 0.8704
Epoch 4 Global_step 374000	Train_loss: 0.3336	Eval_AUC: 0.8704
Epoch 4 Global_step 375000	Train_loss: 0.3272	Eval_AUC: 0.8695
Epoch 4 Global_step 376000	Train_loss: 0.3328	Eval_AUC: 0.8708
Epoch 4 Global_step 377000	Train_loss: 0.3312	Eval_AUC: 0.8706
Epoch 4 Global_step 378000	Train_loss: 0.3339	Eval_AUC: 0.8708
Epoch 4 Global_step 379000	Train_loss: 0.3323	Eval_AUC: 0.8715
Epoch 4 Global_step 380000	Train_loss: 0.3295	Eval_AUC: 0.8720
Epoch 4 Global_step 381000	Train_loss: 0.3354	Eval_AUC: 0.8721
Epoch 4 Global_step 382000	Train_loss: 0.3284	Eval_AUC: 0.8706
Epoch 4 Global_step 383000	Train_loss: 0.3316	Eval_AUC: 0.8705
Epoch 4 Global_step 384000	Train_loss: 0.3296	Eval_AUC: 0.8702
Epoch 4 Global_step 385000	Train_loss: 0.3358	Eval_AUC: 0.8699
Epoch 4 Global_step 386000	Train_loss: 0.3324	Eval_AUC: 0.8705
Epoch 4 Global_step 387000	Train_loss: 0.3337	Eval_AUC: 0.8705
Epoch 4 Global_step 388000	Train_loss: 0.3325	Eval_AUC: 0.8702
Epoch 4 Global_step 389000	Train_loss: 0.3233	Eval_AUC: 0.8720
Epoch 4 Global_step 390000	Train_loss: 0.3358	Eval_AUC: 0.8720
Epoch 4 Global_step 391000	Train_loss: 0.3298	Eval_AUC: 0.8715
Epoch 4 Global_step 392000	Train_loss: 0.3318	Eval_AUC: 0.8701
Epoch 4 Global_step 393000	Train_loss: 0.3282	Eval_AUC: 0.8712
Epoch 4 Global_step 394000	Train_loss: 0.3306	Eval_AUC: 0.8713
Epoch 4 Global_step 395000	Train_loss: 0.3315	Eval_AUC: 0.8712
Epoch 4 Global_step 396000	Train_loss: 0.3333	Eval_AUC: 0.8732
Epoch 4 Global_step 397000	Train_loss: 0.3386	Eval_AUC: 0.8713
Epoch 4 Global_step 398000	Train_loss: 0.3316	Eval_AUC: 0.8709
Epoch 4 Global_step 399000	Train_loss: 0.3300	Eval_AUC: 0.8712
Epoch 4 Global_step 400000	Train_loss: 0.3349	Eval_AUC: 0.8723
Epoch 4 Global_step 401000	Train_loss: 0.3322	Eval_AUC: 0.8700
Epoch 4 Global_step 402000	Train_loss: 0.3275	Eval_AUC: 0.8720
Epoch 4 Global_step 403000	Train_loss: 0.3353	Eval_AUC: 0.8717
Epoch 4 Global_step 404000	Train_loss: 0.3328	Eval_AUC: 0.8725
Epoch 4 Global_step 405000	Train_loss: 0.3298	Eval_AUC: 0.8709
Epoch 4 Global_step 406000	Train_loss: 0.3300	Eval_AUC: 0.8703
Epoch 4 Global_step 407000	Train_loss: 0.3344	Eval_AUC: 0.8719
Epoch 4 DONE	Cost time: 65177.27
Epoch 5 Global_step 408000	Train_loss: 0.1186	Eval_AUC: 0.8724
Epoch 5 Global_step 409000	Train_loss: 0.3083	Eval_AUC: 0.8715
Epoch 5 Global_step 410000	Train_loss: 0.3058	Eval_AUC: 0.8706
Epoch 5 Global_step 411000	Train_loss: 0.3054	Eval_AUC: 0.8700
Epoch 5 Global_step 412000	Train_loss: 0.3057	Eval_AUC: 0.8694
Epoch 5 Global_step 413000	Train_loss: 0.3036	Eval_AUC: 0.8695
Epoch 5 Global_step 414000	Train_loss: 0.3036	Eval_AUC: 0.8703
Epoch 5 Global_step 415000	Train_loss: 0.3057	Eval_AUC: 0.8690
Epoch 5 Global_step 416000	Train_loss: 0.3039	Eval_AUC: 0.8699
Epoch 5 Global_step 417000	Train_loss: 0.3053	Eval_AUC: 0.8682
Epoch 5 Global_step 418000	Train_loss: 0.3021	Eval_AUC: 0.8696
Epoch 5 Global_step 419000	Train_loss: 0.3013	Eval_AUC: 0.8689
Epoch 5 Global_step 420000	Train_loss: 0.3043	Eval_AUC: 0.8699
Epoch 5 Global_step 421000	Train_loss: 0.3088	Eval_AUC: 0.8709
Epoch 5 Global_step 422000	Train_loss: 0.3042	Eval_AUC: 0.8700
Epoch 5 Global_step 423000	Train_loss: 0.3037	Eval_AUC: 0.8682
Epoch 5 Global_step 424000	Train_loss: 0.3062	Eval_AUC: 0.8693
Epoch 5 Global_step 425000	Train_loss: 0.3086	Eval_AUC: 0.8687
Epoch 5 Global_step 426000	Train_loss: 0.3042	Eval_AUC: 0.8672
Epoch 5 Global_step 427000	Train_loss: 0.3045	Eval_AUC: 0.8694
Epoch 5 Global_step 428000	Train_loss: 0.3128	Eval_AUC: 0.8695
Epoch 5 Global_step 429000	Train_loss: 0.3044	Eval_AUC: 0.8677
Epoch 5 Global_step 430000	Train_loss: 0.3102	Eval_AUC: 0.8689
Epoch 5 Global_step 431000	Train_loss: 0.3087	Eval_AUC: 0.8697
Epoch 5 Global_step 432000	Train_loss: 0.3066	Eval_AUC: 0.8684
Epoch 5 Global_step 433000	Train_loss: 0.3101	Eval_AUC: 0.8697
Epoch 5 Global_step 434000	Train_loss: 0.3047	Eval_AUC: 0.8696
Epoch 5 Global_step 435000	Train_loss: 0.3052	Eval_AUC: 0.8682
Epoch 5 Global_step 436000	Train_loss: 0.3043	Eval_AUC: 0.8673
Epoch 5 Global_step 437000	Train_loss: 0.3047	Eval_AUC: 0.8701
Epoch 5 Global_step 438000	Train_loss: 0.3091	Eval_AUC: 0.8697
Epoch 5 Global_step 439000	Train_loss: 0.3125	Eval_AUC: 0.8685
Epoch 5 Global_step 440000	Train_loss: 0.3092	Eval_AUC: 0.8694
Epoch 5 Global_step 441000	Train_loss: 0.3048	Eval_AUC: 0.8683
Epoch 5 Global_step 442000	Train_loss: 0.3077	Eval_AUC: 0.8698
Epoch 5 Global_step 443000	Train_loss: 0.3078	Eval_AUC: 0.8682
Epoch 5 Global_step 444000	Train_loss: 0.3070	Eval_AUC: 0.8700
Epoch 5 Global_step 445000	Train_loss: 0.3102	Eval_AUC: 0.8682
Epoch 5 Global_step 446000	Train_loss: 0.3089	Eval_AUC: 0.8691
Epoch 5 Global_step 447000	Train_loss: 0.3084	Eval_AUC: 0.8685
Epoch 5 Global_step 448000	Train_loss: 0.3050	Eval_AUC: 0.8687
Epoch 5 Global_step 449000	Train_loss: 0.3094	Eval_AUC: 0.8693
Epoch 5 Global_step 450000	Train_loss: 0.3087	Eval_AUC: 0.8688
Epoch 5 Global_step 451000	Train_loss: 0.3044	Eval_AUC: 0.8686
Epoch 5 Global_step 452000	Train_loss: 0.3109	Eval_AUC: 0.8683
Epoch 5 Global_step 453000	Train_loss: 0.3136	Eval_AUC: 0.8689
Epoch 5 Global_step 454000	Train_loss: 0.3116	Eval_AUC: 0.8686
Epoch 5 Global_step 455000	Train_loss: 0.3095	Eval_AUC: 0.8691
Epoch 5 Global_step 456000	Train_loss: 0.3129	Eval_AUC: 0.8691
Epoch 5 Global_step 457000	Train_loss: 0.3152	Eval_AUC: 0.8680
Epoch 5 Global_step 458000	Train_loss: 0.3075	Eval_AUC: 0.8693
Epoch 5 Global_step 459000	Train_loss: 0.3107	Eval_AUC: 0.8689
Epoch 5 Global_step 460000	Train_loss: 0.3104	Eval_AUC: 0.8686
Epoch 5 Global_step 461000	Train_loss: 0.3072	Eval_AUC: 0.8689
Epoch 5 Global_step 462000	Train_loss: 0.3083	Eval_AUC: 0.8694
Epoch 5 Global_step 463000	Train_loss: 0.3121	Eval_AUC: 0.8707
Epoch 5 Global_step 464000	Train_loss: 0.3094	Eval_AUC: 0.8682
Epoch 5 Global_step 465000	Train_loss: 0.3075	Eval_AUC: 0.8697
Epoch 5 Global_step 466000	Train_loss: 0.3076	Eval_AUC: 0.8690
Epoch 5 Global_step 467000	Train_loss: 0.3124	Eval_AUC: 0.8689
Epoch 5 Global_step 468000	Train_loss: 0.3081	Eval_AUC: 0.8700
Epoch 5 Global_step 469000	Train_loss: 0.3115	Eval_AUC: 0.8687
Epoch 5 Global_step 470000	Train_loss: 0.3075	Eval_AUC: 0.8693
Epoch 5 Global_step 471000	Train_loss: 0.3087	Eval_AUC: 0.8705
Epoch 5 Global_step 472000	Train_loss: 0.3093	Eval_AUC: 0.8684
Epoch 5 Global_step 473000	Train_loss: 0.3111	Eval_AUC: 0.8689
Epoch 5 Global_step 474000	Train_loss: 0.3110	Eval_AUC: 0.8673
Epoch 5 Global_step 475000	Train_loss: 0.3102	Eval_AUC: 0.8693
Epoch 5 Global_step 476000	Train_loss: 0.3110	Eval_AUC: 0.8678
Epoch 5 Global_step 477000	Train_loss: 0.3112	Eval_AUC: 0.8696
Epoch 5 Global_step 478000	Train_loss: 0.3107	Eval_AUC: 0.8697
Epoch 5 Global_step 479000	Train_loss: 0.3110	Eval_AUC: 0.8678
Epoch 5 Global_step 480000	Train_loss: 0.3074	Eval_AUC: 0.8696
Epoch 5 Global_step 481000	Train_loss: 0.3108	Eval_AUC: 0.8685
Epoch 5 Global_step 482000	Train_loss: 0.3156	Eval_AUC: 0.8684
Epoch 5 Global_step 483000	Train_loss: 0.3144	Eval_AUC: 0.8684
Epoch 5 Global_step 484000	Train_loss: 0.3117	Eval_AUC: 0.8681
Epoch 5 Global_step 485000	Train_loss: 0.3129	Eval_AUC: 0.8680
Epoch 5 Global_step 486000	Train_loss: 0.3073	Eval_AUC: 0.8693
Epoch 5 Global_step 487000	Train_loss: 0.3101	Eval_AUC: 0.8698
Epoch 5 Global_step 488000	Train_loss: 0.3148	Eval_AUC: 0.8689
Epoch 5 Global_step 489000	Train_loss: 0.3124	Eval_AUC: 0.8679
Epoch 5 DONE	Cost time: 76254.78
Epoch 6 Global_step 490000	Train_loss: 0.2535	Eval_AUC: 0.8698
Epoch 6 Global_step 491000	Train_loss: 0.2916	Eval_AUC: 0.8691
Epoch 6 Global_step 492000	Train_loss: 0.2915	Eval_AUC: 0.8684
Epoch 6 Global_step 493000	Train_loss: 0.2896	Eval_AUC: 0.8673
Epoch 6 Global_step 494000	Train_loss: 0.2929	Eval_AUC: 0.8677
Epoch 6 Global_step 495000	Train_loss: 0.2932	Eval_AUC: 0.8672
Epoch 6 Global_step 496000	Train_loss: 0.2945	Eval_AUC: 0.8677
Epoch 6 Global_step 497000	Train_loss: 0.2946	Eval_AUC: 0.8673
Epoch 6 Global_step 498000	Train_loss: 0.2936	Eval_AUC: 0.8663
Epoch 6 Global_step 499000	Train_loss: 0.2923	Eval_AUC: 0.8662
Epoch 6 Global_step 500000	Train_loss: 0.2969	Eval_AUC: 0.8676
Epoch 6 Global_step 501000	Train_loss: 0.2950	Eval_AUC: 0.8672
Epoch 6 Global_step 502000	Train_loss: 0.2919	Eval_AUC: 0.8664
Epoch 6 Global_step 503000	Train_loss: 0.2939	Eval_AUC: 0.8646
Epoch 6 Global_step 504000	Train_loss: 0.2937	Eval_AUC: 0.8665
Epoch 6 Global_step 505000	Train_loss: 0.2939	Eval_AUC: 0.8673
Epoch 6 Global_step 506000	Train_loss: 0.2987	Eval_AUC: 0.8652
Epoch 6 Global_step 507000	Train_loss: 0.2964	Eval_AUC: 0.8668
Epoch 6 Global_step 508000	Train_loss: 0.2963	Eval_AUC: 0.8670
Epoch 6 Global_step 509000	Train_loss: 0.2953	Eval_AUC: 0.8668
Epoch 6 Global_step 510000	Train_loss: 0.2941	Eval_AUC: 0.8671
Epoch 6 Global_step 511000	Train_loss: 0.2960	Eval_AUC: 0.8667
Epoch 6 Global_step 512000	Train_loss: 0.2975	Eval_AUC: 0.8680
Epoch 6 Global_step 513000	Train_loss: 0.2966	Eval_AUC: 0.8676
Epoch 6 Global_step 514000	Train_loss: 0.2949	Eval_AUC: 0.8668
Epoch 6 Global_step 515000	Train_loss: 0.2950	Eval_AUC: 0.8665
Epoch 6 Global_step 516000	Train_loss: 0.2922	Eval_AUC: 0.8653
Epoch 6 Global_step 517000	Train_loss: 0.2945	Eval_AUC: 0.8662
Epoch 6 Global_step 518000	Train_loss: 0.2957	Eval_AUC: 0.8671
Epoch 6 Global_step 519000	Train_loss: 0.2956	Eval_AUC: 0.8662
Epoch 6 Global_step 520000	Train_loss: 0.3002	Eval_AUC: 0.8662
Epoch 6 Global_step 521000	Train_loss: 0.2962	Eval_AUC: 0.8679
Epoch 6 Global_step 522000	Train_loss: 0.2971	Eval_AUC: 0.8673
Epoch 6 Global_step 523000	Train_loss: 0.2929	Eval_AUC: 0.8662
Epoch 6 Global_step 524000	Train_loss: 0.2951	Eval_AUC: 0.8654
Epoch 6 Global_step 525000	Train_loss: 0.2955	Eval_AUC: 0.8674
Epoch 6 Global_step 526000	Train_loss: 0.2991	Eval_AUC: 0.8661
Epoch 6 Global_step 527000	Train_loss: 0.2966	Eval_AUC: 0.8664
Epoch 6 Global_step 528000	Train_loss: 0.2963	Eval_AUC: 0.8662
Epoch 6 Global_step 529000	Train_loss: 0.2948	Eval_AUC: 0.8685
Epoch 6 Global_step 530000	Train_loss: 0.2978	Eval_AUC: 0.8671
Epoch 6 Global_step 531000	Train_loss: 0.2973	Eval_AUC: 0.8688
Epoch 6 Global_step 532000	Train_loss: 0.2967	Eval_AUC: 0.8667
Epoch 6 Global_step 533000	Train_loss: 0.2992	Eval_AUC: 0.8664
Epoch 6 Global_step 534000	Train_loss: 0.3045	Eval_AUC: 0.8658
Epoch 6 Global_step 535000	Train_loss: 0.3002	Eval_AUC: 0.8676
Epoch 6 Global_step 536000	Train_loss: 0.2971	Eval_AUC: 0.8669
Epoch 6 Global_step 537000	Train_loss: 0.2971	Eval_AUC: 0.8665
Epoch 6 Global_step 538000	Train_loss: 0.2990	Eval_AUC: 0.8672
Epoch 6 Global_step 539000	Train_loss: 0.3005	Eval_AUC: 0.8654
Epoch 6 Global_step 540000	Train_loss: 0.2983	Eval_AUC: 0.8671
Epoch 6 Global_step 541000	Train_loss: 0.3010	Eval_AUC: 0.8669
Epoch 6 Global_step 542000	Train_loss: 0.2984	Eval_AUC: 0.8666
Epoch 6 Global_step 543000	Train_loss: 0.3004	Eval_AUC: 0.8669
Epoch 6 Global_step 544000	Train_loss: 0.2997	Eval_AUC: 0.8662
Epoch 6 Global_step 545000	Train_loss: 0.2999	Eval_AUC: 0.8661
Epoch 6 Global_step 546000	Train_loss: 0.3033	Eval_AUC: 0.8666
Epoch 6 Global_step 547000	Train_loss: 0.2972	Eval_AUC: 0.8672
Epoch 6 Global_step 548000	Train_loss: 0.3059	Eval_AUC: 0.8666
Epoch 6 Global_step 549000	Train_loss: 0.2984	Eval_AUC: 0.8682
